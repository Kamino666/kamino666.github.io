<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pytorch DDP使用方法以及注意点</title>
    <link href="/2021/12/09/Pytorch%20DDP%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%B3%A8%E6%84%8F%E7%82%B9/"/>
    <url>/2021/12/09/Pytorch%20DDP%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%B3%A8%E6%84%8F%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="Pytorch-DDP使用方法以及注意点"><a href="#Pytorch-DDP使用方法以及注意点" class="headerlink" title="Pytorch DDP使用方法以及注意点"></a>Pytorch DDP使用方法以及注意点</h1><p>[TOC]</p><p>Pytorch的DDP指的是<code>DistributedDataParallel</code>，位于<code>torch.nn.parallel</code>中，用于多GPU的模型训练。相比于之前的DP，DDP的速度快了很多。DDP支持多卡多机器，但我没有多机器，所以本文针对最常用的单机器多卡。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>DDP加速的原理是通过启动多个<strong>进程</strong>，提高同时训练的<strong>batch size</strong>来增加并行度的，每一个进程都会加载一个模型，用<strong>不同的数据</strong>进行训练之后得到各自的梯度，然后通过<strong>Ring-Reduce</strong>算法获得所有进程的梯度，然后进行相同的梯度下降。注意在训练前和训练后，所有进程的模型参数都是同步了的。</p><p>Ring-Reduce是很简单理解的一个算法：每个进程都从左手边获得一份梯度，然后从右手发送一份梯度（一份指的是一个GPU得出的梯度），经过$n$次迭代之后，所有进程都获得了相同的完整的梯度。如下图，假设梯度$\nabla w$是GPU0算出来的，第一次$\nabla w$被发送到GPU1，第二次被GPU1发送到GPU2，第三次被GPU2发送到GPU3，第四次被发送到GPU4，第五次被发回给GPU0。这样每个进程都只需要接收一个，发送一个，而且能够清楚知道什么时候结束。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211209210301.png"></p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p>先来了解基础概念：</p><ul><li><code>world_size</code>：并行数，即总共用的卡数。</li><li><code>rank</code>：当前进程全局序号，范围0~world_size。</li><li><code>local_rank</code>：本地序号，由于本文介绍单机器，所以和上面一样。</li><li><code>master_port</code>：DDP需要进程间传递数据，所以需要使用端口。</li><li><code>master_address</code>：同上，需要使用IP地址。</li></ul><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>基本逻辑是这样：</p><pre><code class=" mermaid">graphA[初始化多进程并获取rank号]--&gt;B[使用DistributedSampler提供数据]B --&gt; C[将数据和模型都放在GPU上]C --&gt; D[将模型用DDP包裹]D --&gt; E[训练]E --&gt; F[loss.backward同步梯度]F --&gt; G[保存参数]</code></pre><h3 id="初始化多进程、获取rank号"><a href="#初始化多进程、获取rank号" class="headerlink" title="初始化多进程、获取rank号"></a>初始化多进程、获取rank号</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用这种方法获取local_rank</span><br><span class="hljs-comment"># 其他获取local_rank的方法已经被弃用</span><br>local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])<br><span class="hljs-comment"># 设置device</span><br>torch.cuda.set_device(local_rank)<br><span class="hljs-comment"># 用nccl后端初始化多进程，一般都用这个</span><br>dist.init_process_group(backend=<span class="hljs-string">&#x27;nccl&#x27;</span>)<br><span class="hljs-comment"># 获取device，之后的模型和张量都.to(device)</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, local_rank)<br></code></pre></td></tr></table></figure><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>对于$n$张卡上的$n$个模型，我们当然希望将数据分成不同的$n$部分，分别送给它们训练，所以需要使用<code>torch.utils.data.distributed.DistributedSampler</code>帮助我们自动分配数据。</p><blockquote><p><strong>注意！只有训练集才要用Sampler！</strong>在train之后，经常使用验证集对数据集进行验证得到validation_loss，此时没有必要使用多卡，只需要在一个进程上进行验证。</p><p>在多卡模式下要进行只在一个进程上的操作，通过<code>model.module(inputs)</code>而不是<code>model(inputs)</code>来调用<code>forward()</code>前向传播，而其他进程通过<code>torch.distributed.barrier()</code>来等待主进程完成validate操作。</p><p>假如要多卡推理，参考这篇文章写一个新的sampler[<a href="https://zhuanlan.zhihu.com/p/250471767">原创][深度][PyTorch] DDP系列第三篇：实战与技巧 - 知乎 (zhihu.com)</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">train_dataset = MyDataset()<br><span class="hljs-comment"># shuffle不在dataloader中设置，而是在sampler中设置</span><br>train_sampler = DistributedSampler(train_dataset, shuffle=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># batch_size指的是一张卡上的batch_size，总batch_size应该是要乘并行数</span><br>train_loader = torch.utils.data.DataLoader(train_dataset, <br>                                           batch_size=<span class="hljs-number">64</span>, <br>                                           sampler=train_sampler)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EPOCHS):<br>    <span class="hljs-comment"># 每轮开始前需要调用这个方法进行正确的数据shuffle</span><br>    <span class="hljs-comment"># 否则每一轮用的都是相同的顺序</span><br>    train_sampler.set_epoch(epoch)<br>    ...<br></code></pre></td></tr></table></figure><h3 id="把数据和模型放在GPU上"><a href="#把数据和模型放在GPU上" class="headerlink" title="把数据和模型放在GPU上"></a>把数据和模型放在GPU上</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 直接to(device)即可，注意要收到返回值</span><br>model = YourModel()<br>model = model.to(device)<br>your_data = your_data.to(device)<br></code></pre></td></tr></table></figure><h3 id="把模型用DDP包裹"><a href="#把模型用DDP包裹" class="headerlink" title="把模型用DDP包裹"></a>把模型用DDP包裹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># local_rank就是进程号</span><br><span class="hljs-comment"># 从此之后，调用model()就是用DDP模式的前向传播</span><br><span class="hljs-comment"># 要使用原始的前向传播，需要model.module()</span><br>model = DDP(model, device_ids=[local_rank], output_device=local_rank)<br></code></pre></td></tr></table></figure><h3 id="训练、同步梯度"><a href="#训练、同步梯度" class="headerlink" title="训练、同步梯度"></a>训练、同步梯度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 仍然可以直接调用模型的train()方法</span><br><span class="hljs-comment"># 但是假如要调用其他你自己写的方法，就得model.module.func()</span><br>model.train()<br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    loss = model(data)<br>    optimizer.zero_grad()<br>    loss.backward()  <span class="hljs-comment"># 这个操作自动同步梯度</span><br>    optimizer.step()<br>    <span class="hljs-comment"># 但是仍然需要累加得到所有进程loss的值的和</span><br>    dist.all_reduce(loss, op=dist.ReduceOp.SUM)<br>    <span class="hljs-comment"># 然后除以并行数，就是这个batch的loss值了</span><br>    loss /= world_size<br></code></pre></td></tr></table></figure><h3 id="保存参数"><a href="#保存参数" class="headerlink" title="保存参数"></a>保存参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存的是参数，不需要DDP包裹</span><br>torch.save(model.module.state_dict())<br></code></pre></td></tr></table></figure><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 通过外部命令运行</span> <br><span class="hljs-meta">#</span><span class="bash"> 通过CUDA_VISIBLE_DEVICES控制可见的卡数</span><br><span class="hljs-meta">#</span><span class="bash"> 通过--nproc_per_node确定使用多少卡</span><br>CUDA_VISIBLE_DEVICES=&quot;0,1,2,3&quot; python -m torch.distributed.run --nproc_per_node 4 train.py <br></code></pre></td></tr></table></figure><h2 id="DDP注意点复习！"><a href="#DDP注意点复习！" class="headerlink" title="DDP注意点复习！"></a>DDP注意点复习！</h2><ol><li>要把模型和数据放在进程对应的那张卡上</li><li>要使用Sampler来分发训练数据，并且shuffle不设置在Dataloder中而是Sampler中，每个epoch还需要调用Sampler的<code>set_epoch()</code>方法。</li><li>训练和验证区分较大，验证一般在主进程中进行一次验证即可，不需要sampler，操作和单卡一样，之后将数据同步给其他进程。</li><li>在多卡时要调用模型的其他方法或者使用单卡的模式，需要用<code>model.module</code>来获得原始模型，同样保存参数时也保存的是<code>model.module</code>的参数而不是DDP包裹的。</li></ol><h2 id="DDP小技巧"><a href="#DDP小技巧" class="headerlink" title="DDP小技巧"></a>DDP小技巧</h2><h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><p>使用<code>dist.all_reduce(loss, op=dist.ReduceOp.SUM)</code>可以同步tensor的数据，由于算法限制，要算平均值只能用求和运算<code>dist.ReduceOp.SUM</code>之后再除以<code>world_size</code>。</p><p>假如要同步的不是tensor，可以创建Tensor然后<strong>放进对应的GPU</strong>，再同步。</p><p>假如需要获得每个进程的某个tensor的值（即有n个GPU就获得n个值），那么使用<code>dist.all_gather</code>可以获得tensor列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 官网API文档</span><br><span class="hljs-comment"># All tensors below are of torch.int64 dtype.</span><br><span class="hljs-comment"># We have 2 process groups, 2 ranks.</span><br>tensor_list = [torch.zeros(<span class="hljs-number">2</span>, dtype=torch.int64) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br>tensor_list<br><span class="hljs-comment"># [tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1</span><br>tensor = torch.arange(<span class="hljs-number">2</span>, dtype=torch.int64) + <span class="hljs-number">1</span> + <span class="hljs-number">2</span> * rank<br>tensor<br><span class="hljs-comment"># tensor([1, 2]) # Rank 0</span><br><span class="hljs-comment"># tensor([3, 4]) # Rank 1</span><br>dist.all_gather(tensor_list, tensor)<br>tensor_list<br><span class="hljs-comment"># [tensor([1, 2]), tensor([3, 4])] # Rank 0</span><br><span class="hljs-comment"># [tensor([1, 2]), tensor([3, 4])] # Rank 1</span><br></code></pre></td></tr></table></figure><p>同步数据时假如要控制所有进程同时，可以使用<code>torch.distributed.barrier()</code>，让快的进程等一下慢的进程，假如timeout了，可以看看代码是否能优化，或者在运行之前提供参数提高timeout的值。</p><p><strong>假如dist.barrier()失效，可能是这种情况</strong><a href="https://discuss.pytorch.org/t/distributeddataparallel-barrier-doesnt-work-as-expected-during-evaluation/99867">DistributedDataParallel barrier doesn’t work as expected during evaluation - distributed - PyTorch Forums</a></p><blockquote><p>参考文献：</p><p>[<a href="https://zhuanlan.zhihu.com/p/178402798">原创][深度][PyTorch] DDP系列第一篇：入门教程 - 知乎 (zhihu.com)</a></p><p><a href="https://www.zhihu.com/question/57799212/answer/612786337"> ring allreduce和tree allreduce的具体区别是什么？ - 知乎 (zhihu.com)</a></p><p><a href="https://discuss.pytorch.org/t/distributeddataparallel-barrier-doesnt-work-as-expected-during-evaluation/99867">DistributedDataParallel barrier doesn’t work as expected during evaluation - distributed - PyTorch Forums</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>Pytorch</tag>
      
      <tag>DDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习中的Normalization</title>
    <link href="/2021/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Normalization/"/>
    <url>/2021/12/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Normalization/</url>
    
    <content type="html"><![CDATA[<h1 id="深度学习中的Normalization"><a href="#深度学习中的Normalization" class="headerlink" title="深度学习中的Normalization"></a>深度学习中的Normalization</h1><p>[TOC]</p><p>Normalization翻译为<code>规范化</code>或者<code>归一化</code>，不是标准化。</p><p>深度学习模型喜欢<strong>独立同分布</strong>的数据，<strong>独立</strong>即<strong>n维特征中每一维之间都没有相关性</strong>，同分布即<strong>特征的每一维都具有相同的均值和方差</strong>。在深度学习网络中，因为网络很深，如果数据在某一层开始有偏移，则网络加深会导致其加剧（Internal Covariate Shift, or ICS），而Normalization能够减缓这个问题。</p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p>BN就是将一个batch内的数据进行归一化，先求得均值$\mu_B$和方差$\sigma_B^2$，然后对每个元素进行归一化：$x’_i=\frac{x_i-\mu_B}{\sqrt{\sigma^2_B+\epsilon}}$，下面那个$\epsilon$是防止除以0。</p><p>之后，使用可学习参数$\gamma_i,\beta_i$变换为原始的分布：$y_i=\gamma_i\cdot x’_i + \beta_i$。<strong>这一步是为了保证模型表达能力不因为Normalization而下降</strong>，变化后数据均值为$\beta$，方差为$\gamma^2$。</p><p>使用BN时，得注意batch小时这个方法效果可能不佳。</p><p>对于图片<code>N C H W</code>的维度，BN统计的是<code>N H W</code>的均值和方差，对于每一个通道分开计算。</p><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><p>对于图片<code>N C H W</code>的维度，LN统计的是<code>C H W</code>的均值和方差，和batch size就没有关系了。</p><blockquote><p>参考文献：</p><p><a href="https://zhuanlan.zhihu.com/p/33173246">详解深度学习中的Normalization，BN/LN/WN - 知乎 (zhihu.com)</a></p><p><a href="https://www.zhihu.com/question/38102762">深度学习中 Batch Normalization为什么效果好？ - 知乎 (zhihu.com)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>未分类</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>Normalization</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Object Relational Graph with Teacher Recommended Learning for Video Captioning论文笔记</title>
    <link href="/2021/12/04/ORG%20TRL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/12/04/ORG%20TRL%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning论文笔记"><a href="#Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning论文笔记" class="headerlink" title="Object Relational Graph with Teacher-Recommended Learning for Video Captioning论文笔记"></a>Object Relational Graph with Teacher-Recommended Learning for Video Captioning论文笔记</h1><p>[TOC]</p><p>占据<code>paperswithcode.com</code>MSRVTT数据集VideoCaption任务榜一的文章，发表在CVPR2020上。论文主要贡献是一个Object Relational Graph(ORG)编码器和一种Teacher Recommended Learning(TRL)训练方式。</p><h2 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204113740.png"></p><p>这篇论文使用了2D-CNN 3D-CNN和Object三种特征，其中Object特征通过图神经网络ORG学习到特征，然后Description Generator通过对三种特征的注意力机制，通过TRL生成句子。</p><h2 id="Object-Relational-Graph编码器"><a href="#Object-Relational-Graph编码器" class="headerlink" title="Object Relational Graph编码器"></a>Object Relational Graph编码器</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204120043.png"></p><p>对于视频，提取$L$个关键帧，通过2D-CNN和3D-CNN得到特征$\mathcal F, \mathcal M$，通过预训练的object-detector得到特征$\mathcal {R} = {r^i_k}$，表示第$i$帧第$k$个object的特征，最多$N$个特征，object层面的特征相互是独立的。</p><p>对于d维的Object特征，K个特征可以表示为$K\times d$的矩阵，定义$A=\phi(R) \cdot \psi(R)^T$为关系矩阵，其中$\phi,\psi$是两个可学习的线性层，将$A$归一化之后可以得到$\hat A=softmax(A, dim=1)$，类似注意力矩阵，表示每一个object对于其它object有多少的注意力。之后乘上参数和原本的特征得到加强特征$\hat R=\hat A\cdot R\cdot W_r$。</p><p>对于关系矩阵的获取，这篇文章用了两种方法，一种是帧内的(P-ORG)，另一种是全局的(C-ORG)P-ORG选择帧内的$N$个object，编码他们之间的关系，不同帧的参数是共享的；C-ORG选择全部的$N\times L$个object，但是会筛选出top-k个object来减少复杂度。</p><h2 id="Description-Generation解码器"><a href="#Description-Generation解码器" class="headerlink" title="Description Generation解码器"></a>Description Generation解码器</h2><p>解码器部分由attn解码器和language解码器组成：</p><p>attn解码器使用LSTM网络，$\overline v$是降维掉时间轴的全局视频特征，$w_{t-1}$是前一个生成的单词，$h^{lang}_{t-1}$是language解码器的上一步hidden变量。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204120539.png"></p><p>然后通过输入$v_i$和$h^{attn}_{t-1}$得到施加注意力之后的整个视频的特征$c^g_t$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204172011.png"></p><p>对于Object层面的特征，也使用注意力机制得到local特征$c^l_t$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204172927.png"></p><p>最后送入language解码器，得到输出。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204173007.png"></p><h2 id="Teacher-Recommend-Learning（TRL）"><a href="#Teacher-Recommend-Learning（TRL）" class="headerlink" title="Teacher Recommend Learning（TRL）"></a>Teacher Recommend Learning（TRL）</h2><p>其他的方法在生成句子的时候是期望生成Ground Truth的句子，而Ground Truth是固定的${x^{hard}_t}$。</p><p>$$<br>P_t=CAP(w_{&lt;t}|\theta_{CAP}) \ \mathcal L_{CE} = -\sum^{T}_{t=1}\delta(x^h_t)^T \cdot logP_t<br>$$</p><p>而TRL借助外部知识源ELM（Bert或者GPT）得到一个新的概率分布$Q_t$，这里有一个temperature来平滑这个概率分布。</p><p>$$<br>Q_t=ELM(w_{&lt;t},T_e|\theta_{ELM})<br>$$</p><p>因为$Q_t$中有的单词概率实在是太小，所以不管那些单词，计算KL-loss。</p><p>$$<br>\mathcal L_{KL} = -\sum^{T}<em>{t=1} \sum</em>{d} Q^d_t \cdot log P^d_t<br>$$<br>最终loss是两个值相加。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204174938.png" alt="SOTA"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204175208.png" alt="Table 3"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204175041.png" alt="Table 4"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204181656.png" alt="Figure 6"></p><p>Table3和Table4可以看出TRL贡献了非常多，超过了ORG部分的贡献量。Figure 6也很直观让人感受到TRL的厉害hh。TRL算是在最后的决策部分结合大规模预训练语言模型，效果显著。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211204175317.png" alt="Table 5"></p><p>仅使用帧内Object和跨帧Object的差距并不是很大。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Video Captioning</tag>
      
      <tag>ORG-TRL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hierarchical Modular Network for Video Captioning论文笔记</title>
    <link href="/2021/12/02/Hierarchical%20Modular%20Network%20for%20Video%20Captioning%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/12/02/Hierarchical%20Modular%20Network%20for%20Video%20Captioning%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Hierarchical-Modular-Network-for-Video-Captioning论文笔记"><a href="#Hierarchical-Modular-Network-for-Video-Captioning论文笔记" class="headerlink" title="Hierarchical Modular Network for Video Captioning论文笔记"></a>Hierarchical Modular Network for Video Captioning论文笔记</h1><p>[TOC]</p><p>论文于2021年11月24日发表在了ArXiv上，提出了一个用来进行Video Captioning任务的<strong>分层网络</strong>，从<strong>实体(Entitiy)、动词(Predicate)、句子(Sentence)三个层次来进行建模</strong>。其中作者在Entity的部分贡献更大，提出了一个仿照DETR的模块。结果在MSVD和MSR-VTT上SOTA了。</p><p><strong>没有放出代码</strong></p><h2 id="总体框架"><a href="#总体框架" class="headerlink" title="总体框架"></a>总体框架</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211202191334.png"></p><h2 id="实体模块（Entity）"><a href="#实体模块（Entity）" class="headerlink" title="实体模块（Entity）"></a>实体模块（Entity）</h2><p>这个模块的输入特征由三部分组成，第一部分是Object feature，第二部分是2D-CNN feature，第三部分是3D-CNN feature。</p><p>其中Object使用Fast RCNN提取，先从视频中选择$T$个关键帧(keyframe)，从中总共检测出$L$个objects，每个object的特征维度为$d_0$。在作者的实现中，视频被分成了15个clip，每个clip有16帧，每个clip选出一帧作为关键帧，检测10个objects，并且预训练模型在Visual Genome数据集上训练。而2D-CNN使用InceptionResNetV2提取特征，3D-CNN使用C3D提取特征。以上特征都被全连映射到$d_{model}=512$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203150527.png"></p><p>如图，object特征$O$先送入Transformer的编码器得到特征$O’$（不做position encoding）。而2D-CNN和3D-CNN的特征$\mathcal{C},\mathcal{M}$在特征轴拼接之后送入双向LSTM网络再最大池化得到代表整个视频的特征$v$。仿照DETR，论文还加上了长度为$N$的随机初始化参数$Q$，$Q+v$作为解码器的target输入。解码器输出$\mathcal{E}$，再通过全连得到$\overline {\mathcal{E}}$，$\overline {\mathcal{E}}$的维度是SBERT模型的维度$d_s$。</p><p>为了监督学习，论文用SBERT提取caption中的名词的特征$\mathcal{N}$​（去掉无意义的），然后用DETR中的<code>Hungarian algorithm</code>匹配名词特征与object特征，计算余弦相似度作为loss：$\mathcal{L}_e$。</p><h2 id="动词模块（Predicate）"><a href="#动词模块（Predicate）" class="headerlink" title="动词模块（Predicate）"></a>动词模块（Predicate）</h2><p>这个模块就是一个添加Attention的BiLSTM，运动特征$\mathcal{M}$和目标特征$\epsilon$作为输入，通过注意力机制得到运动关联的目标特征$\mathcal{M}^e$，然后拼接$\mathcal{M}$和$\mathcal{M}^e$送入LSTM得到动作特征$\mathcal{A}$，然后对它最大池化消除时间轴维度，再送入全连把特征维度改成$d_s$，得到$\overline a$。</p><p>为了监督学习，论文用SBERT提取caption中的动词的特征$\mathcal{P}$（去掉无意义的），计算余弦相似度作为loss：$\mathcal{L}_p$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203152845.png"></p><h2 id="句子模块（Sentence）"><a href="#句子模块（Sentence）" class="headerlink" title="句子模块（Sentence）"></a>句子模块（Sentence）</h2><p>这个模块是学习视频整体特征和句子语言特征的。输入2D-CNN特征$\mathcal{C}$、内容关联的动作特征$\mathcal{C}^a$和内容关联的目标特征$\mathcal{C}^e$。（<code>xx关联</code>指的是对xx使用注意力机制）</p><p>上面三者在特征维度拼接，送入双向LSTM得到全局视频特征$\mathcal{G}$。同样，最大池化消除时间轴，再送入全连转换成$\overline g$，特征维度为$d_s$。然后用SBERT提取整个句子的特征，计算余弦相似度作为loss：$\mathcal{L}_s$。</p><h2 id="句子生成模块（Description-Generation）"><a href="#句子生成模块（Description-Generation）" class="headerlink" title="句子生成模块（Description Generation）"></a>句子生成模块（Description Generation）</h2><p>这一部分就是使用LSTM进行句子的生成，输入比较多，如下：</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203154538.png"></p><p>这里面$\bold E$是前一个预测单词的embedding，$h_{t-1}^{lang}$是隐藏，重点在于前面三个$\boldsymbol{g,a,e}$。三者分别代表整个<strong>视频的特征、运动特征和目标特征</strong>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203154933.png"></p><p>三个$\boldsymbol{g,a,e}$如上是拼接而来的，$\boldsymbol{\overline g, \overline a}$是之前获得过的<strong>视频总特征</strong>和运动总特征，而$\boldsymbol{?^l_t}$的变量都是用注意力机制得来的，从左到右分别是对$\mathcal{G},\mathcal{A},\mathcal{E},\overline {\mathcal{E}}$的加权求和，权由$\boldsymbol{h^{lang}_{t-1}}$和他们自己得到，如下图。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203202513.png"></p><p><strong>Loss使用了带ELM的交叉熵</strong>，ELM在论文<code>Object Relational Graph with Teacher-Recommended Learning for Video Captioning</code>中提到，引入外部语言模型来解决long-tail问题。（就是改变了一下分布）</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203155243.png" alt="本图来自ORG-TRL论文"></p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203203040.png"></p><p>比ORG-TRL高了一点点。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211203202704.png"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这玩意太不优雅了，注意力机制可算是给他弄明白了hhhh。</p><p>而且没有做关于引入外部语言模型的消融实验，在<code>Object Relational Graph with Teacher-Recommended Learning for Video Captioning</code>中TRL加上已经能达到Meteor28.6的程度了。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Video Captioning</tag>
      
      <tag>Hierarchical Modular Network</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Https协议的安全性原理</title>
    <link href="/2021/11/19/HTTPS/"/>
    <url>/2021/11/19/HTTPS/</url>
    
    <content type="html"><![CDATA[<h1 id="Https协议的安全性原理"><a href="#Https协议的安全性原理" class="headerlink" title="Https协议的安全性原理"></a>Https协议的安全性原理</h1><p>[TOC]</p><p>超文本传输安全协议（常称为HTTP over SSL/TLS）是一种通过计算机网络进行安全通信的传输协议。https经由http进行通信，但利用SSL/TLS来加密数据包。https使用端口443，URL以<code>https://</code>开头，使用https的网站需要从CA那里获得证书。</p><p>HTTP的数据使用TCP在互联网上明文传输，很容易被黑客截获、篡改或者冒充，而HTTPS除了ip和端口都进行了加密，并且使用了SSL/TLS的安全通信方式，所以相对来说安全。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211119145805.png" alt="what-is-https"></p><blockquote><p>关于SSL/TLS见我另一个博客。</p></blockquote><h2 id="https无法逃脱GFW监管"><a href="#https无法逃脱GFW监管" class="headerlink" title="https无法逃脱GFW监管"></a>https无法逃脱GFW监管</h2><p>这个是显而易见的hhh，毕竟现在打开浏览器输入<code>https://www.google.com</code>也上不了，因为https对对ip和端口是不加密的，而且注意是<strong>源ip、目标ip、源端口、目标端口</strong>都不加密。所以很容易就能封禁某网站的ip。</p><h2 id="https中间人劫持"><a href="#https中间人劫持" class="headerlink" title="https中间人劫持"></a>https中间人劫持</h2><p>首先说明，正常情况下https是不会遭遇中间人攻击的，因为HTTPS基于的TLS协议考虑到了这种情况。</p><p>中间人攻击(Man in the middle attack, or MITM)指的是在密码学和计算机安全领域中是指攻击者与通讯的两端分别创建独立的联系，并交换其所收到的数据，使通讯的两端认为他们正在通过一个私密的连接与对方直接对话，但事实上整个会话都被攻击者完全控制。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211119151139.jpg"></p><p>TLS通过数字证书来防御这种攻击，即User在访问某Web Applicaiton的时候，会先明文建立TCP连接，然后发送明文证书请求，然后某Web App会把CA认证的证书发给User，这个证书使用了CA的私钥进行加密非常安全，User收到证书之后用公钥解密验证证书的有效性，然后就会把本次TLS通讯的秘钥通过证书里的公钥加密发送给Web App。</p><p>假如黑客出现，在User收到Web App发来的正确证书的时候，就已经无计可施了，所以黑客要作为一个中间人，把Web App发来的正确证书进行掉包，生成一个包含自己公钥的假证书发给用户，<strong>假如用户傻傻地不验证证书的正确性，那就会使用中间人的公钥对TLS秘钥进行加密传输，而中间人拥有私钥，于是就能得到会话的TLS秘钥，从而获取信息</strong>。问题在于，用户遇到报错会不会点下图这种“继续浏览此网站”，不点就没事！</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211119152734.png"></p><h2 id="安装根证书"><a href="#安装根证书" class="headerlink" title="安装根证书"></a>安装根证书</h2><p>根证书是证明证书有效的证书。这听上去可能有点绕口，这是一种信任链，假如你信任国家这种最权威的机构，那国家授权的企业你也信任，而企业授权的证书颁发机构你也信任，证书颁发机构信任的网站你也信任，根证书就是信任的源头，它说啥就是啥。</p><p>在操作系统内部会内置很多根证书，同时用户也可以手动安装新的根证书，这就是万恶之源，安装了不可信的根证书之后，中间人颁发的假证书就可以说是假根证书所信任的，那么你的秘钥就泄露出去了。</p><p><strong>所以不要随随便便安装根证书</strong>。但是类似fiddle这样的抓包软件会让你安装根证书，因为它抓包https的技术就是作为一个可信的中间人。或者公司的防火墙也会要求安装根证书，安装之后防火墙就能监控所有的https流量内容（而不只是端口和ip）。</p><blockquote><p>参考文献</p><p><a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%AE%89%E5%85%A8%E5%8D%8F%E8%AE%AE">超文本传输安全协议 - 维基百科，自由的百科全书 (wikipedia.org)</a></p><p><a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB">中间人攻击 - 维基百科，自由的百科全书 (wikipedia.org)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>密码学</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>密码学</tag>
      
      <tag>https</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对称密码学和非对称密码学简介</title>
    <link href="/2021/11/18/%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E5%AD%A6%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E5%AD%A6%E7%AE%80%E4%BB%8B/"/>
    <url>/2021/11/18/%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E5%AD%A6%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E5%AD%A6%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="对称密码学和非对称密码学简介"><a href="#对称密码学和非对称密码学简介" class="headerlink" title="对称密码学和非对称密码学简介"></a>对称密码学和非对称密码学简介</h1><p>[TOC]</p><h2 id="密码学历史"><a href="#密码学历史" class="headerlink" title="密码学历史"></a>密码学历史</h2><p>要了解现代的对称密码学和非对称密码学，可以先简单了解下密码学的历史，这一节摘取一些维基百科“密码学”词条来进行介绍。</p><p><strong>密码学(cryptology)<strong>分成</strong>密码使用学(cryptography)<strong>和</strong>密码分析学</strong>，前者顾名思义是从使用者的角度对使用密码进行加密解密，而后者是从破解者的角度，对密码进行分析破译。<strong>密码学</strong>也可以分成<strong>古典密码学</strong>和<strong>现代密码学</strong>，古典密码学主要关注信息的保密书写和传递，以及与其相对应的破译方法。而现代密码学不只关注信息保密问题，还同时涉及信息完整性验证、信息发布的不可抵赖性、以及在分布式计算中产生的来源于内部和外部的攻击的所有信息安全问题。</p><p>密码学是数学和计算机科学的分支，同时其原理大量涉及信息论（但是在国内学科中“密码学”学科是军事学门类一级学科“军队指挥学”下的二级学科）。同时，我们生活中常用的密码(password)虽然也是密码学研究的对象，但是和密码学中更常见的秘钥(key)、密码算法(cipher, cypher, encode, code)是不一样的。</p><p>古代中国就记录了密码学的使用，周朝兵书《六韬．龙韬》中写姜子牙征战时与主将通信的方式使用阴符和阴书，阴符是以八等长度的符来表达不同的消息和指令，至于阴书则运用了移位法，把书一分为三，分三人传递，要把三份书重新拼合才能获得还原的信息。</p><p>古时西方由于字母少，发展出了接近现代密码学的密码，比如<strong>转置密码</strong>：将字母顺序重新排列，例如<code>help me</code>变成<code>ehpl em</code>；<strong>凯撒密码</strong>：每个字母被往后位移三格字母所取代；<strong>映射密码</strong>：凯撒密码的升级版，把字母随意一一配对互换。</p><p>到了中世纪，西方发明出了多字符加密法，最典型的例子是维吉尼亚加密法：加密重复使用到一个关键字，用哪个字母取代端视轮替到关键字的哪个字母而定。这个关键字可以看作是秘钥，假如用秘钥<code>ABC</code>加密<code>apple</code>，那先重复秘钥到等长<code>ABCAB</code>，然后对应着移位，a移位A对应的量，p移位B对应的量…e移位B对应的量。</p><p>在一战时期，西方打仗时使用的就是类似上面这样的加密方式，用人手+密码本进行加密，而二战时，德国就发明了密码机，用机械代替人手。</p><blockquote><p>德国雪毕伍斯发明了恩尼格码密码机（ENIGMA，直译为“谜”），下面这个视频介绍了这个密码机。</p><p><a href="https://www.youtube.com/watch?v=G2_Q9FoD-oQ">158,962,555,217,826,360,000 (Enigma Machine) - Numberphile - YouTube</a></p><p>下面这个C站的纪录片介绍了当时的密码战</p><p><a href="https://www.bilibili.com/video/BV1HW411N7hd?from=search&seid=224138967020097063&spm_id_from=333.337.0.0">【央视】丘吉尔智斗希特勒，英国如何用密码战抗击德国？智破密码 密码风云（三）_哔哩哔哩_bilibili</a></p></blockquote><p><strong>第二次世界大战后计算机与电子学的发展促成了更复杂的密码</strong>，而且计算机可以加密任何二进制形式的资料，不再限于书写的文字，以语言学为基础的破密术因此失效。多数计算机加密的特色是在二进制字符串上操作，而不像经典密码学那样直接地作用在传统字母数字上。<strong>然而，计算机同时也促进了破密分析的发展，抵消了某些加密法的优势。</strong></p><p>现代密码学的一个特点是，即使敌人知道了使用何种算法。对好的加密法来说，密钥的秘密性理应足以保障资料的机密性，这被叫做柯克霍夫原则。现代密码学还分成了对称密码学和非对称密码学，1976年以前的加密算法都基于对称算法，之后，非对称算法（公钥算法）被Diffie和Hellman发明了。如今，对称算法（DES、AES）和非对称算法（RSA）都广泛应用于各方面。</p><h2 id="对称密码学"><a href="#对称密码学" class="headerlink" title="对称密码学"></a>对称密码学</h2><p>如图，<strong>对称密码学</strong>说的就是编码和解码使用同一个秘钥的加密算法，加密算法可以被公开，发送和接收双方要事先得到同一个秘钥。常见的对称加密算法有AES、ChaCha20、3DES、Salsa20、DES、Blowfish、IDEA、RC5、RC6、Camellia以及我国的SM1。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118173239.png" alt="Symmetric-Encryption"></p><h3 id="DES"><a href="#DES" class="headerlink" title="DES"></a>DES</h3><p>DES是一种对称密钥加密块密码算法，使用56位秘钥对64位明文块进行加密。对于已经转换成二进制的明文，需要将其分解成以64为单位的分组，然后每组都使用秘钥进行加密。<strong>DES作为强加密，拥有混淆(Confusion)和扩散(Diffusion)特征</strong>，混淆指的是秘钥和密文之间关系尽可能模糊，扩散指的是一个明文符号的影响能波及到多位密文（即改动一个位就会导致密文发生较大变化）。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118185815.jpg"></p><p>如图，DES加密过程主要阶段为：</p><pre><code class=" mermaid">graph LRA(64bit明文) --&gt; B[初始置换IP]B --&gt; C[16轮加密变换]C --&gt; D[逆初始置换IP]D --&gt; E(64bit密文)</code></pre><p><strong>初始置换IP</strong>就是简单的把明文按照某种规则替换，比如把第1位替换成58位、第2位替换成50位……</p><p>16轮加密变换每一轮都需要一个48bit的轮秘钥$K_i$，由那个56bit的秘钥经过置换和移位算法产生。</p><p>每一轮的变换如下图，64bit的输入分成左半边和右半边，每次只变换一半，输出的左半总是输入的右半，输出的右半是$左半 \oplus f(右半)$。这个f分成E盒、S盒和置换P。E盒把32位的输入拓展成48位的输出，这增加了DES的扩散特性。然后48位的秘钥和这个48位的输出进行XOR，结果送进S盒生成32位输出，S盒是DES的核心，是算法中唯一的非线性元素，提供了DES的混淆特性（非线性：$S(a) \oplus S(b) \neg S(a+b)$）。之后输入进P盒置换得到$f(右半)$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118191204.png"></p><p>进行16轮次这样的加密后，再逆置换IP就能得到最终的密文</p><p>DES的解密十分简单，和加密过程几乎一样，改变的只有轮秘钥$K_i$的顺序，将$K_i$反向就是解密过程。</p><blockquote><p>目前DES已经不再安全，56bit的秘钥太短了，破解DES的方式主要是暴力攻击，2008年有人就在一天以内暴力破解出了DES。</p><p>DES有10个不那么安全的秘钥，很容易被破解，但是这数量很少，可以忽略。</p></blockquote><h3 id="AES"><a href="#AES" class="headerlink" title="AES"></a>AES</h3><p>AES是用来替换DES的高级加密标准，分别有AES-128、AES-192和AES-256三种方案，里面的数字就是秘钥的位数。AES还有五种加密模式，即CBC、ECB、CTR、OCF、CFB，使用时要注意秘钥长度和加密模式的选择。</p><p>AES和DES很像，都是分组加密的算法，AES加密的是128bit的明文块，同时AES的解密也很简单，就是把加密流程倒置。加密的流程如下图：</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118195058.png" alt="Advanced-Encryption-Standard"></p><p>AES和DES都是照顾了硬件的加密算法，能够高效安全地加密，现在AES仍然是最流行的加密算法之一。截至2006年，针对AES唯一的成功攻击是旁道攻击或社会工程学攻击。</p><h2 id="非对称密码学"><a href="#非对称密码学" class="headerlink" title="非对称密码学"></a>非对称密码学</h2><p>如图，<strong>非对称密码学</strong>使用两个秘钥，一个是公开秘钥(public key)，一个是私有秘钥(private key)；公钥用来加密，私钥用来解密；公钥可以公开，而私钥不能公开。直观来看，这种加密方式就像邮箱（不是电子邮箱！！），邮差可以随意将信从小缝投入你的信箱，但是他无法拿出来，只有你用钥匙才能打开信箱取出信件。</p><p>目前常用的非对称密码有RSA、DH、DSA、ECDH、ECDSA。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118195321.png" alt="Asymmetric-Encryption"></p><h3 id="非对称密码学的特点"><a href="#非对称密码学的特点" class="headerlink" title="非对称密码学的特点"></a>非对称密码学的特点</h3><p>非对称密码解决了对称密码的三个问题：<strong>秘钥分配</strong>、<strong>秘钥数量</strong>、<strong>用户欺骗</strong>。</p><p>秘钥分配指的是虽然用秘钥传输密文是安全的，但是秘钥本身还得保密，假如你想要和地球另一边的人使用对称加密方式进行通信，你得先找到方法把通信的秘钥安全送到他那。而非对称密码可以安全地公布公钥。</p><p>秘钥数量问题指的是n个用户假如要互相通信，那就需要$\frac{n(n-1)}{2}$个秘钥，每个人都要保存$n-1$个秘钥，这样太麻烦了。</p><p>用户欺骗则是一种更巧妙的问题，在对称通信中，AB双方都有相同的秘钥，假如A是用户，B是淘宝，A向B发送了购买一件商品的加密信息，但是A后来又后悔了，于是A欺骗说：“我没有发送这条信息，既然B也有秘钥，那么B可以伪造这份信息。”</p><p>根据<code>Understanding Cryptography: A Textbook for Students and Practitioners</code>这本书，非对称密码学的主要功能如下：</p><ol><li>秘钥建立：在不安全信道上建立秘钥</li><li>不可否认性：A发送了消息给B，不能否认</li><li>身份标识：可确信是谁发送了加密消息</li><li>加密：加密 XD</li></ol><p>同时，非对称密码学也有缺点，那就是耗时长，比对称密码学的方法能慢上一百倍甚至一千倍。所以实践中经常混合使用这两种方法进行通信。</p><h3 id="非对称密码学的根基"><a href="#非对称密码学的根基" class="headerlink" title="非对称密码学的根基"></a>非对称密码学的根基</h3><p>目前非对称密码学主要建立在三种计算问题上，</p><ol><li><p>整数分解：素数相乘得到的因式很难分解回来</p></li><li><p>离散对数：假设在整数范围内，对数$x=log_b(a)$，已知$x,b$，计算$a$容易；但是已知$a,b$，计算$x$就很麻烦。</p></li><li><p>椭圆曲线：椭圆曲线通用方程为$y^2=x^3+ax+b$，任何一条不垂直的直线与曲线的交点不超过3个。定义一种运算，曲线上两个点为AB，AB连直线得到C’，C’关于x轴有对称点C，称作$A \ dot \ B=C$。给定一个初始点A，一个动点B，经过n次dot运算之后得出Z，从A Z求出n比较困难。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211118203903.gif"></p></li></ol><h3 id="数字签名和数字证书"><a href="#数字签名和数字证书" class="headerlink" title="数字签名和数字证书"></a>数字签名和数字证书</h3><p><strong>数字签名（英语：Digital Signature，又称公钥数字签名）</strong>是一种功能类似写在纸上的普通签名、但是使用了公钥加密领域的技术，以用于鉴别数字信息的方法。<strong>解决的问题是：确认收到的文件没有被改动。</strong></p><p>数字签名将非对称密码反过来使用，加密的秘钥当作私钥，解密的秘钥当作公钥，对一份文件进行签名的过程就是用Hash函数得到文件的摘要，然后用私钥对其进行加密，得到摘要的密文，即数字签名。接收者收到消息后用同一种Hash函数计算出摘要，然后用被公钥解密的数字签名来比对，假如有变动则说明消息收到篡改。</p><p>由于非对称密码的性质，公钥不能计算出私钥，所以接收者可以知道发送者是谁、消息是否被改动过，并且可以确信发送者发送了消息。</p><blockquote><p><strong>Hash函数：</strong></p><p>又叫做单向散列函数，能够根据任意长度的消息快速生成固定长度的一个值，<strong>不同的消息生成的值不同</strong>。假如两个不同的消息生成出了同一个散列值，那就叫做碰撞，Hash具有抗碰撞性。Hash生成的值无法推算回原来的值。目前的具体Hash算法有MD4、MD5、SHA-1、SHA-256、SHA-384、SHA-512等。</p><p>Hash函数可以用作密码管理，密码明文存放在数据库不安全，所以一般存的是Hash之后的密文，用户输入密码后，服务器Hash得到的值和数据库中的密文进行比对来认证。</p><p>Hash函数还可以用来快速检索，假如要从许多文件中检索一个文件，那就可以直接用文件的Hash值来比较。</p><p>Hash最后的一个常用功能就是这里说的数字签名啦~</p></blockquote><p>然而，假如一开始发送者就是别人假装的，那么接收者收到的数字签名就是坏人伪造的、收到的公钥也是坏人的，<strong>要确信公钥来自发送者，还需要数字证书技术。</strong></p><p><strong>数字证书（digital certificate）或身份证书（identity certificate）</strong>是用于公开密钥基础建设的电子文件，用来证明公开密钥拥有者的身份。此文件包含了公钥信息、拥有者身份信息（主体）、以及数字证书认证机构（发行者）对这份文件的数字签名，以保证这个文件的整体内容正确无误。</p><p>发送者发送自己的数字签名公钥时，发送一个由权威认证中心（CA）认证过的证书，这个证书由CA的私钥加密，你可以用CA的公钥解密出证书内容，然后向CA求证是否正确。这个过程相当于接收者和发送者完全信任一个第三方，而第三方能证明某个公钥属于某个发送者。</p><p>实际应用中，由于需要CA的企业太多了，所以采用分级管理，假如你不信任B，那么查看C给B的证书；假如不信任C，那么查看D给C的证书……直到最后就是Google、政府机构这些最权威的CA了。</p><p>你也可以自己给自己证明颁发证书，但是并没有什么用，浏览器或者别的电脑软件会发出警告。</p><blockquote><p>参考文献：</p><p>深入浅出密码学 清华大学出版社</p><p><a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81%E5%AD%A6">密码学 - 维基百科，自由的百科全书 (wikipedia.org)</a></p><p><a href="https://zh.wikipedia.org/wiki/%E5%B0%8D%E7%A8%B1%E5%AF%86%E9%91%B0%E5%8A%A0%E5%AF%86">对称密钥加密 - 维基百科，自由的百科全书 (wikipedia.org)</a></p><p><a href="https://www.ssl2buy.com/wiki/symmetric-vs-asymmetric-encryption-what-are-differences">Symmetric vs. Asymmetric Encryption - What are differences? (ssl2buy.com)</a></p><p><a href="https://blog.csdn.net/zxh2075/article/details/80620570">DES加密教程详细解读_zxh2075的专栏-CSDN博客</a></p><p><a href="https://www.youtube.com/watch?v=Y61qn_SQl40">Data Encryption Standard - YouTube</a></p><p><a href="https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95">RSA加密算法 - 维基百科，自由的百科全书 (wikipedia.org)</a></p><p><a href="http://blog.hubwiz.com/2020/06/16/elliptic-curve-intro/">椭圆曲线密码学【科普】 | 学习软件编程 (hubwiz.com)</a></p><p><a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E9%96%8B%E9%87%91%E9%91%B0%E8%AA%8D%E8%AD%89#%E4%B8%AD%E5%9C%8B%E4%BA%92%E8%81%AF%E7%B6%B2%E7%B5%A1%E4%BF%A1%E6%81%AF%E4%B8%AD%E5%BF%83%E7%99%BC%E8%A1%8C%E5%81%87%E6%86%91%E8%AD%89%E4%BA%8B%E4%BB%B6">公开密钥认证 - 维基百科，自由的百科全书 (wikipedia.org)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>密码学</category>
      
    </categories>
    
    
    <tags>
      
      <tag>密码学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SSL/TLS协议原理</title>
    <link href="/2021/11/16/SSL%20TLS%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86/"/>
    <url>/2021/11/16/SSL%20TLS%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="SSL-TLS协议原理"><a href="#SSL-TLS协议原理" class="headerlink" title="SSL/TLS协议原理"></a>SSL/TLS协议原理</h1><p>SSL(Secore Socket Layer)是安全套接层，TLS(Transport Layer Security)是SSL的高级版本，一般叫做SSL/TLS，是<strong>计算机网络应用层的一种安全通信协议</strong>。SSL/TLS工作在TCP之上，HTTPS等应用之下，通过采用机密性、数据完整性、服务器鉴别和客户鉴别来解决安全问题。</p><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>SSL有三个阶段：<strong>握手、秘钥导出、数据传输</strong>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211116195440.png"></p><h3 id="握手"><a href="#握手" class="headerlink" title="握手"></a>握手</h3><p>首先，蓝色部分是建立（不安全的）TCP连接的过程，这一部分就是TCP的三次握手，这一部分有的时候可能被忽略。</p><p>在建立TCP连接后，客户端向服务端传输一个包含一些基本信息的hello报文<code>Client Hello</code>。基本信息即SSL版本、会话ID、加密四件套列表、客户端随机数等。（图中未包含随机数）</p><p>之后，服务端从客户端支持的加密四件套中选择一种，然后把选择+CA证书+服务端随机数+SSL版本+会话ID组合成<code>Server Hello</code>返回给客户端。客户端收到证书之后验证证书，若验证成功，则客户端可确信服务端。</p><p>之后，客户端生成一个前主密钥（Pre Master Secret），再从证书中用服务端选择的方法提取服务端公钥，用服务端公钥加密PMS后传输给服务端。<strong>此时，双方都获得了此次SSL通话的前主密钥，即握手成功。</strong></p><blockquote><p><strong>加密四件套：</strong></p><p>例<code>ECDH-ECDSA-AES128-SHA256 </code>：ECDH是秘钥交换算法、ECDS是证书算法（非对称密码）、AES128是数据加密算法（对称密码）、SHA256是MAC算法（Hash）。</p></blockquote><h2 id="秘钥导出"><a href="#秘钥导出" class="headerlink" title="秘钥导出"></a>秘钥导出</h2><p>PMS包含的不只是1个秘钥，而是4个秘钥，服务端和客户端能通过之前生成的两个随机数（客户端随机数和服务端随机数）各自用秘钥导出函数<strong>独立</strong>计算出主密钥（Master Secret），而MS可以分片成4个秘钥分别是客户端加密秘钥、客户端MAC秘钥、服务端加密秘钥、服务端MAC秘钥，这个过程叫做秘钥导出。</p><blockquote><p><strong>注意此处的MAC指的是Message Authentication Code，即消息认证码</strong>。MAC需要发送者和接收者共享一个MAC秘钥，发送者根据发送数据计算MAC值，将数据和MAC发给对方。接收者收到数据之后也计算MAC值，然后比对收到的MAC值，从而判断消息是否被改动。</p></blockquote><p>在客户端和服务端都能计算出MAC后，客户端会立马发送所有握手报文的MAC值给服务端，而服务端收到后进行验证，也会发送所有握手报文的MAC值给客户端。</p><blockquote><p><strong>为什么最后还要互相传一次MAC</strong>：这两步使握手报文不被篡改，因为<code>CLIENT HELLO</code>和<code>SERVER HELLO</code>这两个报文都是明文传输，假如没有这两步，那么可能会有人将客户端支持的加密算法改成较弱的算法，或者把SSL改成更弱的早期版本。</p><p><strong>不直接传输MS的原因：</strong>通过PMS各自独立计算MS，不将其放在信道进行传输，可以从根源上防止MS泄露，保证其安全性。</p><p><strong>添加随机数的原因：</strong>可以防止“连接重放攻击”：假如别人截取了你昨天在淘宝买东西的报文，然后今天重新发这个报文100次，没有随机数参与的话，那这个报文就是完全正确的了，你就会再买这个东西100次啦。</p></blockquote><h2 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h2><p>SSL将数据流分割成<strong>记录</strong>，对每个记录附加一个MAC，然后加密<code>记录+MAC</code>进行传输。对于MAC的计算，发送者将通过<code>记录+序号hash</code>计算MAC，序号初始为0，每发一个记录，序号就+1。这样就能防止中间人的重排序和重放报文。</p><blockquote><p><strong>参考文献</strong></p><p>计算机网络：自顶向下方法（第7版） 机械工业出版社</p><p><a href="https://blog.csdn.net/qq_41137136/article/details/86482650"> 认证篇——消息认证码_锦瑟常思的博客-CSDN博客_消息认证码</a></p><p><a href="https://medium.com/@vanrijn/an-overview-of-the-ssl-handshake-3885c37c3e0f">An overview of the SSL Handshake. In this post I will give an overview of… | by Robert van Rijn | Medium</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>密码学</category>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>密码学</tag>
      
      <tag>SSL/TLS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的机器学习课笔记 #4-SVM支持向量机</title>
    <link href="/2021/11/10/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%204-SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <url>/2021/11/10/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%204-SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="我的机器学习课笔记-4-SVM支持向量机"><a href="#我的机器学习课笔记-4-SVM支持向量机" class="headerlink" title="我的机器学习课笔记 #4-SVM支持向量机"></a>我的机器学习课笔记 #4-SVM支持向量机</h1><p>[TOC]</p><p><strong>SVM，全称Support Vector Machine，即支持向量机，是一种监督学习算法</strong>，基础的SVM是二分类线性模型，但可通过核函数拓展至非线性分类或者用其他方法拓展至多分类模型。本文是学习SVM基础模型、软间隔与正则项、核函数以及数学上的求解方法时所做的笔记。</p><h2 id="SVM基础模型"><a href="#SVM基础模型" class="headerlink" title="SVM基础模型"></a>SVM基础模型</h2><p>SVM算法的动机就是想画一条线，能<strong>最好地</strong>分开训练样本中的两个类别。如何判断“最好”呢？判断离这条线最近的几个点与线的距离，这个距离越大，效果就越好。判断距离时选中的那几个点被叫做<strong>支持向量</strong>，SVM的训练结果直接由这几个支持向量决定，这叫做SVM的<strong>稀疏性</strong>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211110112521.png"></p><h2 id="理论求解"><a href="#理论求解" class="headerlink" title="理论求解"></a>理论求解</h2><p>要画的那一条“线”其实是一个超平面，数学上用 $\boldsymbol{w^Tx}+b=0$这个方程表示<em>（几何中一条线的方程是Ax+By+C=0，一个面的方程是Ax+By+Cz+D=0，以此类推到多维空间的超平面数学方程）</em></p><p>而点到超平面的距离公式是$ d=\frac{|\boldsymbol{w^Tx}+b|}{||w||}$<em>（几何中一个三维空间的点到平面距离公式是 $d=\frac{|Ax+By+Cz+D|}{\sqrt{A^2+B^2+C^2}}$，以此类推）</em></p><p>此时新假设两个平行于$\boldsymbol{w^Tx}+b=0$的超平面，一个是$\boldsymbol{w^Tx}+b=1$，另一个是$\boldsymbol{w^Tx}+b=-1$，需要找到的 $\boldsymbol{w^T}$需要满足以下条件，而通过平面间距的公式得到新假设的这两个超平面<strong>间隔</strong>为 $\gamma=\frac{2}{||w||}$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211112161002.svg"></p><p>所以我们需要优化的问题是：<br>$$<br>argmin_{w,b}(\frac{||w||}{2}) \quad s.t. y_i(\boldsymbol{w^Tx_i}+b) \ge 1<br>$$<br><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211112155619.jpg" alt="西瓜书配图"></p><blockquote><p>利用<strong>对偶问题</strong>求解（参考西瓜书附录）</p><p><strong>拉格朗日乘子法的解释</strong>：拉格朗日乘子法是一种寻找<strong>多元函数在一组约束下的极值</strong>的方法。通过引入拉格朗日乘子，可将有d个变量、k个约束的最优化问题转换为d+k个变量、无约束的最优化问题。</p><p>如图，假如函数是 $f(x,y)$，约束是 $g(x,y)=C$，那么在最优点（图中等高线交点）函数梯度和约束梯度方向相同或相反，即 $\nabla f(x_i,y_i) + \lambda \nabla g(x_i,y_i) = 0$。此时定义另一个函数 $L(x,y,\lambda)=f(x,y)+\lambda g(x,y)$，则 $\frac{\partial L}{\partial x,y} = \nabla f(x_i,y_i) + \lambda \nabla g(x_i,y_i)$。所以原问题就转换成了最后这个方程的最优化问题。</p><p>假如约束不是个等式，而是不等式，也可以使用这种方法。假设函数是 $f(x,y)$，约束是 $g(x,y) \le 0$。假如最优点$(x_i,y_i)$满足$g(x_i,y_i)&lt;0$，那约束就不起作用，直接对原始做无约束最优化；假如最优点$(x_i,y_i)$满足$g(x_i,y_i)=0$，那就和等式约束的情况一样了，但是此时函数梯度和约束梯度方向<strong>必然**相反，所以此时 $\lambda&gt;0$。结合两种情况，归纳成</strong>KKT条件**：<br>$$<br>g(x,y) \le 0 \quad \lambda \ge 0 \quad \lambda g(x)=0<br>$$<br><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211113141611.jpeg"></p><p>使用<strong>拉格朗日乘子法</strong>求SVM的最优化问题：</p><p>将$argmin_{w,b}(\frac{||w||}{2}) \quad s.t. y_i(\boldsymbol{w^Tx_i}+b) \ge 1$转换成拉格朗日函数即<br>$$<br>L(\boldsymbol w, b, \boldsymbol \alpha)= \frac{||w||^2}{2} + \sum^m_{i=1} \alpha_i (1-y_i(\boldsymbol{w^Tx_i}+b))<br>$$<br>满足KKT条件：<br>$$<br>1-y_i(\boldsymbol{w^Tx_i}+b) \le 0 \quad \alpha_i \ge 0 \quad \alpha_i (1-y_i(\boldsymbol{w^Tx_i}+b))=0<br>$$<br><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211113153507.jpg"></p><p>现在问题就只剩下解出$L(\boldsymbol \alpha)$的最大值（此处留坑）</p></blockquote><h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>核函数，或者叫做核技巧，是在SVM中用来将线性拓展到非线性的工具。对于图中左边这种无法用一根直线划分的数据分布，使用某种映射函数 $\phi(x)$映射到高维空间后，就能用一个平面划分。<strong>但是</strong>$\phi(x)$ <strong>有很多种，而且映射之后也无法保证是线性可分的。只能保证假如原始空间是有限维度的，那么一定会有一个高维特征空间使样本线性可分。</strong></p><p>在使用映射函数提升维度后，对偶问题变成了 $最大化 -\frac{1}{2}\sum^m_{i=1}\sum^m_{j=1} \alpha_i \alpha_j y_i y_j \phi(\boldsymbol{x_i})^T\phi(\boldsymbol{x_j}) + \sum^m_{i=1}\alpha_i$，但是求 $\phi(\boldsymbol{x_i})^T\phi(\boldsymbol{x_j})$是在是太麻烦了，需要升维之后再求内积，所以我们<strong>使用核技巧，用核函数代替内积</strong>，即 $k(\boldsymbol{x_i, x_j}) = \phi(\boldsymbol{x_i})^T\phi(\boldsymbol{x_j})$。从这个角度来看，核函数就是计算样本映射到高维空间的内积。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114151644.png"></p><p>核函数对应着一个核矩阵，对于任意对称函数，只要这个矩阵是<strong>半正定</strong>的，那这个函数就能当做核函数，一个半正定矩阵就暗中对应着一个高维空间。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114164932.jpeg"></p><p>对于这个核函数的选择，西瓜书上列了这些。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114165616.jpg"></p><blockquote><p>对称函数：$f(x, y) = f(y,x)$</p><p>半正定矩阵：<strong>给定一个</strong>$n\times n$<strong>的实数对称矩阵</strong>$A$，<strong>若对于任意长度</strong>$n$<strong>的向量</strong>$\boldsymbol{x}$，有$\boldsymbol{x^TAx} \ge 0$<strong>恒成立，则为半正定矩阵</strong>。$y=\boldsymbol{x^TAx}$就和$y=ax^2$差不多，要它$\ge 0$恒成立，就是要$A$满足一个从另一个角度$\ge 0$的条件。</p><p>证明：$K(x^{(i)},x^{(j)})$是$K$矩阵$i$行$j$列的值，又可以看作是某两个向量特征映射之后的内积，对于高维向量的单独一个值，就是向量通过$\phi_k$函数（k是高维的维度）的出来的单个值。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114163738.png"></p></blockquote><h2 id="软间隔"><a href="#软间隔" class="headerlink" title="软间隔"></a>软间隔</h2><p>前面提到就算用了核函数也不能保证数据在高维空间是线性可分的，于是我们可以考虑保留少部分点是错误分类的。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114165853.jpg"></p><p>此时需要优化的问题变成了<br>$$<br>argmin_{w,b}(\frac{||w||}{2} + C\sum^m_{i=1}\ell_{0/1}(y_i(\boldsymbol{w^Tx_i}+b) - 1))<br>$$<br>其中$\ell_{0/1}(z)$是当$z&lt;0$时为1，$z\ge0$时为0的函数。</p><p>$y_i(\boldsymbol{w^Tx_i}+b) &lt; 1$时，点不位于超平面正确的那一侧，此时$\ell_{0/1}(z)=1$，第二项开始起作用，而作用就是作为一个正数，让loss的值变大，<strong>从而让优化算法使不符合要求的点尽量少</strong>。</p><p>说到优化算法，上面说的$\ell_{0/1}(z)$明显是没有导数还不连续的，所以一般使用别的函数来替代它。如下图，有三种损失，分别是hinge损失、指数损失和对率损失，其中hinge损失用的最多。</p><p>下图$z&lt;0$时即点在超平面（上图虚线）的另一侧，此时$\ell(z) \ge 1$；下图$0&lt;z$时即点在超平面（上图虚线）的正确侧，但会根据点与分割线的距离给予不同的损失，此时$0 \le \ell(z) \le 1$。这样的话两个额外的超平面（上图虚线）就不是强行划分的界限了，而是形成了和距离有关的<strong>软间隔</strong>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211114171204.jpg"></p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>定义$\xi = \ell(y_i(\boldsymbol{w^Tx_i}+b) - 1)$，要优化的那一部分可以简写成下面这样：<br>$$<br>argmin_{w,b}(\frac{||w||^2}{2} + C\sum^m_{i=1} \xi_i)<br>$$<br>我们换个形式，也可以是这样：<br>$$<br>argmin_{w,b}(\sum^m_{i=1} \xi_i + \lambda ||w||^2)<br>$$<br>这样的话就很像逻辑回归添加了L2正则化的损失函数：$argmin_{w,b}(\sum^m_{i=1} (y-\hat{y})^2 + \lambda ||w||^2)$。两者的第一项被叫做<strong>经验风险</strong>，指模型在训练集学习到的经验；第二项被叫做<strong>结构风险</strong>，描述模型的某些性质，这一项又可以被叫做<strong>正则化项</strong>，而$\lambda$叫做正则化常数，用来获取结构上复杂度较小的模型。</p><blockquote><p>参考文献</p><p><a href="https://www.zhihu.com/question/38586401">如何理解拉格朗日乘子法？ - 知乎 (zhihu.com)</a></p><p><a href="https://medium.com/analytics-vidhya/how-to-classify-non-linear-data-to-linear-data-bb2df1a6b781">Kernel Trick in SVM. Kernel Trick can solve this issue using… | by Siddhartha Sharma | Analytics Vidhya | Medium</a></p><p><a href="https://zhuanlan.zhihu.com/p/44860862">浅谈「正定矩阵」和「半正定矩阵」 - 知乎 (zhihu.com)</a></p><p><a href="https://www.zhihu.com/question/289165454">SVM的核函数中为什么要求核矩阵是半正定的？ - 知乎 (zhihu.com)</a></p><p><a href="http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-linear-svm/">Support Vector Machines for Beginners - Linear SVM - A Developer Diary</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>课程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>SVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的机器学习课笔记 #2-线性模型</title>
    <link href="/2021/11/09/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%202-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    <url>/2021/11/09/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%202-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="我的机器学习课笔记-2-线性模型"><a href="#我的机器学习课笔记-2-线性模型" class="headerlink" title="我的机器学习课笔记 #2-线性模型"></a>我的机器学习课笔记 #2-线性模型</h1><p>[TOC]</p><p>线性模型就是一个通过<strong>属性的线性组合</strong>来进行预测的函数。下式中(1)(2)(3)都是线性的，而(4)不是线性的，因为看中的是学习参数$w$的线性，而不是属性本身的变化是不是线性。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211109155712.png"></p><p>线性模型的优点是可解释性强，缺点是拟合能力比较弱，这一章使用线性模型进行回归和分类任务。</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>线性回归的目标如下，最小化所有样本的<strong>预测结果与真实结果之间的欧几里得距离</strong>，即最小化均方误差（MSE）。<br>$$<br>f(x_i)=wx_i+b，f(x)\approx y_i<br>$$</p><p>$$<br>argmin(\sum_{i=1}^{m}(f(x_i)-y_i)^2)<br>$$</p><p>求解w、b有两种方法，一是通过<strong>最小二乘法</strong>可以得到w和b的最优解，二是通过<strong>梯度下降法</strong>迭代求导较优解。最小二乘法虽然能够一次求解，但是适用范围窄、当特征维度大时计算量比较大；梯度下降法是深度学习中最普遍的方法，面对成千上万的特征维度仍然能够很好求解。</p><blockquote><p><strong>最小二乘法</strong></p><p>最小二乘法要求损失函数是凸函数，当损失函数的导数为0的时候认为达到了最优点，通过这个方程解出w和b的值。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211111154323.png" alt="image-20211111154323303"></p></blockquote><blockquote><p><strong>对数线性回归</strong></p><p>有时逼近的不是y而是y的衍生物，比如逼近y的对数：$\ln y=wx_i+b$</p><p>这种严格来说不是线性回归，而是广义线性模型的一种，广义线性模型需要一个单调可微函数$g(·)$<br>$$<br>广义线性模型： y=g^{-1}(w^Tx+b)<br>$$</p></blockquote><h2 id="线性回归改进——正则化"><a href="#线性回归改进——正则化" class="headerlink" title="线性回归改进——正则化"></a>线性回归改进——正则化</h2><p>为了抑制线性模型的过拟合，可以通过在损失函数中添加L1范数或者L2范数来进行正则化，对应<strong>LASSO回归</strong>和<strong>Ridge岭回归</strong>。</p><p>L1范数就是$||w||<em>1=\sum^{d}</em>{i=1}|w_i|$，即向量w所有元素的绝对值的和</p><p>L2范数就是$||w||<em>2=\sum^{d}</em>{i=1}w_i^2$，即向量w所有元素的平方的和</p><p>如图，使用时通过超参数$\lambda$与原来的损失函数相加构成新的损失函数</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211109161859.png" alt="Ridge_Regression"></p><p>正则化抑制过拟合的原理是惩罚过大的w项，w太大会导致那么拟合曲线斜率就会更大、更不平滑，在损失函数中加上正则化项后w变大会导致损失函数变大，而我们的算法会让损失函数尽量小，从而得到更小的w，进而抑制了过拟合。两种正则化的对比如图，椭圆中心是原来loss的最低处，现在会往原点靠，得到的拟合效果如图，能较好的抑制曲线一上一下的过拟合情况。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211109162548.png"></div><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211109163052.png"></div></div></div><h2 id="线性分类（对数几率回归、逻辑回归）"><a href="#线性分类（对数几率回归、逻辑回归）" class="headerlink" title="线性分类（对数几率回归、逻辑回归）"></a>线性分类（对数几率回归、逻辑回归）</h2><p>假如做的是二分类任务，那么要输出的就不是一个值而是0/1了，即 $y\in {0,1}$。要把$wx_i+b$的回归值转换成0/1，理想使用阶跃函数，但是因为不连续而不利于计算。所以需要找到一个决策函数 $g(·)$来近似，要求<strong>单调可微分</strong>，发现<strong>sigmoid</strong>函数（也叫对数几率函数 logistic function）符合条件。这个函数满足单调可微，而且形式简单，值位于0到1之间，预测时大于0.5的判为正例，小于0.5的判为负例。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211111194901.png" alt="Sigmoid函数"></p><p>为什么叫他对数几率回归呢，因为把函数形式变换一下就可以看做 $\ln{\frac{y}{1-y}}=w^Tx+b$，近似 $\frac{y}{1-y}$这个“几率”的对数。此处“几率”是 $\frac{发生概率}{不发生概率}$。</p><p>机器学习三要素的“模型”已经有了，接下来是损失函数，<strong>二分类问题的损失函数不使用MSE而使用对数似然函数</strong>。为什么不使用MSE呢？<strong>一是因为用MSE计算sigmoid出来的概率和标签时，MSE不是凸函数（这个想证明但是不会证）；二是会出现梯度消失</strong>，证明如下。</p><blockquote><p>MSEloss的值用E表示，用标签 $y_i$减去$\sigma$出来的概率，再求平方，然后对loss求偏导如公式所示，当$\sigma$接近$y_i$时，$\sigma$和$1-\sigma$总有一个趋近于0，此时梯度消失。举个例子：当y=1时，预测出来σ=0.00001，此时距离真实值很远，应该梯度很大，然而梯度接近0。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211112151336.svg"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211112151208.svg"></p></blockquote><p>我们模型目前的输出是一个0~1的数，可以看作是预测正类出现的概率，而似然函数就是概率的对数。<br>$$<br>p(y=1|x)=sigmoid(w^Tx+b)<br>$$<br>$$<br>p(y=0|x)=1-sigmoid(w^Tx+b)<br>$$<br>$$<br>Loss(w,b)=\sum^m_{i=1}{\ln{p(y_i|x_i;w, b)}} 其中x_i,y_i是一对数据集标注<br>$$</p><p>数据集三要素还差一个优化算法，我们使用极大似然法+梯度下降解决，目的是最大化上面这个loss，数学推导如下：</p><blockquote><p><strong>极大似然法 maximum likelihood method</strong></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211111213436.jpg"></p></blockquote><h2 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h2><p>之前提到的分类学习只是在二分类，<strong>若要进行多分类的学习任务，可以使用ovo（one vs one）、ovr（one vs rest）、mvm（many vs many）</strong>三种策略。</p><ul><li>ovo，就是把N个类别两两配对，训练 $\frac{N(N-1)}{2}$个二分类器，然后通过这些二分类器的结果进行投票得出最终预测值</li><li>ovr，就是训练N个二分类器，每次都选取一个类别作为正例，其余为负例，这样只用训练N个但是数据不均衡</li><li>mvm，每次选择若干个类作为正例，若干个类作为负例。这种选取有很多种方式，在这里不详细介绍。</li></ul><blockquote><p>参考文献</p><p><a href="https://chrisalbon.com/code/machine_learning/linear_regression/ridge_regression/">Ridge Regression (chrisalbon.com)</a></p><p><a href="https://jishuin.proginn.com/p/763bfbd2bbb3">AI 面试高频问题: 为什么二分类不用 MSE 损失函数？-技术圈 (proginn.com)</a></p><p><a href="https://www.pianshen.com/article/48901189766/">梯度下降数学推导</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>课程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的机器学习课笔记 #1-绪论与模型评估</title>
    <link href="/2021/11/06/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%201-%E7%BB%AA%E8%AE%BA%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"/>
    <url>/2021/11/06/%E6%88%91%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%AC%94%E8%AE%B0%201-%E7%BB%AA%E8%AE%BA%E4%B8%8E%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="我的机器学习课笔记-1-绪论与模型评估"><a href="#我的机器学习课笔记-1-绪论与模型评估" class="headerlink" title="我的机器学习课笔记 #1-绪论与模型评估"></a>我的机器学习课笔记 #1-绪论与模型评估</h1><p>[TOC]</p><h2 id="没有免费午餐定理（no-free-lunch-theorem-or-NFL）"><a href="#没有免费午餐定理（no-free-lunch-theorem-or-NFL）" class="headerlink" title="没有免费午餐定理（no free lunch theorem, or NFL）"></a>没有免费午餐定理（no free lunch theorem, or NFL）</h2><p>人们使用机器学习是期望机器学习到的算法有用，但是NFL定理却证明，对于任意两个学习算法，它们的期望性能都一样。但是别灰心，NFL定理的前提是“所有情况下”，所以NFL说的是“<strong>一个算法不可能在任何情况下都取得最好的性能</strong>”。</p><p>但是我们并不需要一个算法在任何情况下性能都最好，甚至，我们经常只关注一个算法在一个方面的性能，比如使用鸢尾花数据集进行分类预测时，我们假设<strong>数据集中的4个属性足够让我们将鸢尾花进行分类</strong>，但是实际上鸢尾花有许多许多许多的属性，要将这些属性都综合考虑在内才能在所有情况下正确预测，所以用这个数据集训练出来的模型在其他鸢尾花数据集上可能就不工作了。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211106173104.jpg" alt="NFL 图源知乎"></p><p>或者NFL定理也可以理解为“<strong>你不可能在没有假设的情况下从数据中学习</strong>”，如下图，我们的机器学习模型在学习过程中对于输入和输出作出了假设，这种假设可能在某些数据集上适用，但是换成别的数据集就不适用了。比如我有一个处理视频的模型，它假设视频中有物体运动的时序信息，但是视频中也可能没有运动，也可能是个意义不明的所有帧像ppt那样排布的视频，在这些情况下假设失效。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211106171336.jpeg" alt="no free lunch theorems"></p><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>对一个模型的评估会分成两类，一类是训练误差，另一类是泛化误差。前者是在训练样本上进行评估得到的误差，后者是在新样本上进行评估得到的误差。</p><p>这两类误差的大小能导致过拟合和欠拟合现象，如下表和下图，</p><table><thead><tr><th></th><th>泛化误差大</th><th>泛化误差小</th></tr></thead><tbody><tr><td>训练误差大</td><td>欠拟合</td><td>不可能</td></tr><tr><td>训练误差小</td><td>过拟合</td><td>模型的目标</td></tr></tbody></table><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211106174253.png" alt="欠拟合与过拟合 图源geeksforgeeks"></p><p>如何得到训练误差和泛化误差呢？可以分为<strong>得到训练集和测试集的方法</strong>和<strong>使用哪种误差函数</strong>这两个问题。</p><h3 id="如何得到训练集和测试集？"><a href="#如何得到训练集和测试集？" class="headerlink" title="如何得到训练集和测试集？"></a>如何得到训练集和测试集？</h3><ul><li><p>留出法</p><p>最常用，就是把数据集的划分成两个互斥的集合，一个训练一个预测。</p></li><li><p>交叉验证法</p><p>小样本适用，因为会带来更大的计算开销。K折交叉验证指的是将数据集随机分成K份，进行K次训练和预测，每次训练选取K-1份作为训练集，每次预测选取剩下那1份作为测试集。</p></li><li><p>自助法</p><p>适用于集成学习，不会减少训练集的数据数量，但会改变数据集的分布。就是将一个拥有m个数据的数据集进行放回抽样，抽m次出来得到的就是训练集，用所有数据去掉训练集就是测试集，易知训练集的数量是m，但里面会有重复的数据。</p></li></ul><h3 id="使用哪种误差函数？"><a href="#使用哪种误差函数？" class="headerlink" title="使用哪种误差函数？"></a>使用哪种误差函数？</h3><p>误差函数有很多很多种，作用就是告诉你模型的性能。西瓜书上主要介绍的是分类任务的性能度量。</p><h4 id="错误率和精度"><a href="#错误率和精度" class="headerlink" title="错误率和精度"></a>错误率和精度</h4><p>错误率就是分类错误样本占总数的比例，精度又叫做正确率、准确率（accuracy）。</p><h4 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h4><p>对于二分类结果，通常列出下面这种混淆矩阵，注意这个表的纵轴是真实情况，横轴是预测结果，有的图可能会把横纵轴对换，但是字母是不变的。</p><p>结果中的<code>T/P</code>指的是预测是否正确，而<code>P/N</code>指的是预测的是正例还是反例。FP就是预测是正例，但是预测错了，实际是反例，以此类推。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211107165119.png"> </p><h4 id="查准率、查全率、P-R曲线、F1"><a href="#查准率、查全率、P-R曲线、F1" class="headerlink" title="查准率、查全率、P-R曲线、F1"></a>查准率、查全率、P-R曲线、F1</h4><p>查准率查全率可以用搜索引擎的角度来解释，<strong>查准率就是搜索出来的数据有多少是对的，查全率就是有多少对的数据被查出来了</strong>，两者分母不同。也可以把查准率叫做精确率（和acc准确率区分开），把查全率叫做召回率。<br>$$<br>查准率、精确率：Precise=\frac{TP}{TP+FP}<br>$$</p><p>$$<br>查全率、召回率：Recall=\frac{TP}{TP+FN}<br>$$</p><p>P-R曲线就是纵轴P，横轴R的曲线。分类问题一般会对测试数据得出一个预测概率，从高到低排序，可以手动选择最高的k个作为预测正例，在k不确定的时候，查准率和查全率就会呈现P-R曲线。<strong>假如k很大，那么查全率就会高，查准率就会低，因为把很多低概率的结果都判成正例。</strong></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211107170803.png" alt="P-R和ROC曲线"></p><p>查准率和查全率是对于模型两方面的评估，但是我们想要一个综合的评价指标，于是<strong>使用调和平均得到F1这个指标。</strong><br>$$<br>\frac{1}{F1} = \frac{1}{2} (\frac{1}{P}+\frac{1}{R})<br>$$<br>若对于查准率和查全率需要偏好，则可以使用<strong>加权调和平均</strong>。<br>$$<br>\frac{1}{F_\beta} = \frac{1}{1+\beta^2} (\frac{1}{P}+\frac{\beta^2}{R})<br>$$</p><blockquote><p>调和平均：参考<a href="https://www.zhihu.com/question/23096098">如何理解与应用调和平均数？ - 知乎 (zhihu.com)</a></p><p>考虑一次去便利店并返回的行程：</p><ul><li><strong>去程</strong>速度为<code>30 mph</code></li><li><strong>返程</strong>时交通有一些拥堵，所以速度为<code>10 mph</code></li><li>去程和返程走的是同一路线，也就是说距离一样（5英里）</li></ul><p>整个行程的平均速度是多少？如果不假思索地应用算术平均数的话，结果是20 mph（(30+10)/2）。</p><p>但是这么算不对。因为去程速度更快，所以你更快地完成了去程的5英里，整个行程中以30 mph的速度行驶的时间更少，以10 mph的速度行驶的时间更多，所以整个行程期间你的平均速度不会是<code>30 mph</code>和<code>10 mph</code>的中点，而应该更接近<code>10 mph</code>。</p><p>用调和平均数呢？2 / (1/30 + 1/10) = 15 mph 一下子得到了真正的行程平均速度，<strong>自动</strong>根据在每个方向上使用的时间进行调整。</p></blockquote><h4 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h4><p>用查准率查全率得到的P-R曲线和F1指标有一个缺点，那就是<strong>都没用上混淆矩阵中的TN——也就是“真反例”——也就是预测是反例，真实是反例的结果</strong>。所以定义FPR为“假正例率”，<strong>ROC就是以FPR为横轴，召回率为纵轴的曲线。</strong><br>$$<br>FPR=\frac{FP}{TN+FP}<br>$$<br>对于ROC曲线，越往左上角凸的模型越好，理解为“<strong>所有负例中被判错的少，且所有正例中被判对的多。</strong>”</p><p>然而P-R曲线和ROC曲线都有一个问题，那就是曲线之间不好准确比较，对于交叉的曲线无法判断孰优孰劣。所以将ROC曲线下的面积AUC作为单个数字的指标。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211107181343.png" alt="ROC曲线"></p><h2 id="模型性能分析"><a href="#模型性能分析" class="headerlink" title="模型性能分析"></a>模型性能分析</h2><p>得到模型的泛化误差后，我们仍然想知道如何模型为什么会得到这样的性能，于是我们对模型的泛化误差进行分析，可得：<br>$$<br>泛化误差=偏差(bias)+方差(var)+噪声(noise)<br>$$</p><ul><li>偏差指的是模型算法本身的拟合能力，是预测结果与真实结果的偏离程度</li><li>方差指的是模型对于相同大小的<strong>训练集</strong>的学习结果的抖动。</li><li>噪声是和数据集本身有关的泛化误差的下界，即学习本身的难度。</li></ul><p>假如是图片识别猫狗的二分类问题，在模型还没训练的时候，模型瞎猜能得到50%的正确率，无论训练集测试集怎么划分肯定都大概是这个结果，此时正确率低反映偏差高、数据划分不带来结果变化反映方差低；在模型训练很久之后，模型会对训练集拟合得越来越好，此时正确率上升，偏差也随之下降，但是也可能学习到训练集中的特殊信息，导致过拟合，此时方差高。</p><blockquote><p>参考文献：</p><p>周志华的西瓜书</p><p><a href="https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/">Machine Learning’s No Free Lunch Theorem Explained (analyticsindiamag.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/138019862">No free lunch theorem-没有免费的午餐 - 知乎 (zhihu.com)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
      <category>课程笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MATLAB基础笔记</title>
    <link href="/2021/11/05/MATLAB%E5%9F%BA%E7%A1%80/"/>
    <url>/2021/11/05/MATLAB%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="MATLAB基础笔记"><a href="#MATLAB基础笔记" class="headerlink" title="MATLAB基础笔记"></a>MATLAB基础笔记</h1><p>基本参考<a href="http://c.biancheng.net/view/6595.html">MATLAB是什么？ (biancheng.net)</a>、<a href="https://ww2.mathworks.cn/help/index.html?s_tid=CRUX_lftnav">文档主页 - MathWorks 中国</a></p><h2 id="变量、类型、关键字"><a href="#变量、类型、关键字" class="headerlink" title="变量、类型、关键字"></a>变量、类型、关键字</h2><p><strong>变量</strong></p><p>变量和Python一样不用声明，变量名别奇奇怪怪的就行。</p><table><thead><tr><th>特殊变量</th><th>意义</th></tr></thead><tbody><tr><td>pi</td><td>圆周率</td></tr><tr><td>ans</td><td>默认变量</td></tr><tr><td>i或者j</td><td>复数</td></tr><tr><td>eps</td><td>最小数</td></tr><tr><td>inf</td><td>无穷大</td></tr><tr><td>NaN</td><td>not a number</td></tr></tbody></table><p><strong>创建矩阵</strong>的时候，用<code>,</code>隔开一行中的元素，用<code>;</code>分隔列。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs matlab">x = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>;<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br><br><span class="hljs-built_in">ans</span> =<br><br>     <span class="hljs-number">1</span>     <span class="hljs-number">2</span><br>     <span class="hljs-number">3</span>     <span class="hljs-number">4</span><br></code></pre></td></tr></table></figure><p>通常创建矩阵的方式：</p><ul><li><code>a:b:c</code>：生成整数序列，即从a开始步长为b，一直到不小于c的数</li><li><code>linspace(start, end, n)</code>：包括start和end，生成线性的n个数据。</li><li><code>ones()</code>,<code>zeros()</code>,<code>eye()</code>：全1，全0，对角矩阵</li><li><code>rand()</code>,<code>randn()</code>：均匀分布、正态分布</li></ul><p><strong>类型</strong></p><p>查看类型可以用<code>class</code>，查看维度等详细信息可以用<code>whos()</code>、</p><p>NaN类型可以用<code>isnan()</code>找出矩阵中的NaN，有NaN的地方是1。找出之后可以用<code>find()</code>继续找到索引位置。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs matlab">$ 把数组中NaN类型变成<span class="hljs-number">0</span>的代码<br><span class="hljs-built_in">i</span> = <span class="hljs-built_in">find</span>(<span class="hljs-built_in">isnan</span>(a))<br>a(<span class="hljs-built_in">i</span>) = <span class="hljs-built_in">zeros</span>(<span class="hljs-built_in">size</span>(<span class="hljs-built_in">i</span>))<br></code></pre></td></tr></table></figure><p><strong>空数组</strong></p><p>就是没有元素的数组，假如<code>find()</code>不到东西，可能就会返回这个。空数组用<code>x = []</code>创建。判断空数组用<code>isempty(x)</code>。</p><h2 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h2><p>MATLAB里等于是==，但是不等于是~=。</p><p><code>&amp;</code>表示与，<code>|</code>表示或，<code>~</code>表示取反，<code>any(x)</code>表示x里any not 0 in x，<code>all(x)</code>表示all not 0 in x。</p><h2 id="数学运算符"><a href="#数学运算符" class="headerlink" title="数学运算符"></a>数学运算符</h2><p><code>&#39;</code>、<code>transpose(x)</code>：转置</p><p><code>+、-</code>：加减法     <code>sum()</code>：求和</p><p><code>.*</code>：按元素乘法    <code>*</code>：矩阵乘法</p><p><code>.^</code>：按元素求幂    <code>^</code>：矩阵幂</p><p><code>mod()</code>：模</p><p><code>round()</code>、<code>floor()</code>、<code>ceil()</code>：四舍五入、往下、往上</p><h2 id="下标-索引"><a href="#下标-索引" class="headerlink" title="下标/索引"></a>下标/索引</h2><p><strong>下标从1开始！！！！</strong></p><p><strong>下标从1开始！！！！</strong></p><p><strong>下标从1开始！！！！</strong></p><p>下标用<code>()</code>表示，先行再列，不能用负数下标但是可以用end表示最后一行（用end-1访问倒数第2个元素），其它和python差不多。</p><p>下标内容可以是一维数组，也就是说可以用<code>x([1,5,6])</code>这种方法。</p><p>而索引指的是把矩阵拍扁之后的序号，对于矩阵，下标可以是一个二维坐标，而索引是一个数字。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">A=<br>    <span class="hljs-number">8</span>    <span class="hljs-number">1</span>    <span class="hljs-number">6</span><br>    <span class="hljs-number">3</span>    <span class="hljs-number">5</span>    <span class="hljs-number">7</span><br>    <span class="hljs-number">4</span>    <span class="hljs-number">9</span>    <span class="hljs-number">2</span><br>元素  索引  下标<br> <span class="hljs-number">8</span>     <span class="hljs-number">1</span>    (<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br> <span class="hljs-number">3</span>     <span class="hljs-number">2</span>    (<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br> <span class="hljs-number">4</span>     <span class="hljs-number">3</span>    (<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br> <span class="hljs-number">1</span>     <span class="hljs-number">4</span>    (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br> <span class="hljs-number">5</span>     <span class="hljs-number">5</span>    (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br> <span class="hljs-number">9</span>     <span class="hljs-number">6</span>    (<span class="hljs-number">3</span>,<span class="hljs-number">2</span>)<br> <span class="hljs-number">6</span>     <span class="hljs-number">7</span>    (<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br> <span class="hljs-number">7</span>     <span class="hljs-number">8</span>    (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br> <span class="hljs-number">2</span>     <span class="hljs-number">9</span>    (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><h2 id="循环、条件"><a href="#循环、条件" class="headerlink" title="循环、条件"></a>循环、条件</h2><p>条件语法如下，不用冒号不用括号，按照缩进分隔，用end结尾</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-keyword">if</span> expression<br>    statements<br><span class="hljs-keyword">elseif</span> expression<br>    statements<br><span class="hljs-keyword">else</span><br>    statements<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>循环语法如下，用end结尾，可以用break和continue，values可以是次数也可以是可遍历的结构</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-keyword">for</span> index = values<br>   statements<br><span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">while</span> expression<br>   statements<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>需要在文件中创建，文件名是函数名，<code>function [y1,...,yN] = myfun(x1,...,xM)</code>：声明名为 <code>myfun</code> 的函数，该函数接受输入 <code>x1,...,xM</code> 并返回输出 <code>y1,...,yN</code>。</p>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MATLAB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CLIP4Caption论文笔记</title>
    <link href="/2021/11/02/CLIP4Caption%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <url>/2021/11/02/CLIP4Caption%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="CLIP4Caption论文笔记"><a href="#CLIP4Caption论文笔记" class="headerlink" title="CLIP4Caption论文笔记"></a>CLIP4Caption论文笔记</h1><p>[TOC]</p><p>论文：<code>CLIP4Caption: CLIP for Video Caption</code></p><p>网址：<a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3479207">CLIP4Caption: CLIP for Video Caption (acm.org)</a>、<a href="https://doi.org/10.1145/3474085.3479207">https://doi.org/10.1145/3474085.3479207</a></p><p>代码：无</p><p>这篇2021年10月发布在MM’21的论文提出了一个基于CLIP、CLIP4CLIP(1)和Uni-VL的模型，用来做视频描述任务（Video Captioning），效果拔群，METEOR和CIDEr指标都是SOTA。文章主要想利用已有的vision-language预训练模型来帮助下游任务。同时文章还提出了一种集成学习方法，效果也有提升。作者还发了一篇<code>CLIP4Caption++: Multi-CLIP for Video Caption</code>主要在VATEX数据集上实验，并且添加了subtitle的多模态，放在另一篇文章中讲吧.。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102131519.png" alt="CLIP4Caption整体架构"></p><p>模型分成两部分——预训练阶段和微调阶段，预训练阶段就是用CLIP4clip的方式在MSR-VTT数据集上进行视频检索任务的学习，这一部分要非常多的算力资源，目的是训练出一个更强大的CLIP Video Encoder。微调阶段就是用Transformer的Seq2seq架构，以CLIP video特征作为输入来训练，其中Decoder用Uni-VL(2)的Caption Generation任务的Decoder的权重进行初始化。</p><h2 id="Video-Text匹配预训练"><a href="#Video-Text匹配预训练" class="headerlink" title="Video-Text匹配预训练"></a>Video-Text匹配预训练</h2><p>这一部分被作者叫做video-text matching network (VTM)，本文使用了TSN的帧取样方法，K是超参数，作者在之后有对比实验，并且分成K份后从每份里只抽1帧。</p><blockquote><p><strong>TSN sampling</strong> (3)</p><p>假设原视频是<strong>V</strong>，现在把V分成K份（原文K=3）得到{S<del>1</del> ，S<del>2</del>，S<del>3</del>}，然后又从S<del>k</del>中随机采样n帧(令n=1)，得到snippets：{T<del>1</del> ，T<del>2</del>，T<del>3</del>}。</p></blockquote><p>训练完全仿照CLIP4Clip，Loss使用<strong>symmetric cross entropy loss</strong></p><p>训练方式是在一个Batch内进行匹配，一个text对所有video进行相似度计算，然后能得出匹配的概率分布，同时也有真实分布，即输入的pair是1，batch内构成的其他pair是0，t2v同理。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102140700.png" alt="symmetric cross entropy loss"></p><p><strong>注意这个loss和<code>Symmetric Cross Entropy for Robust Learning with Noisy Labels, ICCV2019</code>提出的loss同名，但不是同一个loss！</strong></p><h2 id="Video-Captioning训练"><a href="#Video-Captioning训练" class="headerlink" title="Video Captioning训练"></a>Video Captioning训练</h2><p>文章使用了Uni-VL的部分权重，本文使用的是1层的Transformer Encoder和3层12头768的Transformer Decoder。（Decoder还好，但是暂时没懂这篇论文加载的是Uni-VL哪里的Encoder）</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102144107.png" alt="UNI-VL"></p><h2 id="Ensemble-strategy"><a href="#Ensemble-strategy" class="headerlink" title="Ensemble strategy"></a>Ensemble strategy</h2><p>文章训练出了多个模型来集成学习，多个模型之间通过voting来决定最终输出，而每个模型的权重由一个综合的metric来决定。将METEOR、BLEU等metric归一化后取平均就是综合metric。通过统计哪个模型更接近真实值，哪个模型更不接近可以得出importance score，就是每个模型的权重。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102190016.png" alt="METRIC overall"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102190205.png" alt="importance score"></p><h2 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211102190435.png" alt="结果"></p><p>在MSR-VTT上的效果绝对SOTA了，之前没有论文METEOR超过30，去掉Ensemble也有31.2了，而且这还只是单模态的使用。</p><blockquote><p>参考文献</p><ol><li><code>Clip4clip: An empirical study of clip for end to end video clip retrieval</code></li><li><code>Univl: A unified video and language pre-training model for multimodal understanding and generation</code></li><li><code>Temporal Segment Networks: Towards Good Practices for Deep Action Recognition</code></li></ol></blockquote>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>CLIP4Caption</tag>
      
      <tag>Video Captioning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Matplotlib</title>
    <link href="/2021/10/29/Python%20matplotlib%E5%B8%B8%E7%94%A8/"/>
    <url>/2021/10/29/Python%20matplotlib%E5%B8%B8%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Matplotlib"><a href="#Python-Matplotlib" class="headerlink" title="Python Matplotlib"></a>Python Matplotlib</h1><p>[TOC]</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>Figure</strong>是一个Matplotlib窗口显示的图的整体概念，就是最大的单位；一个Figure可以包含多个<strong>Axes</strong>子图，Axes是一幅图的最小单位，使用<code>plt.plot()</code>等函数是绘制在Axes上而不是figure上。</p><p>对于一个Axes有下图这些元素，其中注意坐标轴是<code>axis</code>，容易和<code>Axes</code>弄混，两个都翻译成“轴”。</p><p><strong>Matplotlib</strong>有两种使用方式，一种是面向对象的方式，另一种是MATLAB风格的基于状态的方式，按道理在Python中应该多使用面向对象的方式，但是实际上大家都习惯混着用。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211201154523.png"></p><h2 id="面向对象的基本使用方式"><a href="#面向对象的基本使用方式" class="headerlink" title="面向对象的基本使用方式"></a>面向对象的基本使用方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用plt.subplots()创建figure和ax，假如用这个创建多子图的figure则会返回ax数组</span><br>fig, ax = plt.subplots()<br><span class="hljs-comment"># 绘图是在axes上绘图，不是在figure上</span><br><span class="hljs-comment"># 在一个axes上可以叠加多个绘制</span><br>ax.plot([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br>ax.plot([<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">&#x27;r&#x27;</span>)<br><span class="hljs-comment"># 绘制完之后保存的是figure</span><br>fig.savefig(<span class="hljs-string">&#x27;example.png&#x27;</span>)<br><span class="hljs-comment"># 绘制完之后展示figure</span><br>fig.show()<br></code></pre></td></tr></table></figure><h2 id="面向状态的基本使用方式"><a href="#面向状态的基本使用方式" class="headerlink" title="面向状态的基本使用方式"></a>面向状态的基本使用方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.plot([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>plt.ylabel(<span class="hljs-string">&#x27;some numbers&#x27;</span>)<br>plt.savefig(<span class="hljs-string">&#x27;example.png&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><blockquote><p>参考文献：</p><p><a href="https://matplotlib.org/stable/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py">Usage Guide — Matplotlib 3.5.0 documentation</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Matplotlib</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Argparse</title>
    <link href="/2021/10/28/Python%20argparse/"/>
    <url>/2021/10/28/Python%20argparse/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Argparse"><a href="#Python-Argparse" class="headerlink" title="Python Argparse"></a>Python Argparse</h1><p>Python的Argparse库是一个内置的用来获取<strong>命令行输入参数</strong>的库。简单来说就是解析下面这条语句中python main.py后面这些参数的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python main.py  -v xxxx -m<br></code></pre></td></tr></table></figure><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>首先初始化实例，然后对实例添加参数选项，最后解析成对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">parser = argparse.ArgumentParser()<br>parser.add_argument(...)<br>args = parser.parse_args()<br><br><span class="hljs-comment"># 获取参数</span><br>args.参数名<br></code></pre></td></tr></table></figure><h3 id="添加普通参数"><a href="#添加普通参数" class="headerlink" title="添加普通参数"></a>添加普通参数</h3><p>普通参数就是一个key一个value，最普通的参数类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&quot;-v&quot;</span>, <span class="hljs-string">&quot;--video&quot;</span>,          <span class="hljs-comment"># 一个参数key可以有两个名字</span><br>                    <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>,                 <span class="hljs-comment"># 类型可以是int或者str</span><br>                    required=<span class="hljs-literal">True</span>,            <span class="hljs-comment"># 是否为必选参数</span><br>                    default=<span class="hljs-string">&quot;./video1.npy&quot;</span>,   <span class="hljs-comment"># 假如非必选，默认值是</span><br>                    <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;帮助文本&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="无值参数"><a href="#无值参数" class="headerlink" title="无值参数"></a>无值参数</h3><p>可以没有value的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&quot;-m&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>)<br><span class="hljs-comment"># 假如输入有参数则会被解析为True，否则False</span><br>args.m == <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><h3 id="固定值范围参数"><a href="#固定值范围参数" class="headerlink" title="固定值范围参数"></a>固定值范围参数</h3><p>就是value必须从几个选项中选择一个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&quot;--feat&quot;</span>, choices=[<span class="hljs-string">&quot;resnet&quot;</span>, <span class="hljs-string">&quot;vgg&quot;</span>])<br><span class="hljs-comment"># 只能 --feat resnet 或者 --feat vgg</span><br></code></pre></td></tr></table></figure><h3 id="多值参数"><a href="#多值参数" class="headerlink" title="多值参数"></a>多值参数</h3><p>value可以是多个值，解析结果为列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--foo&#x27;</span>, nargs=<span class="hljs-string">&#x27;*&#x27;</span>)  <span class="hljs-comment"># 传递多个参数，可为0</span><br>parser.add_argument(<span class="hljs-string">&#x27;--foo&#x27;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>)  <span class="hljs-comment"># 至少给这个key传递一个参数</span><br></code></pre></td></tr></table></figure><h3 id="互斥参数"><a href="#互斥参数" class="headerlink" title="互斥参数"></a>互斥参数</h3><p>就是在某个组内的参数不允许同时出现两个及以上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">group = parser.add_mutually_exclusive_group()<br>group.add_argument(<span class="hljs-string">&quot;-a&quot;</span>)<br>group.add_argument(<span class="hljs-string">&quot;-b&quot;</span>)<br></code></pre></td></tr></table></figure><blockquote><p>参考文献</p><p><a href="https://docs.python.org/3/library/argparse.html">argparse — Parser for command-line options, arguments and sub-commands — Python 3.10.0 documentation</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>argparse</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch DDP多卡训练</title>
    <link href="/2021/10/25/Pytorch%20DDP/"/>
    <url>/2021/10/25/Pytorch%20DDP/</url>
    
    <content type="html"><![CDATA[<h1 id="Pytorch-DDP多卡训练"><a href="#Pytorch-DDP多卡训练" class="headerlink" title="Pytorch DDP多卡训练"></a>Pytorch DDP多卡训练</h1><p>DDP指的是DistributedDataParallel，即支持多机多卡的Pytorch官方库，位于<code>torch.distributed</code>中。</p><p>本文简单介绍使用DDP进行<strong>单机多卡</strong>训练的步骤。</p><h2 id="1-开头导入库、获取local-rank、初始化backend"><a href="#1-开头导入库、获取local-rank、初始化backend" class="headerlink" title="1. 开头导入库、获取local_rank、初始化backend"></a>1. 开头导入库、获取local_rank、初始化backend</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><br><span class="hljs-comment"># 有的用parser获取LOCAL_RANK的已经过时了</span><br>local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>]) <br>torch.cuda.set_device(local_rank)<br>dist.init_process_group(backend=<span class="hljs-string">&#x27;nccl&#x27;</span>)  <span class="hljs-comment"># 一般使用的后端为nccl</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, local_rank)<br></code></pre></td></tr></table></figure><h2 id="2-初始化DDP模型"><a href="#2-初始化DDP模型" class="headerlink" title="2. 初始化DDP模型"></a>2. 初始化DDP模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">model = YourModel().to(device)  <span class="hljs-comment"># 要在把模型放进GPU之后再DDP</span><br>model = DDP(model, device_ids=[local_rank], output_device=local_rank)<br></code></pre></td></tr></table></figure><h2 id="3-数据处理"><a href="#3-数据处理" class="headerlink" title="3. 数据处理"></a>3. 数据处理</h2><p>使用DDP的batchsize是单张卡上的batchsize，假如你用一张卡训练的batchsize是64，然后想分散在四张卡上，那么batchsize应该设置成16</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">train_iter = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>)<br>train_sampler = torch.utils.data.distributed.DistributedSampler(train_iter)<br>train_loader = torch.utils.data.DataLoader(train_iter, batch_size=batch_size, sampler=train_sampler)  <span class="hljs-comment"># 注意sampler！</span><br><br><span class="hljs-comment"># 在epoch中</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(xx):<br>    trainloader.sampler.set_epoch(epoch)  <span class="hljs-comment"># 注意set_epoch</span><br>    <span class="hljs-keyword">for</span> xxx <span class="hljs-keyword">in</span> train_loader:<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><h2 id="4-模型保存"><a href="#4-模型保存" class="headerlink" title="4. 模型保存"></a>4. 模型保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> dist.get_rank() == <span class="hljs-number">0</span>:  <span class="hljs-comment"># 先判断是主卡，免得所有卡都保存一次</span><br>    torch.save(model.module, <span class="hljs-string">&quot;saved_model.pth&quot;</span>)  <span class="hljs-comment"># 保存的是DDP.module</span><br></code></pre></td></tr></table></figure><h2 id="5-程序运行"><a href="#5-程序运行" class="headerlink" title="5. 程序运行"></a>5. 程序运行</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> nproc_per_node就是使用多少张卡</span><br><span class="hljs-meta">#</span><span class="bash"> 可使用来选择多卡机器上的某几张卡CUDA_VISIBLE_DEVICES=4,5,6,7</span><br>python -m torch.distributed.launch --nproc_per_node 8 main.py<br></code></pre></td></tr></table></figure><h2 id="6-使用Pytorch推荐的spawn方式"><a href="#6-使用Pytorch推荐的spawn方式" class="headerlink" title="*6. 使用Pytorch推荐的spawn方式"></a>*6. 使用Pytorch推荐的spawn方式</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">demo_fn</span>(<span class="hljs-params">rank, world_size</span>):</span>  <span class="hljs-comment"># 两个参数，第一个参数一定是rank</span><br>    dist.init_process_group(<span class="hljs-string">&quot;nccl&quot;</span>, rank=rank, world_size=world_size)<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">import</span> torch.multiprocessing <span class="hljs-keyword">as</span> mp<br>mp.spawn(demo_fn,<br>         args=(world_size,), <span class="hljs-comment"># 传参给demo_fn，调用demo_fn的时候还会有一个参数表示rank</span><br>         nprocs=world_size,  <span class="hljs-comment"># 用多少卡</span><br>         join=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><blockquote><p>参考文献</p><p>[<a href="https://zhuanlan.zhihu.com/p/178402798">原创][深度][PyTorch] DDP系列第一篇：入门教程 - 知乎 (zhihu.com)</a></p><p><a href="https://pytorch.org/docs/stable/multiprocessing.html#torch.multiprocessing.spawn">Multiprocessing package - torch.multiprocessing — PyTorch 1.10.0 documentation</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
      <tag>DDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Video Captioning任务 Transformer方向小综述</title>
    <link href="/2021/10/25/Video%20Captioning%E4%BB%BB%E5%8A%A1%20Transformer%E6%96%B9%E5%90%91%E5%B0%8F%E7%BB%BC%E8%BF%B0/"/>
    <url>/2021/10/25/Video%20Captioning%E4%BB%BB%E5%8A%A1%20Transformer%E6%96%B9%E5%90%91%E5%B0%8F%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Video-Captioning任务-Transformer方向小综述"><a href="#Video-Captioning任务-Transformer方向小综述" class="headerlink" title="Video Captioning任务 Transformer方向小综述"></a>Video Captioning任务 Transformer方向小综述</h1><p>[TOC]</p><h2 id="涉及的论文"><a href="#涉及的论文" class="headerlink" title="涉及的论文"></a>涉及的论文</h2><ol><li><code>TVT: Two-View Transformer Network for Video Captioning</code></li><li><code>A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer</code></li><li><code>SBAT: Video Captioning with Sparse Boundary-Aware Transformer</code></li><li><code>Multi-modal Dense Video Captioning</code></li><li><code>iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering</code></li><li><code>ActBERT: Learning Global-Local Video-Text Representations</code></li><li><code>Multi-modal Transformer for Video Retrieval</code></li><li><code>Reconstruction network for video captioning</code></li><li><code>Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</code></li><li><code>CLIP4Caption: CLIP for Video Caption</code></li></ol><h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><p>图来自文献1，基于Transformer的Video Captioning任务基本都是这种模式，可以叫做<code>Vanilla Transformer</code>、<code>Base Model architecture</code>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026135703.png" alt="Baseline"></p><h2 id="多模态特征融合"><a href="#多模态特征融合" class="headerlink" title="多模态特征融合"></a>多模态特征融合</h2><p>本任务使用的多模态特征包括rgb(image, frame, 不含时序信息)、motion(动作)、object(目标检测)、voice(音频)、speech(音频中人说的话)。其中RGB必备，还有很多选择motion和voice的。</p><p>文献1，2，3都使用了多种模态的特征，本节对于特征的融合进行归纳总结。</p><h3 id="文献1-TVT-Attentive-fusion-block"><a href="#文献1-TVT-Attentive-fusion-block" class="headerlink" title="文献1 TVT Attentive-fusion block"></a>文献1 TVT Attentive-fusion block</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026140703.png" alt="Attentive-fusion block"></p><p>文献1对多种特征进行独立的Transformer encode，得到的输出是图中红色的frame encoder output和motion encoder output，它对Transformer decoder的中间那个SA层进行了改进。</p><p>图中3个SA层的<strong>Q</strong>都是和Baseline的Caption那一路的特征，先分配好frame的注意力，同时分配好motion的注意力，之后在时间轴堆叠，再分配好堆叠后的注意力。</p><h3 id="文献2-Bi-modal-Transformer"><a href="#文献2-Bi-modal-Transformer" class="headerlink" title="文献2 Bi-modal Transformer"></a>文献2 Bi-modal Transformer</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026141348.png" alt="Bi-modal Transformer"></p><p>这篇论文任务其实是Dense Video Captioning，但是去掉Proposal Generator也是一个Video Captioning的模型。它不仅在Decoder进行了特征融合，还在Encoder进行特类似的特征融合。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026141541.png" alt="Encoder"></p><p>编码阶段如上图，每一个Encoder层进行完Baseline的SA层后，再进行一个交叉的Bi-Modal Attention，然后Feed forward。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026141723.png" alt="Decoder"></p><p>解码阶段如上图，Baseline的中间SA层也改成类似的Bi-Modal Attention，然后Bridge是直接用全连接层把concat起来的特征降维。</p><p><strong>解码阶段模态融合方法和文献1的区别就是concat后的张量用SA还是用全连来降维</strong></p><h3 id="文献3-SBAT-Cross-Modal"><a href="#文献3-SBAT-Cross-Modal" class="headerlink" title="文献3 SBAT Cross-Modal"></a>文献3 SBAT Cross-Modal</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026142223.png" alt="SBAT"></p><p>这篇论文是只在Encoder上做了特征融合，用的类似文献2的方法，但是在一个Encoder层的第一个SA层后又加了个Feed forward，参数更多了。</p><h3 id="文献4-MDVC-amp-文献5-iPerceive"><a href="#文献4-MDVC-amp-文献5-iPerceive" class="headerlink" title="文献4 MDVC &amp; 文献5 iPerceive"></a>文献4 MDVC &amp; 文献5 iPerceive</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026142656.png" alt="MDVC"></p><p>和文献2是同一个作者，这是更早的文章。算是直接train出3个Transformer，然后在最后全连决策的时候进行特征融合。文献5的方法和这个几乎一模一样。</p><h3 id="文献6-ActBERT"><a href="#文献6-ActBERT" class="headerlink" title="文献6 ActBERT"></a>文献6 ActBERT</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026155723.png" alt="ActBERT"></p><p>这种特征融合就很迷惑了……还没看懂。</p><p>文章说这种方法对于$\omega$、$\alpha$和$r$三种模态是不相等的。$\omega$的KV一部分来源于本身，另一部分来源于用$\alpha$和$r$进行SA的结果，两部分特征用全连降维。$r$的KV和$\omega$一样。但是$\alpha$的就很奇怪了，只融合了$\omega$的特征？</p><h3 id="文献7-MMT"><a href="#文献7-MMT" class="headerlink" title="文献7 MMT"></a>文献7 MMT</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211026160854.png" alt="MMT"></p><p>这种特征融合方法解决了文献2、3中方法不能拓展到三个及以上特征的问题，但是会导致时间维度较大。</p><p>这里就是先把多种特征先弄成同一特征维（时间维可不同），然后加上时序信息的Temporal embeddings和区分不同特征的expert embeddings，文章还给每一种特征增加了一个agg特征，这是对每一种特征的时序进行pooling得到的Global信息。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在Encoder的特征融合中，文献2、3都没有做到融合第三种特征，因为使用三种特征后会出现六路encoder输出。</p><p>在Decoder的特征融合中，方法都类似，区别是用全连或者SA降维。</p><h1 id="榜单"><a href="#榜单" class="headerlink" title="榜单"></a>榜单</h1><h2 id="MSR-VTT"><a href="#MSR-VTT" class="headerlink" title="MSR-VTT"></a>MSR-VTT</h2><table><thead><tr><th>方法</th><th>METEOR</th><th>ROUGH</th><th>CIDEr</th><th>Bleu@4</th></tr></thead><tbody><tr><td>SBAT(3)</td><td>28.9</td><td>61.5</td><td>51.6</td><td>42.9</td></tr><tr><td>att-TVT(N+I+V)(1)</td><td>28.2</td><td>61.1</td><td>48.5</td><td>42.5</td></tr><tr><td>att-TVT(N+I)(1)</td><td>27.9</td><td>59.6</td><td>47.7</td><td>40.1</td></tr><tr><td>RecNet(8)</td><td>26.6</td><td>59.3</td><td>42.7</td><td>39.1</td></tr><tr><td>GRU-EVE(9)</td><td>28.4</td><td>60.7</td><td>48.1</td><td>38.3</td></tr><tr><td>CLIP4Caption(10)</td><td>30.7</td><td>63.7</td><td>57.7</td><td>46.1</td></tr><tr><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h2 id="VATEX"><a href="#VATEX" class="headerlink" title="VATEX"></a>VATEX</h2>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>Video Captioning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Type Hints</title>
    <link href="/2021/10/24/Python%20type%20hint/"/>
    <url>/2021/10/24/Python%20type%20hint/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Type-Hints"><a href="#Python-Type-Hints" class="headerlink" title="Python Type Hints"></a>Python Type Hints</h1><p>Python是一门不注重类型转换的语言，不像C++那样需要进行显式类型声明，这样在程序编写的过程中或许会更方便，但是在debug的时候就可能会很麻烦了，所以Python在3.5版本中引入了Type Hints。</p><p>Type Hints指的是在Python中显式提示某个变量的类型，可以翻译为<strong>类型提示</strong>，假如用错了类型，IDE就会有提示，能够让开发者更加方便地找到错误。</p><p>Type Hints的写法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">变量名: 类型  <span class="hljs-comment"># 1</span><br>变量名: 类型 = 值  <span class="hljs-comment"># 2</span><br><span class="hljs-comment"># 例子：</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">x: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span>, y: <span class="hljs-built_in">str</span> = <span class="hljs-number">2</span></span>):</span><br>    <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><p>对于类型，可以是基本类型、自定义类型、容器类型、可选……，可见下表</p><table><thead><tr><th>类型</th><th>说明</th><th>备注</th></tr></thead><tbody><tr><td><code>int</code>,<code>str</code>,<code>list</code>,<code>dict</code></td><td>可以直接使用的基本类型</td><td></td></tr><tr><td><code>List[int]</code>,<code>Tuple[str]</code></td><td>指定列表内元素的类型</td><td>要from typing import</td></tr><tr><td><code>Dict[str, ...]</code></td><td>指定字典键值对的类型</td><td>要from typing import</td></tr><tr><td><code>*args: str</code>,<code>**kwargs: str</code></td><td>规定可变参数是固定类型</td><td></td></tr><tr><td><code>Union[int, str, bool]</code></td><td>接受某几种类型</td><td>要from typing import</td></tr><tr><td><code>Optional[int]</code></td><td>接受某种类型或者None</td><td>要from typing import</td></tr><tr><td><code>Any</code></td><td>接受所有类型</td><td>要from typing import</td></tr><tr><td><code>Callable[[参数类型], 返回类型]</code></td><td>接受可调用类型</td><td>要from typing import</td></tr></tbody></table><p>假如类型太长了，可以使用别名</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">config: <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>], <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>]] = [...]<br><span class="hljs-comment"># 上面这条语句和下面这条等价</span><br>Config = <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">int</span>], <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">int</span>]]<br>config: Config = [...]<br></code></pre></td></tr></table></figure><blockquote><p>参考文献</p><p><a href="https://mp.weixin.qq.com/s/CbZYOkaY0z1Brw4W5coG3w">Python Type Hints 从入门到实践 (qq.com)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Type Hints</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何构建数据集？大佬们都这么干的……</title>
    <link href="/2021/10/22/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E4%B8%8E%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/"/>
    <url>/2021/10/22/%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E4%B8%8E%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="如何构建数据集？大佬们都这么干的……"><a href="#如何构建数据集？大佬们都这么干的……" class="headerlink" title="如何构建数据集？大佬们都这么干的……"></a>如何构建数据集？大佬们都这么干的……</h1><p>当下深度学习对数据的要求越来越高，更好的数据往往就能训练出更好的模型，为了得到更好的数据，各路大佬们都绞尽脑汁，本文将介绍5种不同的构建数据集的方法。</p><h2 id="从最普通的开始吧——MNIST"><a href="#从最普通的开始吧——MNIST" class="headerlink" title="从最普通的开始吧——MNIST"></a>从最普通的开始吧——MNIST</h2><p><strong>MNIST</strong>数据集由2018年图灵奖得主、CNN之父——<strong>Yann LeCun</strong>大佬收集得到，包含数万个20x20的手写数字图片组成，一般用在机器学习识别手写数字的任务上，学习卷积神经网络的人大部分都从这个数据集入门的。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023091413.png" alt="来源 Tensorflow"></p><p>LeCun大佬收集数据的方式很简单，先是从500位高中生中收集到了58,527个图像，这就是SD-1数据集，但是这样数据来源不够随机，所以后面又从人口普查局的员工中抽选了250个人构建了SD-3数据集，把这两个数据集混合之后，构成了MNIST数据集。虽然没有特别说明，但是人口普查局的员工大概是分布在各个地方的，而且混合了成人和高中生的数据集也更加精确。</p><div class="note note-success">            <p>构建数据集方法1 Get√:+1:：</p><p>找一堆工具人创造数据、标记数据。</p><p>优点：想要啥就有啥</p><p>缺点：假如要获取海量数据，成本就非常非常非常高</p>          </div><h2 id="自动化获取数据——网络爬虫"><a href="#自动化获取数据——网络爬虫" class="headerlink" title="自动化获取数据——网络爬虫"></a>自动化获取数据——网络爬虫</h2><p>目前的大规模数据集基本都离不开网络爬虫，通过网络爬虫，可以自动化获取存在于互联网上的海量数据，比如用于图像识别的<strong>ImageNet</strong>数据集、用于视频描述的<strong>MSR-VTT</strong>数据集、用于动作识别的<strong>Kinetics</strong>数据集等等。</p><p>包含视频文件的Kinetics和MSR-VTT数据集都是使用网络爬虫在YouTube上搜索关键字爬取到视频数据的，假如你也想用这种方式构建自己的数据集，可以使用<a href="https://github.com/ytdl-org/youtube-dl">这个工具</a>或者<a href="https://github.com/MrS0m30n3/youtube-dl-gui">这个带界面的工具</a>。</p><div class="note note-success">            <p>构建数据集方法2 Get√:+1:：</p><p>用网络爬虫获取数据，但是还是得找一堆工具人标记数据。</p><p>优点：能获取到很多数据</p><p>缺点：标注成本很高</p>          </div><h2 id="找不到那么多工具人——那就众包吧"><a href="#找不到那么多工具人——那就众包吧" class="headerlink" title="找不到那么多工具人——那就众包吧"></a>找不到那么多工具人——那就众包吧</h2><p>众包指的是一个公司或机构把过去由员工执行的工作任务，以自由自愿的形式外包给非特定的（而且通常是大型的）大众志愿者的做法。Amazon Mechanical Tuckers (AMT)是目前很多人使用的众包平台，发布者把任务发布在平台上，想要做这项工作的人就能接受任务并获取报酬，与外包不同，众包的特点是发布的任务可能由成百上千个来自全球各地的人完成。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023103735.png" alt="Amazon Mechanical Turk"></p><p><strong>ImageNet</strong>数据集就是由AMT平台上的来自167个国家的四万九千个人完成标注的。为了保证数据的可信度，同一张图片可能由四五个人进行标注，然后选出最多人选择的那个标签。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023104035.jpeg" alt="CVPR 2017 李飞飞PPT"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023104725.png" alt="AMT工作界面"></p><div class="note note-success">            <p>构建数据集方法3 Get√:+1:：</p><p>使用“工具人“平台来对数据进行标注。</p><p>优点：Money is all you need</p><p>缺点：No money</p>          </div><h2 id="我不想花那么多钱——那就白嫖！"><a href="#我不想花那么多钱——那就白嫖！" class="headerlink" title="我不想花那么多钱——那就白嫖！"></a>我不想花那么多钱——那就白嫖！</h2><p><strong>reCAPTCHA</strong>是由卡内基梅隆大学所开发的验证码系统，这个系统不仅能为网站抵挡住一部分的网络爬虫，同时也能白嫖访问用户的智力。</p><p>刚开始，reCAPTCHA是这样的，用户被要求输入两个单词，其中一个单词是能被计算机识别的（即知道答案的），另一个单词是无法正确识别的（即不知道答案的），假如访客答对了已知答案的那个单词，那么就能够判断访客不是爬虫，并且也能基本判断访客对另一个单词的回答也是正确的，这样就获得了一个新图片的标注。使用这种白嫖方法，reCAPTCHA成功把《纽约时报》几十年的纸质资料数字化。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023105305.jpg" alt="Modern-captcha"></p><p>Google看到了这个方法，于是在2009年把reCAPTCHA收购了，现在大家在上网时时常能够看见下面这种验证码，这就是Google改进之后的reCAPTCHA，可以让你对图像识别、图像分割、语音识别所需要的数据进行标注，同时，改进后的评分算法也能更加精准地判断访客是爬虫还是真人，以避免爬虫带来的标注噪声。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023105930.jpeg"></div><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023105942.png"></div></div></div><div class="note note-success">            <p>构建数据集方法4 Get√:+1:：</p><p>用验证码白嫖标注，不用花钱。</p><p>优点：成本极低，并且会有很多很多人来标注。</p><p>缺点：只有用户流量大的公司才能使用这种方法，并且始终存在噪声。</p>          </div><h2 id="我甚至都不想写爬虫——自动生成数据集"><a href="#我甚至都不想写爬虫——自动生成数据集" class="headerlink" title="我甚至都不想写爬虫——自动生成数据集"></a>我甚至都不想写爬虫——自动生成数据集</h2><p>现在出现了一种”合成数据集“，这种数据集里面的数据是通过计算机程序生成的，生成方式可以是3D建模、图片拼凑，还可以使用已有的深度学习网络生成新的数据集图片。</p><p><strong>MPI-Sintel</strong>数据集是由华盛顿大学和佐治亚理工学院的研究人员通过截取3D动画电影<strong>《寻龙记》（Sintel）</strong>不同场景而制作的数据集，相比较爬虫爬取到的数据，这种计算机创作出来的视频数据能够具有更清晰的画面（YouTube上用户上传的视频质量不一），并且标注也非常容易获得，通过不同的3D渲染还能增加/去除一些Shader上的噪声。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023112740.png" alt="Sintel数据集"></p><p>而<strong>FlyingChairs</strong>数据集更进一步，它在一些背景图上加入几张奇奇怪怪的运动3D椅子，并以此来得到视频—光流图数据，用来训练一些预测光流的神经网络，后面他们还让加入的东西不局限于椅子，构建了一个FlyingThings3D数据集。这种生成数据的方式基本没有版权或者隐私上的问题，但是由于生成的数据与实际数据是有差别的，所以依此训练出的模型也有可能是过拟合的，需要研究人员进行优化或者调整。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211023112950.png" alt="FlyingChairs"></p><div class="note note-success">            <p>构建数据集方法5 Get√:+1:：</p><p>直接建模生成数据集和标注。</p><p>优点：避免了数据的隐私问题和版权问题，数据集规模可以随意调整，并且想要什么就能做什么，对于比较难获取的数据也可以直接生成，噪声方差也能调整。</p><p>缺点：生成数据集与真实情况可能存在差异，导致模型学习到偏差（bias），</p>          </div><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th>方法</th><th>举例</th><th>优点</th><th>不足</th></tr></thead><tbody><tr><td>用工具人创造数据、标记数据。</td><td>MNIST</td><td>想要啥就有啥</td><td>假如要获取海量数据，成本就非常非常非常高</td></tr><tr><td>用网络爬虫获取数据</td><td>ImageNet MSR-VTT</td><td>能获取到很多数据</td><td>还是得找一堆工具人标记数据，标注成本高</td></tr><tr><td>使用众包平台来对数据进行标注。</td><td>ImageNet MSR-VTT</td><td>Money is all you need</td><td>No money</td></tr><tr><td>用验证码白嫖标注</td><td>reCAPTCHA</td><td>成本极低，并且会有很多很多人来标注。</td><td>只有用户流量大的公司才能使用这种方法，存在噪声。</td></tr><tr><td>直接建模生成数据集和标注</td><td>MPI-Sintel FlyingChairs</td><td>避免了数据的隐私问题和版权问题，数据集规模可以随意调整，对于比较难获取的数据也可以直接生成，噪声方差也能调整。</td><td>生成数据集与真实情况可能存在差异</td></tr></tbody></table><blockquote><p>参考文献：</p><p><a href="http://yann.lecun.com/exdb/mnist/">MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges</a></p><p><a href="https://zh.wikipedia.org/wiki/ReCAPTCHA">reCAPTCHA - 维基百科，自由的百科全书 (wikipedia.org)</a></p><p><a href="https://zhuanlan.zhihu.com/p/248351130">什么是合成数据？ - 知乎 (zhihu.com)</a></p><p>FlowNet: Learning Optical Flow with Convolutional Networks</p><p>A Naturalistic Open Source Movie for Optical Flow Evaluation</p><p><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html">Computer Vision Group, Freiburg (uni-freiburg.de)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>技术杂文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
      <tag>数据获取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Video Swin Transformer</title>
    <link href="/2021/10/22/Video%20Swin%20Transformer/"/>
    <url>/2021/10/22/Video%20Swin%20Transformer/</url>
    
    <content type="html"><![CDATA[<h1 id="Video-Swin-Transformer"><a href="#Video-Swin-Transformer" class="headerlink" title="Video Swin Transformer"></a>Video Swin Transformer</h1><p>[TOC]</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Swin Transformer分为两篇论文，一篇是21年5月的<code>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</code>，另一篇是21年6月的<code>Video Swin Transformer</code>。其中<strong>Swin Transformer</strong>是对ViT的改进，使用分层的Transformer和偏移窗（shifted window）来提升效果并节约算力。<strong>Video Swin Transformer</strong>则是像3D-CNN对于CNN的改进一样，Video Swin Transformer将这种方法拓展到了视频上，为同一个团队研究成果。</p><h2 id="模型基本结构"><a href="#模型基本结构" class="headerlink" title="模型基本结构"></a>模型基本结构</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806101614.png" alt="Swin Transformer"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806134847.png" alt="Video Swin Transformer"></p><p>第一张图是处理图像的Swin Transformer，第二行图是处理视频的Video Swin Transformer，以图像为例：</p><ul><li>初始的$H \times W \times 3$是RGB图片三通道，经过<strong>Patch Partition</strong>之后，每16个像素合成一个<strong>Patch</strong>，此时维度变成$\frac{H}{4} \times \frac{W}{4} \times 48$，</li><li>再经过一个<strong>全连（Linear Embedding）</strong>控制通道的维度为可变值C，此时维度为$\frac{H}{4} \times \frac{W}{4} \times C$。</li><li>之后每个Stage还会有个<strong>Patch Merging</strong>层，将4个Patch合成一个新的Patch，所以分辨率又下降了$2\times 2$，再进行全连来控制通道维度为$2C$，此时维度变为$\frac{H}{8} \times \frac{W}{8} \times 2C$​​。</li></ul><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211022171846.png"></div><div class="group-image-wrap"><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211022171851.png"></div></div></div><blockquote><p>这一步是Hierarchical的体现，模仿的是ResNet和其他CNN，不断缩小图像并加深channel。如上图，好处就是比较ViT能够对更细微的Local特征进行学习，并能减少需要的算力。</p></blockquote><h2 id="Swin-Transformer-block"><a href="#Swin-Transformer-block" class="headerlink" title="Swin Transformer block"></a>Swin Transformer block</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211022171858.png" alt="block"></p><p>这就是一个Swin Transformer Block，由LN（Layer Normalization）、MLP（多层感知器）、MSA（多头self-attention）组成，其中MSA有window和shifted-window两种。</p><p><strong>LN就是与batch无关的标准化</strong>，用均值和标准方差对数据进行标准化处理，如下图。<a href="https://blog.csdn.net/Xidian185/article/details/105542121">Transformer代码详解与项目实战之Layer Normalization_Xidian185的专栏-CSDN博客</a></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210912160410.jpeg" alt="标准化"></p><p><strong>W-MSA</strong>是在一个window里的自注意力模块，图中每个灰色小方格都是由若干像素组成的，用来计算self-attention的最小处理单位。在W-MSA里可以通过指定window大小来在小范围进行self-attention。两个MSA的不同之处在于有没有shifted window，如图。这种shift是将整体往右下循环移动(2, 2)，左上角的4x4就到了中间，右下角的4x4就分到了四个角。虽然window的数量从4变成了9，但是作者在算法上证明了这两种需要算力相同。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211022172033.png" alt="Shifted Window"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210911112942.png" alt="Attention"></p><h2 id="相对位置偏置（relative-position-bias）"><a href="#相对位置偏置（relative-position-bias）" class="headerlink" title="相对位置偏置（relative position bias）"></a>相对位置偏置（relative position bias）</h2><p>self-attention的原始公式是</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210911112842.png" alt="Attention"></p><p>swin-transformer里面改成了这样</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210911112942.png" alt="Attention with bias"></p><p>通过增加一个Bias来体现一个window内不同patch的相对位置（local），类似Transformer里的Positional-Encoding。</p><p>对于二维的swin-transformer，$Q(<em>,dim) @ K^T(dim,</em>) = (<em>,</em>)$​​​​，即结果和dim无关，是原特征的各维度相乘，Attention张量形状为<code>(M*B, num_heads, M*M, M*M)</code>，也就是说，我们需要一个类似的矩阵B。</p><p>下面结合二维Transformer源码来理解，假设$window_size=M=4$​​​。</p><p>首先形成relative_position可学习参数，用0初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># nn.Parameter和tensor差不多，但是会自动认为是可训练参数</span><br><span class="hljs-comment"># 2*Wh-1 * 2*Ww-1, nH 假如window是个4x4的，那么这个参数就是(7*7, nH)矩阵</span><br>self.relative_position_bias_table = nn.Parameter(<br>torch.zeros(<br>(<span class="hljs-number">2</span> * window_size[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>) * (<span class="hljs-number">2</span> * window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>),<br>num_heads))  <br></code></pre></td></tr></table></figure><p>构建每个点的坐标coords，总共16个二维坐标。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># get pair-wise relative position index for each token inside the window</span><br><span class="hljs-comment"># 构建坐标的表格 coords.shape: [2,4,4] 即以左上角为原点的二维坐标</span><br>coords_h = torch.arange(self.window_size[<span class="hljs-number">0</span>])<br>coords_w = torch.arange(self.window_size[<span class="hljs-number">1</span>])<br>coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  <span class="hljs-comment"># 2, Wh, Ww</span><br>coords_flatten = torch.flatten(coords, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 2, Wh*Ww 即[2,16]</span><br></code></pre></td></tr></table></figure><p>获取relative_position_index。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># [2,16,1] - [2,1,16] = [2,16,16]</span><br>relative_coords = coords_flatten[:, :, <span class="hljs-literal">None</span>] - coords_flatten[:, <span class="hljs-literal">None</span>, :]<br><span class="hljs-comment"># 变形-&gt;[16,16,2]</span><br>relative_coords = relative_coords.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).contiguous()<br><br><span class="hljs-comment"># 所有坐标+3，即坐标没负数</span><br>relative_coords[:, :, <span class="hljs-number">0</span>] += self.window_size[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>  <span class="hljs-comment"># shift to start from 0</span><br>relative_coords[:, :, <span class="hljs-number">1</span>] += self.window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span><br><br><span class="hljs-comment"># ？不明白的乘7</span><br>relative_coords[:, :, <span class="hljs-number">0</span>] *= <span class="hljs-number">2</span> * self.window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span><br><span class="hljs-comment"># sum去掉最后一维，即二维坐标转一维</span><br>relative_position_index = relative_coords.<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>)  <span class="hljs-comment"># Wh*Ww, Wh*Ww</span><br>self.register_buffer(<span class="hljs-string">&quot;relative_position_index&quot;</span>, relative_position_index)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210911173444.png" alt="运行结果"></p><p><code>relative_position_index</code>的范围是0~48，即49种数，对应<code>relative_position_bias_table</code>的<code>49,dH</code>。这个table就是相对位置编码，每个数就是偏移量，值为0的和值为1的相对距离就是1，对应着不同的bias。</p><p>在forward中的（部分）代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x, mask=<span class="hljs-literal">None</span></span>):</span><br>       <span class="hljs-comment"># 相对位置偏置 = table[index].view(M*M,M*M,nH)</span><br>       relative_position_bias = self.relative_position_bias_table[<br>self.relative_position_index.view(-<span class="hljs-number">1</span>)]<br>               .view(<br>               self.window_size[<span class="hljs-number">0</span>] * self.window_size[<span class="hljs-number">1</span>],<br>               self.window_size[<span class="hljs-number">0</span>] * self.window_size[<span class="hljs-number">1</span>],-<span class="hljs-number">1</span>)  <span class="hljs-comment"># Wh*Ww,Wh*Ww,nH</span><br>       <span class="hljs-comment"># 变形</span><br>       relative_position_bias = relative_position_bias.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).contiguous()  <span class="hljs-comment"># nH, Wh*Ww, Wh*Ww</span><br>       attn = attn + relative_position_bias.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># (1, num_heads, windowsize, windowsize)</span><br></code></pre></td></tr></table></figure><h2 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211022172515.png"></p><p>作者调出了4种大小的模型。</p><h2 id="Video-Swin-Transformer用Swin-Transformer进行初始化"><a href="#Video-Swin-Transformer用Swin-Transformer进行初始化" class="headerlink" title="Video Swin Transformer用Swin Transformer进行初始化"></a>Video Swin Transformer用Swin Transformer进行初始化</h2><p>略</p><h2 id="最终能得到的"><a href="#最终能得到的" class="headerlink" title="最终能得到的"></a>最终能得到的</h2><h2 id="Video-Swin-Transformer-1"><a href="#Video-Swin-Transformer-1" class="headerlink" title="Video Swin Transformer"></a>Video Swin Transformer</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806134847.png"></p><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>相比于图像的，多了T轴，Patch等元素也都变成3D的了。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806135138.png"></p><h3 id="shifted-window"><a href="#shifted-window" class="headerlink" title="shifted window"></a>shifted window</h3><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806135501.png"></p><p>token可以看作是最基本的像素，红色透明立方体是窗，为了减少计算量，swin transformer在单独的窗内计算self-attention而不是在整张图。</p><p>通过两种window来链接不同的token，这两种的计算效率经过验证是一样的。</p><h3 id="模型类型"><a href="#模型类型" class="headerlink" title="模型类型"></a>模型类型</h3><p>作者train出了这么几个</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210806135759.png"></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语论文写作</title>
    <link href="/2021/10/16/%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/"/>
    <url>/2021/10/16/%E8%8B%B1%E6%96%87%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="英语论文写作"><a href="#英语论文写作" class="headerlink" title="英语论文写作"></a>英语论文写作</h1><p>[TOC]</p><h2 id="标题的方法"><a href="#标题的方法" class="headerlink" title="标题的方法"></a>标题的方法</h2><p><strong>有什么效果？、吸引读者（把有意思的放上来）、中心明确</strong></p><h2 id="摘要的写法"><a href="#摘要的写法" class="headerlink" title="摘要的写法"></a>摘要的写法</h2><blockquote><p>Attention is all you need 论文摘要</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211016161830.png" alt="image-20211016161830899"></p><p><code>be based on</code>：基于    <code>propose</code>：提出    <code>achieve 28.4 BLEU</code>：取得了score</p><p><code>require less time to train</code>：需要更少的时间训练</p></blockquote><blockquote><p>A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer 论文摘要</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211016162734.png" alt="image-20211016162734511"></p><p><code>exploit</code>：发掘、开采    <code>generalize</code>：推广（就是瞎改人家模型）</p><p><code>capable</code>：be able to    <code>digest</code>：消化，使用特征</p></blockquote><blockquote><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211016164135.png" alt="image-20211016164135568"></p></blockquote><h2 id="Introduction的写法"><a href="#Introduction的写法" class="headerlink" title="Introduction的写法"></a>Introduction的写法</h2><p>近3年文献。</p><p>娓娓道来，把读者思路带偏到自己这里</p><h2 id="i-e-e-g-etc-et-al-的用法"><a href="#i-e-e-g-etc-et-al-的用法" class="headerlink" title="i.e. e.g. etc. et al.的用法"></a>i.e. e.g. etc. et al.的用法</h2><p><code>i.e.</code>：意思是“那就是说，换句话说”，“in other words”。例子：Four phase states (i.e., 0◦, 90◦, 180◦, and 270◦) are realized through the combination of the phase shifter and the array radiation element. 在这里是解释四种状态是哪四种。<code>[ˌaɪˈiː]或者that is</code></p><p><code>e.g.</code>：意思是“举个例子”，“for example”。例子：The evaluation noted that the employee had frequently exhibited irresponsible behavior (e.g., coming to work late, failing to complete projects).在这里是举例什么是irresponsible behavior。<code> [ ,i&#39;dʒi ]或者for example</code></p><p><code>etc.</code>：意思是“等等”，“et cetera”。例子：”We could use cupcakes, cookies, etc.” 不用and，在e.g.后也不用加etc.，指人的时候也不能用etc.，假如etc.后面结束不用加句号，但是别的符号要加。<code> [ˌet ˈsetərə ]</code></p><p><code>et al.</code>：意思是“等人”，“ et alia”。同etc.用法，但是指的是人。 <code> [ˌet ˈæl ]或者and so on</code></p><h2 id="定冠词与不定冠词"><a href="#定冠词与不定冠词" class="headerlink" title="定冠词与不定冠词"></a>定冠词与不定冠词</h2><p><strong>不定冠词：a an；定冠词：the；零冠词：&lt;空&gt;</strong></p><p>参考：<a href="https://www.zhihu.com/question/46825717/answer/652234107"> 英文论文写作有哪些需要注意的细节？ - 知乎 (zhihu.com)</a></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211016104857.jpeg" alt="img"></p><ol><li><p>标题加不加the、a、an都可以</p><p>A Novel Reconfigurable Miniaturized Phase Shifter for 2-D Beam Steering 2-Bit Array Applications</p><p>A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer</p></li><li><p>单数可数名词不能单独出现</p><p>加a an the</p></li><li><p>名词后有修饰短语（介词短语the cat on the desk，定语从句the people who is my brother，非谓语动词the man fighting the dog，同位语，形容词词组）</p></li><li><p>不能单独发音的大写缩略词（NASA，the FBI）</p></li><li><p>地理名词太难了，建议写作的时候现查</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文写作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Self Attention详解</title>
    <link href="/2021/10/04/Self%20Attention/"/>
    <url>/2021/10/04/Self%20Attention/</url>
    
    <content type="html"><![CDATA[<h1 id="Self-Attention详解"><a href="#Self-Attention详解" class="headerlink" title="Self Attention详解"></a>Self Attention详解</h1><p>对于Self-attention的原理进行充分的解释</p><blockquote><p>参考资料</p><p>Google本家论文：<strong>Attention Is All You Need</strong></p><p>Pytorch官方Transformer实现：<a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer">torch.nn.modules.transformer — PyTorch 1.9.1 documentation</a></p><p><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io)</a></p><p><a href="https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853">Transformers Explained Visually (Part 3): Multi-head Attention, deep dive | by Ketan Doshi | Towards Data Science</a></p></blockquote><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>这一块李宏毅老师讲的很好。<a href="https://www.bilibili.com/video/av56239558">李宏毅-Transformer_哔哩哔哩_bilibili</a></p><p>从Seq2Seq的角度来说，深度学习开始用的就是RNN类网络，但是这种做法很难并行计算，并且每个状态传递的信息用的是一个hidden向量。之后有人用CNN代替RNN，CNN的卷积操作可以实行并行计算，但是由于卷积核的大小不能太大（否则计算太复杂），感受野范围受限，要像RNN那样感受到全局信息就要多层CNN卷积，就像VGG那样不断缩小H、W维度，增厚C维度，但是这样计算量还是会提高很多。</p><p>因此，Google想弄出一个既能关照到每个输入的信息，也不需要太多计算的网络。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211004104306.png" alt="CNN与RNN"></p><h2 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h2><p>这块也借用李宏毅老师的PPT，和RNN类似，自注意力也是一个Seq2Seq的模型，输入序列，输出也是序列，可以把内部想象成一个黑箱，SA（Self Attention）的输入和输出与RNN相同。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211004104728.png" alt="RNN与自注意力"></p><p>论文中的公式如下，注意力由三个张量Q、K、V得到，而QKV是由输入张量X作三个相似的矩阵运算得到的。Q代表Query，K代表Key，V代表Value（其中K和V的长度一定要相同，和V可以不同），这是一个类似<strong>查询</strong>的结构：我们用<strong>Q</strong>的每一个值$Q_i$（<strong>Q</strong>是有长度的），去查询每一个$K_i$，然后通过Softmax函数得到注意概率α，再用这个α来重新分配对<strong>V</strong>的注意力。<strong>我们最终要的是（一个参考了V的）崭新的Q（或者是X）</strong><br>$$<br>Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_{model}}})V<br>$$<br><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211015205747.png" alt="QKV的由来"></p><p>数学上，用Query查询Key的过程是Q、K两个矩阵的内积，内积这个操作能够计算两个张量的相似度，余弦相似度的分子就是内积。这个地方的具体解释先挖个坑，总之我们能通过这个乘法操作，把$X\times W$得到的embed维度给消掉，得到一个$S<em>T$的矩阵（如下图，假设Q的长度和KV不一样）。*<em>这个矩阵的每一行就可以看作是Query的某个元素对K的每一个元素的”注意力“。从深度学习的角度，这个注意力得到的方式是对矩阵$W^Q$$W^K$$W^V$的学习。</em></em></p><p>上一段”注意力“打引号是因为这还不是真正的注意力，<strong>注意力的特点是对于T长的张量的每个元素的注意力总和为1</strong>，就像有100块钱给T个人分，每个人分到的钱数的总和就是100，不能多也不能少，<strong>这个操作通过$Softmax$函数实现。</strong>而公式中除以$\sqrt{d_{model}}$的操作是为了归一化，用人话说就是让矩阵的值不要太大。这里的详细解释也挖个坑。假如要对自注意力层进行可视化的话，一般被可视化的就是这个α矩阵。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211015205819.png" alt="公式示意图"></p><p>公式最后一部分与V相乘的操作就很容易理解了，我们要的是新的tgt，所以要通过分配注意力到V上来实现。加入tgt和memory像图中一样是不同的，那么tgt的信息融入在了α矩阵，然后通过最后这个操作结合上memory的信息。</p><h2 id="更进一步-Multi-Head"><a href="#更进一步-Multi-Head" class="headerlink" title="更进一步 Multi Head"></a>更进一步 Multi Head</h2><p>多头注意力就是通过设置多个W来得到多种QKV，然后进行上面的运算，是增加模型复杂度（拟合能力）的一种手段。但是这样就会得到d_head个attention，维度是$S<em>emb</em>d_{head}$，我们可以通过一个全连接层将后两个维度$emb*d_{head}$降维回$emb$。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211015205841.png" alt="多头注意力"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211015205902.jpeg" alt="多“头”注意力"></p><blockquote><p>但是多个头真的能关注到不同的信息吗？</p><p><a href="https://arxiv.org/pdf/1905.09418.pdf">Analyzing Multi-Head Self-Attention:Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned</a>写了可以把几个头斩掉，挖坑以后写。</p><p><a href="https://arxiv.org/pdf/1810.10183.pdf">Multi-Head Attention with Disagreement Regularization</a>写了可以通过正则化让多个头关注不同的地方，挖坑以后写。</p></blockquote><blockquote><h3 id="术语解释"><a href="#术语解释" class="headerlink" title="术语解释"></a>术语解释</h3><p>看文献的时候可能遇到一些术语，专门在这里解释一下</p><ul><li>SA：self attention 自注意力</li><li>MSA：multi-head self attention 多头自注意力</li><li>d_head, d_model：pytorch中分别表示头数和$W$的隐藏维度。要和后面的dim_feedforward区分开。</li><li>tgt，memory：Transformer里面Decoder的self attention层，Q和KV不一样，tgt是Q，memory是KV。</li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>未分类</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>Self-Attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习之梯度累加（Pytorch实现）</title>
    <link href="/2021/10/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E7%B4%AF%E5%8A%A0Pytorch%E5%AE%9E%E7%8E%B0/"/>
    <url>/2021/10/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A2%AF%E5%BA%A6%E7%B4%AF%E5%8A%A0Pytorch%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="深度学习之梯度累加（Pytorch实现）"><a href="#深度学习之梯度累加（Pytorch实现）" class="headerlink" title="深度学习之梯度累加（Pytorch实现）"></a>深度学习之梯度累加（Pytorch实现）</h1><blockquote><p>参考文献</p><p><a href="https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa">What is Gradient Accumulation in Deep Learning? | by Raz Rotenberg | Towards Data Science</a></p><p><a href="https://www.cnblogs.com/sddai/p/14598018.html">梯度累加(Gradient Accumulation) - stardsd - 博客园 (cnblogs.com)</a></p></blockquote><h2 id="梯度累加是什么"><a href="#梯度累加是什么" class="headerlink" title="梯度累加是什么"></a>梯度累加是什么</h2><p>梯度累加就是把一个<strong>大Batch分成小mini-batch</strong>，每个mini-batch分别送模型算loss得到梯度，并进行累加，直到大Batch里所有数据计算完，再梯度下降。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20211003145612.jpg" alt="梯度累加示意图"></p><p>梯度累加就是运行几个step但是不更新模型，在这几个step中，模型的参数不变，也就是假装我们在计算大Batch。</p><h2 id="Pytorch代码示例"><a href="#Pytorch代码示例" class="headerlink" title="Pytorch代码示例"></a>Pytorch代码示例</h2><p>传统训练过程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader):<br>    optimizer.zero_grad()                   <span class="hljs-comment"># 梯度清零</span><br>    outputs = net(inputs)                   <span class="hljs-comment"># 正向传播</span><br>    loss = criterion(outputs, labels)       <span class="hljs-comment"># 计算损失</span><br>    loss.backward()                         <span class="hljs-comment"># 反向传播，计算梯度</span><br>    optimizer.step()                        <span class="hljs-comment"># 更新参数</span><br>    <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % evaluation_steps == <span class="hljs-number">0</span>:<br>        evaluate_model()<br></code></pre></td></tr></table></figure><p>梯度累加</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader):<br>    outputs = net(inputs)                   <span class="hljs-comment"># 正向传播</span><br>    loss = criterion(outputs, labels)       <span class="hljs-comment"># 计算损失函数</span><br>    loss = loss / accumulation_steps        <span class="hljs-comment"># 损失标准化</span><br>    loss.backward()                         <span class="hljs-comment"># 反向传播，计算梯度</span><br>    <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % accumulation_steps == <span class="hljs-number">0</span>:<br>        optimizer.step()                    <span class="hljs-comment"># 更新参数</span><br>        optimizer.zero_grad()               <span class="hljs-comment"># 梯度清零</span><br>        <span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % evaluation_steps == <span class="hljs-number">0</span>:<br>            evaluate_model()<br></code></pre></td></tr></table></figure><p><strong>挖坑：Video Captioning通过梯度累加来加快速度</strong></p><p><strong>实验平台GPU被占了做不了实验填不了坑了哼唧</strong></p>]]></content>
    
    
    <categories>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>Pytorch</tag>
      
      <tag>梯度累加</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux配置Clash</title>
    <link href="/2021/10/03/Linux%E9%85%8D%E7%BD%AEClash/"/>
    <url>/2021/10/03/Linux%E9%85%8D%E7%BD%AEClash/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux配置Clash"><a href="#Linux配置Clash" class="headerlink" title="Linux配置Clash"></a>Linux配置Clash</h1><p><strong>本文参考：</strong></p><p><a href="https://zhuanlan.zhihu.com/p/369344633">Linux下安装&amp;配置Clash以实现代理上网 - 知乎 (zhihu.com)</a></p><p><a href="https://lancellc.gitbook.io/clash/">Introduce - Clash (gitbook.io)</a></p><p>这篇文章用来防止忘记怎么配Clash，干货笔记。</p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><strong>Github Release：</strong><a href="https://github.com/Dreamacro/clash/releases">Releases · Dreamacro/clash (github.com)</a></p><p>从Assets中找到Linux amd64的gz文件，下载下来</p><p>网盘备份：<a href="https://drive.google.com/file/d/1-F9O79RvVYu9iIdciZXAesxunKWoIVGa/view?usp=sharing">Google Drive</a> <a href="https://pan.baidu.com/s/1-GwOpETvLqGSQwg5IRs6xQ">百度网盘:ucjy</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>不要直接复制。Clash基本就靠config.yaml运行，不用输入什么参数。</p><p>切换模式、切换节点都在config.yaml里弄。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">su  <span class="hljs-comment"># 用管理员账号</span><br>gunzip xxx.gz  <span class="hljs-comment"># gunzip解压gz文件</span><br><span class="hljs-built_in">cd</span> &lt;folder&gt;  <span class="hljs-comment"># 进入有那个可执行文件的文件夹</span><br>wget -O config.yaml [订阅链接]  <span class="hljs-comment"># 下载订阅链接，或者直接把文件重命名为config.yaml</span><br>chmod +x clash  <span class="hljs-comment"># 该权限让其可执行</span><br>./clash <span class="hljs-comment"># 运行梯子</span><br>./clash -d /etc/clash   <span class="hljs-comment"># 指定config目录</span><br>./clash -f /etc/clash/config.yaml  <span class="hljs-comment"># 指定config文件</span><br></code></pre></td></tr></table></figure><p>安装好了只是占了端口，搭好梯子，还需要配置系统把数据通过那个端口送出去。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">settings <span class="hljs-built_in">set</span> org.gnome.system.proxy mode <span class="hljs-string">&#x27;manual&#x27;</span><br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.http port 7890<br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.http host <span class="hljs-string">&#x27;127.0.0.1&#x27;</span><br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.https port 7890<br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.https host <span class="hljs-string">&#x27;127.0.0.1&#x27;</span><br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.socks port 7891<br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy.socks host <span class="hljs-string">&#x27;127.0.0.1&#x27;</span><br>gsettings <span class="hljs-built_in">set</span> org.gnome.system.proxy ignore-hosts <span class="hljs-string">&quot;[&#x27;localhost&#x27;, &#x27;127.0.0.0/8&#x27;, &#x27;::1&#x27;]&quot;</span><br></code></pre></td></tr></table></figure><p>这里面第一行是开启的命令，剩下是配置的命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">settings <span class="hljs-built_in">set</span> org.gnome.system.proxy mode <span class="hljs-string">&#x27;manual&#x27;</span>  <span class="hljs-comment"># 开启</span><br>settings <span class="hljs-built_in">set</span> org.gnome.system.proxy mode <span class="hljs-string">&#x27;none&#x27;</span>    <span class="hljs-comment"># 关闭</span><br></code></pre></td></tr></table></figure><p>接下来就可以使用了</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>用curl命令测试网站：<code>curl www.youtube.com</code></p><p>别用ping，ping不通的，ping用ICMP协议在计算机网络的网络层，socks代理在运输层。</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>Clash</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git原理</title>
    <link href="/2021/09/22/Git%E5%8E%9F%E7%90%86/"/>
    <url>/2021/09/22/Git%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="Git原理"><a href="#Git原理" class="headerlink" title="Git原理"></a>Git原理</h1><p>[TOC]</p><h2 id="仓库-repository"><a href="#仓库-repository" class="headerlink" title="仓库 (repository)"></a>仓库 (repository)</h2><p>仓库是git中最大的单位，就是一份代码/项目所在的地方，在实际中，就是一个目录(category)。</p><p>仓库可以通过<code>git init</code>命令来创建，创建之后，会出现一个<code>.git</code>的隐藏目录，里面保存着Git所需要的文件。</p><p>仓库里的文件一开始是空的，即使实际中的目录有文件，我们需要手动将文件添加进仓库（的暂存区），使用<code>git add &lt;file&gt;</code>，可以一次添加多个文件，也可以使用通配符。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git add 1.txt<br>git add 1.txt 2.txt<br>git add *.txt<br>git add ./data/*<br></code></pre></td></tr></table></figure><p>添加文件之后，就可以使用<code>git commit</code>命令进行提交，commit就是把暂存区(Stage)的改动一次性提交给仓库(实际上是分支branch)，在提交的时候，可以附带一些信息（这点是强烈推荐）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git commit -m <span class="hljs-string">&quot;message&quot;</span><br></code></pre></td></tr></table></figure><blockquote><p>commit的消息也可以选择性地遵守一定的规则</p><p>feat: 新功能<br>change：需求变更<br>fix：缺陷修复<br>test：修改测试代码<br>docs：文档变更<br>style：代码格式调整<br>refactor：代码重构</p></blockquote><h2 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h2><p>Git最重要的特点就是能够版本回退，回退的单位是commit。要回退到某个commit，需要先知道对应的<code>commit id</code>，这个id是用SHA1算出来的随机字符串。</p><p>回退的时候使用的是<code>git reset</code>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git reset --hard HEAD^  <span class="hljs-comment"># 回退到上一个版本，使用hard模式 HEAD表示当前 HEAD^表示上一个</span><br>git reset --hard 3s56fv  <span class="hljs-comment"># 跳转到某个commit id，id可以不用打全</span><br></code></pre></td></tr></table></figure><p>要找到想要的commit id，可以用<code>git log</code>来看过去，假如已经在“过去”，可以用<code>git reflog</code>来看未来。要从乱七八糟的log中找到你要的commit，那就得看你的commit message有没有好好写了。</p><h2 id="文件撤销修改-discard-changes-rollback"><a href="#文件撤销修改-discard-changes-rollback" class="headerlink" title="文件撤销修改(discard changes/rollback)"></a>文件撤销修改(discard changes/rollback)</h2><p>假如你不是想回退整个版本，而是改动一个文件后不想要改动了，那就可以使用<code>git checkout</code>命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git checkout -- &lt;file&gt;<br><span class="hljs-comment"># 1. 假如file还没有放进暂存区，即没git add，那么会撤销到和仓库里一样的状态</span><br><span class="hljs-comment"># 2. 假如file已经git add了，那么会撤销到add时的状态</span><br></code></pre></td></tr></table></figure><p>假如想把一个已经放进暂存区的文件撤回到和仓库一样的状态，可以使用之前提到的<code>git reset</code>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git reset HEAD &lt;file&gt;  <span class="hljs-comment"># 把文件的暂存区修改回退到工作区</span><br></code></pre></td></tr></table></figure><p>假如要从仓库中删除一个文件，那么应该使用<code>git rm</code>命令，假如是误删除了一个文件，也可以使用和上面一样的<code>git checkout</code>命令来恢复。</p><h2 id="添加远程库、推送"><a href="#添加远程库、推送" class="headerlink" title="添加远程库、推送"></a>添加远程库、推送</h2><p>假如想要将仓库共享出去，那么可以使用<code>git remote add</code>命令添加远程库，远程库的名字一般都默认为origin</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git remote add origin git@github.com:用户名/库名.git  <span class="hljs-comment"># 添加一个叫做origin的远程库</span><br></code></pre></td></tr></table></figure><p>之后把本地库内容推送到远程库上可以使用<code>git push</code>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git push origin master  <span class="hljs-comment"># origin是远程库名 master是分支名</span><br></code></pre></td></tr></table></figure><p>假如是想从远程库中下载一份到本地，使用<code>git clone</code>命令，链接在Github的repo主页都会写。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> &lt;链接&gt;<br></code></pre></td></tr></table></figure><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><p>每次commit，都会有一条时间线，这个时间线就是分支(branch)。默认的分支叫做master或者main，<code>HEAD</code>指向当前分支，下面是分支创建切换的基本操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git checkout -b newbranch  <span class="hljs-comment"># 创建并让HEAD指向这个新分支</span><br>git branch newbranch  <span class="hljs-comment"># 创建新分支</span><br>git checkout newbranch  <span class="hljs-comment"># HEAD指向某个分支</span><br>git branch  <span class="hljs-comment"># 查看分支</span><br>git branch -d newbranch  <span class="hljs-comment"># 删除分支</span><br><span class="hljs-comment"># git还提供了新的切换分支命令 git switch</span><br></code></pre></td></tr></table></figure><p>有多个分支时，可以合并分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git merge 分支名  <span class="hljs-comment"># 将某个分支合并到当前HEAD指向的那个分支</span><br></code></pre></td></tr></table></figure><p>对于分支管理，建议master分支用来发布版本，然后新建一个dev分支，所有人的改动都在dev分支上进行，有大版本更新时再合并到master。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210922131104.png" alt="来源：廖雪峰"></p><h2 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h2><p>git的拉取可以分为<code>fetch</code>、<code>pull</code>两种，<code>fetch</code>将远程主机的最新内容拉取到本地，需要检查再判断是否合并到本机，而<code>pull</code>则是拉取下来直接合并，但是可能产生冲突。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git fetch origin &lt;branch&gt;  <span class="hljs-comment"># </span><br>git merge FETCH_HEAD  <span class="hljs-comment"># 把刚才fetch的合并</span><br>git pull origin &lt;remote_branch&gt;:&lt;local_branch&gt;  <span class="hljs-comment"># 直接pull</span><br></code></pre></td></tr></table></figure><p>如图经常有这种冲突的情况，本地dev分支进行了改动，远程master分支也进行了改动。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210922142749.png" alt="git.drawio"></p><p>此时可以采取解决方案1：<strong>把merge到master分支</strong></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210922143448.png" alt="git-Page-2.drawio"></p><p>但是这样不太好看，于是可以采取解决方法2：<strong>rebase再push</strong></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210922144606.png" alt="git-Page-2.drawio (1)"></p><p>假如有冲突的话，可以在pycharm里面的Update Project打开代码解决冲突的三视窗口，在这里可解决代码冲突。这个不是git的命令，是pycharm的。</p><h2 id="藏匿stash"><a href="#藏匿stash" class="headerlink" title="藏匿stash"></a>藏匿stash</h2><p>假如你在某个分支上工作到一半时，想切换到master分支去临时修复一个bug，可以通过<code>git stash</code>命令保存当前尚未commit的任务。</p><blockquote><p>假如你没有stash就切换分支，会发现当前状态还是在dev改动后的状态</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git stash  <span class="hljs-comment"># 暂时藏匿工作</span><br>git stash list  <span class="hljs-comment"># 查看stash</span><br>git stash apply  <span class="hljs-comment"># 恢复stash</span><br>git stash drop  <span class="hljs-comment"># 删除stash</span><br>git stash pop  <span class="hljs-comment"># 恢复stash并删除</span><br>git stash apply stash@&#123;0&#125;  <span class="hljs-comment"># 恢复某个stash</span><br></code></pre></td></tr></table></figure><h2 id="pick一个commit"><a href="#pick一个commit" class="headerlink" title="pick一个commit"></a>pick一个commit</h2><p>假如想复制别的分支的某个commit到当前分支，可以使用<code>git cherry-pick</code>命令，相当于在这个分支做了一次commit。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git cherry-pick &lt;commit id&gt;  <span class="hljs-comment"># 将某个commit复制到当前分支</span><br></code></pre></td></tr></table></figure><h2 id="标签-Tag"><a href="#标签-Tag" class="headerlink" title="标签 Tag"></a>标签 Tag</h2><p>使用<code>git tag</code>命令可以为当前commit打上一个标签，差不多就是给commit起个别名。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git tag &lt;info&gt;  <span class="hljs-comment"># 给当前commit打标签</span><br>git tag &lt;info&gt; &lt;commit id&gt;  <span class="hljs-comment"># 给指定commit打标签</span><br>git tag -a &lt;tagname&gt; -m <span class="hljs-string">&quot;message&quot;</span>  <span class="hljs-comment"># 给标签分成名字和内容</span><br>git tag  <span class="hljs-comment"># 查看标签</span><br></code></pre></td></tr></table></figure><p>但是push的时候假如要加标签，需要一个额外的参数<code>--tags</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git push origin master --tags<br>git push origin &lt;tagname&gt;  <span class="hljs-comment"># 或者push特定的tag名</span><br></code></pre></td></tr></table></figure><h2 id="子模块-Submodule"><a href="#子模块-Submodule" class="headerlink" title="子模块 Submodule"></a>子模块 Submodule</h2><p><a href="https://git-scm.com/docs/git-submodule/">Git - git-submodule Documentation (git-scm.com)</a><br><a href="https://zhuanlan.zhihu.com/p/87053283">Git中submodule的使用 - 知乎 (zhihu.com)</a></p><p>子模块就是一个嵌入在一个仓库里的另一个仓库，子模块拥有自己的History，可以单独管理。</p><p><strong>创建子模块</strong>使用如下命令，创建后会出现一个.gitmodules文件和子仓库的目录，此时一般单独commit一次表示加入了子模块。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git submodule add &lt;url&gt;  <span class="hljs-comment"># 在本库中创建子模块</span><br></code></pre></td></tr></table></figure><p>创建子模块之后，别人clone并不会拉取到子模块代码，可以使用如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. clone到底</span><br>git <span class="hljs-built_in">clone</span> url --recurse-submodules<br><span class="hljs-comment"># 2. 或者，已经clone后更新子模块</span><br>git submodule init<br>git submodule update<br></code></pre></td></tr></table></figure><p><strong>假如在本库中修改了子模块：</strong></p><p>需要进入子模块文件夹，在子模块单独使用各类git命令。之后再本库中使用<code>git add</code>把子模块的变化提交上去。（可以先<code>git status</code>查看要提交什么，并不是提交整个库）</p><p><strong>假如子模块远端有版本变化：</strong></p><p>需要进入子模块文件夹<code>git pull</code>，或者使用<code>git submodule foreach &#39;git pull origin master&#39;</code>一键更新所有子模块。</p><p><strong>假如要删除子模块：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git submodule deinit &lt;模块目录&gt;  <span class="hljs-comment"># 卸载子模块</span><br>git submodule deinit &lt;模块目录&gt; --force  <span class="hljs-comment"># 卸载子模块，丢弃本地修改</span><br>git rm &lt;模块目录&gt;  <span class="hljs-comment"># 删除文件</span><br>git commit -m <span class="hljs-string">&quot;&quot;</span>  <span class="hljs-comment"># 提交删除的操作</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
      <category>常用易忘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>通过transformer实现的细粒度分类模型——TransFG</title>
    <link href="/2021/04/30/TransFG-Fine-Grained/"/>
    <url>/2021/04/30/TransFG-Fine-Grained/</url>
    
    <content type="html"><![CDATA[<h1 id="TransFG"><a href="#TransFG" class="headerlink" title="TransFG"></a>TransFG</h1><p><code>TransFG: A Transformer Architecture for Fine-grained Recognition</code></p><p>关键词：计算机视觉、Transformer、细粒度分类、ViT</p><h2 id="（前置）ViT：Vision-Transformer"><a href="#（前置）ViT：Vision-Transformer" class="headerlink" title="（前置）ViT：Vision Transformer"></a>（前置）ViT：Vision Transformer</h2><p>用来取代CNN，优点是节约计算资源。其适合在超大规模数据集（14M~300M）上训练。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210426224957.png" alt="img"></p><p>输入由于要是序列，就将图像切分成一系列patch。</p><blockquote><p>pretrained model命名：</p><p>B：base 参数最少    L：Large 参数多    H：Huge 参数最多</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210426231155.png" alt="image-20210426231155245"></p><p>一些可能用到的术语：</p><ul><li>R50+：结合Resnet50，将Resnet50的特征map输入</li><li>ViT-L/16：这里的16指的是patch的大小是16</li><li>BiT：改动的ResNet，用来做对比的</li></ul></blockquote><h2 id="论文要解决的问题"><a href="#论文要解决的问题" class="headerlink" title="论文要解决的问题"></a>论文要解决的问题</h2><p>传统的计算Fine-grained的方法是将图像的特定区域过CNN后区分，并且可能需要额外标注。</p><p>TransFG可以减少复杂度，提高性能。（减少复杂度……然鹅这模型还是很大）</p><p>率先尝试使用Vision Transformer来解决细粒度分类问题。</p><h2 id="模型主体架构"><a href="#模型主体架构" class="headerlink" title="模型主体架构"></a>模型主体架构</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429133624.png" alt="image-20210429133616028"></p><p>这里面每一个Transformer Layer都是下面这种多头self-attention，作者通过加载ViT的权重使用预训练模型，不冻结权重。（论文图是12 Layer）</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429133906.png" alt="image-20210429133906473" style="zoom: 50%;" /><h2 id="作者针对Fine-Grained做出的优化"><a href="#作者针对Fine-Grained做出的优化" class="headerlink" title="作者针对Fine-Grained做出的优化"></a>作者针对Fine-Grained做出的优化</h2><ol><li><p>原ViT是粗暴的切分原图像成16patch，作者增加了重叠部分<strong>overlap</strong>，设置超参数S来控制重叠的多少。S越小效果越好但耗算力越多。</p></li><li><p><strong>PSM(Part Selection Module)</strong> 选择模块。作者在前11层提取每一层输出的<code>α</code>，然后在Layer的维度相乘</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429143058.png" alt="image-20210429143058723"></p><p>得到了Seq个$\alpha_{final}$，$\alpha_{final}$获取了所有层对信息的注意力。</p><p>然后选择$\alpha_{final}$最大的K个（Multi-head的个数）信息$A_k$作为下一层的输入。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429144508.png" alt="image-20210429144430161"></p><p>原本ViT会在0位置新加一个额外的Token，叫做classification token，用来保存总信息。</p><p>所以用PSM之后，最后一层attention变得hard了起来，之前层的总体信息保存在0号token中，而每一个patch对应的特征则经过选择之后再送入最后一层。</p></li><li><p>Contrastive feature learning 对比特征学习</p><p>作者认为交叉熵不够，还加入了<code>Contrastive Loss</code>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429174308.png" alt="image-20210429174303822"></p><p>详见笔记Contrastive Loss与Triplet Loss</p><blockquote><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429195820.png" alt="img"></p><p>假如要改进，也许可以改成<code>Triplet Loss</code></p></blockquote></li></ol><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429195454.png" alt="image-20210429195416444"></p><p>除此以外还有iNat2017、Dogs、NABirds等数据集，都是state of art。</p><ul><li><p>重叠patch的提升</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429195559.png" alt="image-20210429195556264"></p></li><li><p>PSM的提升</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429195614.png" alt="image-20210429195610172"></p></li><li><p>Contrastive的提升</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210429195648.png" alt="image-20210429195648035"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python下使用MySQL（包括MySQL教程）</title>
    <link href="/2021/04/05/Python-MySQL/"/>
    <url>/2021/04/05/Python-MySQL/</url>
    
    <content type="html"><![CDATA[<h1 id="Python下使用MySQL（包括MySQL教程）"><a href="#Python下使用MySQL（包括MySQL教程）" class="headerlink" title="Python下使用MySQL（包括MySQL教程）"></a>Python下使用MySQL（包括MySQL教程）</h1><h2 id="MySQL基本使用"><a href="#MySQL基本使用" class="headerlink" title="MySQL基本使用"></a>MySQL基本使用</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MySQL是一个<strong>开源</strong>的<strong>关系型数据库管理系统</strong>，即<strong>RDBMS</strong>(Relational Database Management System)。使用SQL语言访问数据库。</p><p><strong>关系型数据库</strong>是<strong>依据关系模型</strong>来创建的数据库，关系模型包含“一对一、一对多、多对多”等，分别对应一本书的ISBN、一本书的作者、一个班的老师和学生。<strong>一个关系型数据库就是由二维表及其之间的练习组成的一个数据组织。</strong></p><table><thead><tr><th>关系</th><th>一张二维表，每个关系都有个名字，即表名</th></tr></thead><tbody><tr><td>元组</td><td>行，在数据库中叫做<strong>记录</strong></td></tr><tr><td>属性</td><td>列，在数据库中交做<strong>字段</strong></td></tr><tr><td>域</td><td>属性的取值范围，就是一列的取值限制（数字/字符串）</td></tr><tr><td>关键字</td><td>唯一标识元组的属性，在数据库中叫<strong>主键</strong>，由一个或多个列组成</td></tr><tr><td>关系模式</td><td>对关系的描述。关系名（属性1，属性2…）在数据库中叫<strong>表结构</strong></td></tr></tbody></table><p><strong>非关系型数据库</strong>类似一个巨大的map数据结构或者键值对数据结构。结构不固定，每一个元组可以有不一样的字段。</p><blockquote><p>MySQL由瑞典MySQL AB公司开发，这时候Oracle和MySQL是对头，后来被Sun公司收购，Sun后来又被Oracle公司收购。</p></blockquote><h3 id="MySQL的服务结构"><a href="#MySQL的服务结构" class="headerlink" title="MySQL的服务结构"></a>MySQL的服务结构</h3><pre><code class=" mermaid">graph LRA(MySQL-client) --&gt;|SQL|B[MySQL-server]B --&gt; AB --&gt; C[数据库1]C --&gt; C1[数据表1]C --&gt; C2[数据表2]C --&gt; C3[数据表3]B --&gt; D[数据库2]B --&gt; E[数据库3]</code></pre><p>MySQL通过SQL语言来与服务器沟通，一个数据库服务器可以有多个数据库，每个数据库可以有多个数据表。</p><h3 id="域"><a href="#域" class="headerlink" title="域"></a>域</h3><p>包括<strong>数据类型</strong>和<strong>约束</strong>。</p><table><thead><tr><th align="left">类型</th><th align="left">大小</th><th align="left">范围（signed）</th><th align="left">范围（unsigned）</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">TINYINT</td><td align="left">1 字节</td><td align="left">(-128，127)</td><td align="left">(0，255)</td><td align="left">小整数值</td></tr><tr><td align="left">SMALLINT</td><td align="left">2 字节</td><td align="left">(-32 768，32 767)</td><td align="left">(0，65 535)</td><td align="left">大整数值</td></tr><tr><td align="left">MEDIUMINT</td><td align="left">3 字节</td><td align="left">(-8 388 608，8 388 607)</td><td align="left">(0，16 777 215)</td><td align="left">大整数值</td></tr><tr><td align="left">INT或INTEGER</td><td align="left">4 字节</td><td align="left">(-2 147 483 648，2 147 483 647)</td><td align="left">(0，4 294 967 295)</td><td align="left">大整数值</td></tr><tr><td align="left">BIGINT</td><td align="left">8 字节</td><td align="left">(-9,223,372,036,854,775,808，9 223 372 036 854 775 807)</td><td align="left">(0，18 446 744 073 709 551 615)</td><td align="left">极大整数值</td></tr><tr><td align="left">FLOAT</td><td align="left">4 字节</td><td align="left">(-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38)</td><td align="left">0，(1.175 494 351 E-38，3.402 823 466 E+38)</td><td align="left">单精度 浮点数值</td></tr><tr><td align="left">DOUBLE</td><td align="left">8 字节</td><td align="left">(-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td><td align="left">0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308)</td><td align="left">双精度 浮点数值</td></tr><tr><td align="left">DECIMAL</td><td align="left">DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2</td><td align="left">依赖于M和D的值</td><td align="left">依赖于M和D的值</td><td align="left">小数值</td></tr></tbody></table><table><thead><tr><th align="left">类型</th><th align="left">大小 (字节)</th><th align="left">范围</th><th align="left">格式</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">DATE</td><td align="left">3</td><td align="left">1000-01-01/9999-12-31</td><td align="left">YYYY-MM-DD</td><td align="left">日期值</td></tr><tr><td align="left">TIME</td><td align="left">3</td><td align="left">‘-838:59:59’/‘838:59:59’</td><td align="left">HH:MM:SS</td><td align="left">时间值或持续时间</td></tr><tr><td align="left">YEAR</td><td align="left">1</td><td align="left">1901/2155</td><td align="left">YYYY</td><td align="left">年份值</td></tr><tr><td align="left">DATETIME</td><td align="left">8</td><td align="left">1000-01-01 00:00:00/9999-12-31 23:59:59</td><td align="left">YYYY-MM-DD HH:MM:SS</td><td align="left">混合日期和时间值</td></tr><tr><td align="left">TIMESTAMP</td><td align="left">4</td><td align="left">1970-01-01 00:00:00/2038结束时间是第 <strong>2147483647</strong> 秒，北京时间 <strong>2038-1-19 11:14:07</strong>，格林尼治时间 2038年1月19日 凌晨 03:14:07</td><td align="left">YYYYMMDD HHMMSS</td><td align="left">混合日期和时间值，时间戳</td></tr></tbody></table><table><thead><tr><th align="left">类型</th><th align="left">大小</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">CHAR</td><td align="left">0-255字节</td><td align="left">定长字符串</td></tr><tr><td align="left">VARCHAR</td><td align="left">0-65535 字节</td><td align="left">变长字符串</td></tr><tr><td align="left">TINYBLOB</td><td align="left">0-255字节</td><td align="left">不超过 255 个字符的二进制字符串</td></tr><tr><td align="left">TINYTEXT</td><td align="left">0-255字节</td><td align="left">短文本字符串</td></tr><tr><td align="left">BLOB</td><td align="left">0-65 535字节</td><td align="left">二进制形式的长文本数据</td></tr><tr><td align="left">TEXT</td><td align="left">0-65 535字节</td><td align="left">长文本数据</td></tr><tr><td align="left">MEDIUMBLOB</td><td align="left">0-16 777 215字节</td><td align="left">二进制形式的中等长度文本数据</td></tr><tr><td align="left">MEDIUMTEXT</td><td align="left">0-16 777 215字节</td><td align="left">中等长度文本数据</td></tr><tr><td align="left">LONGBLOB</td><td align="left">0-4 294 967 295字节</td><td align="left">二进制形式的极大文本数据</td></tr><tr><td align="left">LONGTEXT</td><td align="left">0-4 294 967 295字节</td><td align="left">极大文本数据</td></tr></tbody></table><table><thead><tr><th>约束</th><th>解释</th></tr></thead><tbody><tr><td>主键(Primary key)</td><td>物理上存储的顺序</td></tr><tr><td>非空(not NULL)</td><td>不允许填空值</td></tr><tr><td>唯一(unique)</td><td>不允许重复</td></tr><tr><td>默认(default)</td><td>不填写时用默认值</td></tr><tr><td><em>外键(foreign key)</em></td><td><em>只能填写另一处字段的值</em></td></tr></tbody></table><h3 id="SQL语言"><a href="#SQL语言" class="headerlink" title="SQL语言"></a>SQL语言</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>SQL(Structured Query Language)，指结构化查询语言。<strong>SQL语言不区分大小写。</strong></p><p>SQL语句的分号不是必须的，使用分号可以分隔多条SQL语句，可以在对服务器相同请求中执行一条以上的SQL语句。</p><h4 id="数据库操作-不常用"><a href="#数据库操作-不常用" class="headerlink" title="数据库操作(不常用)"></a>数据库操作(不常用)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 查看所有数据库<br>show databases;<br>-- 使用数据库<br>use 数据库名;<br>-- 查看当前数据库<br>select database();<br>-- 创建数据库<br>create database 数据库名 charset=utf8;<br>-- 删除数据库<br>drop database 数据库名<br></code></pre></td></tr></table></figure><h4 id="数据表操作"><a href="#数据表操作" class="headerlink" title="数据表操作"></a>数据表操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 查看当前所有数据表<br>show tables;<br>-- 查看表结构<br>desc 名字<br>-- 删除表<br>drop table 名字<br>-- 查看表的创建语句<br>show create table 名字<br>-- 创建表<br>create table 表名(字段名字 数据结构 约束,字段名字 数据结构);<br>create table people(<br>    id int unsigned primary key not null auto_increment, <br>    age int unsigned,<br>    height decimal(5,2) default 1.70<br>    gender enum(&quot;男&quot;,&quot;女&quot;,&quot;保密&quot;) default &quot;保密&quot;<br>    name varchar(30)<br>);  <br>-- 这个表id是主键，且不能空，且自动增长；age是无符号类型；height是2位小数的5位（包括小数位）数；gender只能有三种值，默认为保密<br><br>-- 增删查改字段<br>alter table 名字 操作 字段名字 数据结构 约束<br>-- 添加<br>alter table people add birthday datetime<br>-- 修改-不重命名<br>alter table people modify birthday date<br>-- 修改-重命名<br>alter table people change birthday birth date<br>-- 删除<br>alter table people drop height<br></code></pre></td></tr></table></figure><h4 id="数据的增删改查（重重重点）-CURD-create-update-retrieve-delete"><a href="#数据的增删改查（重重重点）-CURD-create-update-retrieve-delete" class="headerlink" title="数据的增删改查（重重重点）(CURD-create update retrieve delete)"></a>数据的增删改查（重重重点）(CURD-create update retrieve delete)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 增加<br>-- 完全插入：参数必须对应字段<br>insert into 表名字 values(字段参数)<br>-- 若有些字段不想写,且可以不用写，可用null或者default占位<br>insert into people(default,13,1.80,&quot;男&quot;,&quot;Tom&quot;)<br>-- 部分插入 <br>insert into 表名字 (字段名) values (加入的数据)<br>insert into people (age, name) values (13,&quot;Jack&quot;)<br>-- 多行插入<br>insert into 表名字 values (字段参数1),(字段参数2)<br>insert into 表名字 (字段名) values (加入的数据1),(加入的数据2)<br><br>-- 修改<br>-- 修改所有记录该字段的值<br>update 表名字 set 字段1=新值1，字段2=新值2<br>-- 修改一定某个记录中字段的值 where <br>update 表名字 set 字段=新值 where 字段与值关系(可用大于小于号)<br>update people set age = 18 where id=1<br><br>-- 删除<br>-- 清空表！别用！<br>delete from 表名字<br>-- 删除某个记录<br>delete from 表名字 where<br>-- 逻辑删除，新增一个is_delete操作，标记这行可不可用<br>alter table 表名字 add is_delete bit default 0<br>update 表名字 set is_delete where ...<br><br>-- 查询（基本）<br>-- 查询表所有记录<br>select * from 表名字<br>-- 查询某个记录<br>select * from 表名字 where 字段与值关系<br>-- 查询某个字段<br>select 字段名字 from 表名字 <br>-- 指定别名，指定别名后不能用本名了<br>select 字段名字 as 别名 from 表名字 as 别名<br>select 表名.字段名 from 表名<br>-- 指定列的顺序<br>select 第一个字段,第二个字段 from 表名字<br>-- 去重<br>select distinct 字段 from 表名<br></code></pre></td></tr></table></figure><h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 条件查询<br>-- 使用where关键字<br>&gt; &lt; &gt;= &lt;= -- 和别的语言一样<br>= -- 单等于表示判断<br>&lt;&gt; !=  -- 不等于<br>and or not  -- 与或非，同Python<br>()  -- 括号，优先级很高<br><br>-- 模糊查询<br>-- 使用like关键字<br>-- % 替换0个或多个 | _ 替换一个 | [charlist] 字符列中任意单一字符 | []不在字符列中的任何单一字符<br>select name from people where name like &quot;T%&quot;  -- 名字以T开头<br>-- 使用rlike关键字<br>-- 正则表达式<br>select name from people where name rlike &quot;正则表达式&quot;<br><br>-- 范围查询<br>-- （非连续）使用in和not in关键字  <br>select name from people where age in (12,18,6)  -- &#123;12,18,6&#125;<br>-- （连续）使用between...and...关键字和not between...and...关键字 左闭右闭区间<br>select name from people where age between 6 and 18  -- [6,18]<br><br>-- 空判断<br>-- 使用is null关键字和is not null关键字<br>select name from people where age is null<br></code></pre></td></tr></table></figure><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- order by 字段<br>-- asc 升序(从小到大)   desc 降序<br>select name from people order by age<br>select name from people order by age asc<br>-- order by 多个字段<br>-- 在第一个字段相同情况下，再按第二个字段排...<br>select name from people order by age asc, id desc<br></code></pre></td></tr></table></figure><h4 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 聚合函数只能输出一个结果<br>-- count 总数<br>-- 就是计算输出的东西一共多少行，结果表头是count(*)，可用as<br>select count(*) from people<br>select count(*) as &quot;人数&quot; from people<br>-- max 最大值  min 最小值<br>select max(age) from people<br>select min(height) from people<br>-- sum 求和<br>select sum(age) from people<br>-- avg 平均<br>select avg(age) from people<br>select sum(age) / count(*) from people  -- select后可以用运算和多个函数<br>-- round(x,保留小数位数) 四舍五入<br>select rount(avg(age),1) from people  -- 保留平均数的一位小数<br></code></pre></td></tr></table></figure><h4 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- group by<br>-- xxx是能唯一标记分组后各组之间不同的字段<br>-- xxx不能填*<br>select gender from people group by gender  -- 1*<br><br>-- 与聚合函数一起用，查找不同性别各自的人数<br>select gender,count(*) from people group by gender<br><br>-- group_concat(字段1,字段2) 写什么有什么，链接所有参数<br>-- 查询group中某字段的总和<br>select gender,group_concat(name) from people group by gender  -- 2*<br>select gender,group_concat(name,age) from people group by gender<br>select gender,group_concat(name,&quot;_&quot;，age) from people group by gender  -- 3* <br><br>-- 与where一起用，先判断，然后从中分组<br>select gender,group_concat(name) from people where age&lt;18 group by gender<br><br>-- having 显示符合条件的分组，与where不同的是写在group后面<br>-- 所以where是对表进行判断，having是对分组结果进行判断<br>select gender,group_concat(name) from people group by gender having min(age)&lt;5  -- 4*<br></code></pre></td></tr></table></figure><blockquote><p>1* 的结果</p><table><thead><tr><th>gender</th><th>count(*)</th></tr></thead><tbody><tr><td>男</td><td>5</td></tr><tr><td>女</td><td>3</td></tr></tbody></table><p>2* 的结果</p><table><thead><tr><th>gender</th><th>group_concat(name)</th></tr></thead><tbody><tr><td>男</td><td>Mike, Leo, Tom</td></tr><tr><td>女</td><td>Lucy, Mary</td></tr></tbody></table><p>3* 的结果</p><table><thead><tr><th>gender</th><th>group_concat(name,”_”，age)</th></tr></thead><tbody><tr><td>男</td><td>Mike_12, Leo_18, Tom_6</td></tr><tr><td>女</td><td>Lucy_12, Mary_3</td></tr></tbody></table><p>4* 的结果</p><table><thead><tr><th>gender</th><th>group_concat(name)</th></tr></thead><tbody><tr><td>女</td><td>Lucy, Mary</td></tr></tbody></table></blockquote><h4 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs mysql">-- 使用limit限制<br>-- limit 数字m  查询前m个<br>select * from people limit 5<br>-- limit 数字n,数字m  查询从n开始，查询共m个<br>-- n从0开始<br>select * from peolpe limit 2,6  -- [3,9]<br>select * from peolpe limit 0,5  -- [1,5]<br>select * from peolpe limit 5,5  -- [6,10]<br>select * from peolpe limit 10,5  -- [11,15]<br>-- limit放最后<br>select * from peolpe order by age limit 0,5  -- 按age排序的[1,5]<br></code></pre></td></tr></table></figure><h4 id="链接查询"><a href="#链接查询" class="headerlink" title="链接查询"></a>链接查询</h4><p>结合多个表的查询，比如一张表存放班级信息，另一张表存放同学信息，要显示同学信息的同时再显示该同学的班级信息，就用链接查询。</p><p>略。</p><h4 id="自关联"><a href="#自关联" class="headerlink" title="自关联"></a>自关联</h4><p>一个表中某个字段用的是另一个字段的值</p><p>比如公司中上下属关系，A是B的属下，B是D的属下，C是D的属下，于是数据表中可以新建一个字段，表示每个员工的老板是谁，同时这个老板也在同一个表中，并且也有他的老板。</p><p>略。</p><h4 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h4><p>select中嵌入另一个select语句</p><p>比如查找人群中最高的人的信息，需要select最高的人，然后select *</p><p>略。</p><h2 id="Python-与-MySQL-交互"><a href="#Python-与-MySQL-交互" class="headerlink" title="Python 与 MySQL 交互"></a>Python 与 MySQL 交互</h2><pre><code class=" mermaid">graph LRA(开始) --&gt; B[创建connection]B --&gt; C[获取cursor]C --&gt; D[操作]D --&gt; E[关闭cursor]E --&gt; F[关闭connection]F --&gt; G(结束)</code></pre><h3 id="查询-1"><a href="#查询-1" class="headerlink" title="查询"></a>查询</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pymysql <span class="hljs-keyword">import</span> *<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span><br>    <span class="hljs-comment"># 创建connection</span><br>    conn = connect(<br>    host=<span class="hljs-string">&#x27;localhost&#x27;</span>,<br>        port=<span class="hljs-number">3306</span>,<br>        user=<span class="hljs-string">&#x27;root&#x27;</span>,<br>        password=<span class="hljs-string">&#x27;root&#x27;</span>,<br>        database=<span class="hljs-string">&#x27;study&#x27;</span>,<br>        charset=<span class="hljs-string">&#x27;utf8&#x27;</span><br>    )<br>    <span class="hljs-comment"># 获取cursor</span><br>    cursor = conn.sursor()<br>    <br>    <span class="hljs-comment"># 执行sql语句获取数据 select返回获取的行数</span><br>    cursor.execute(<span class="hljs-string">&quot;&quot;&quot;select * from people;&quot;&quot;&quot;</span>)<br>    <span class="hljs-comment"># 从游标中获取数据(fetch) </span><br>    <span class="hljs-comment"># fetchone()得到一个元组,然后游标向下走一行</span><br>    oneline = cursor.fetchone()<br>    <span class="hljs-comment"># fetchmany(int)元组里面套元组，然后游标向下走那么多行</span><br>    manylines = cursor.fetchmany(<span class="hljs-number">3</span>)<br>    <span class="hljs-comment"># fetchall() 元组里面套元组，获取游标下所有</span><br>    alllines = cursor.fetchall()<br>    <br>    <span class="hljs-comment"># 关闭游标</span><br>    cursor.close()<br>    <span class="hljs-comment"># 关闭连接</span><br>    conn.close()<br></code></pre></td></tr></table></figure><h3 id="增删改"><a href="#增删改" class="headerlink" title="增删改"></a>增删改</h3><p>增删改操作需要增加一个提交connection.commit()操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pymysql <span class="hljs-keyword">import</span> *<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span><br>    <span class="hljs-comment"># 创建connection</span><br>    conn = connect(<br>    host=<span class="hljs-string">&#x27;localhost&#x27;</span>,<br>        port=<span class="hljs-number">3306</span>,<br>        user=<span class="hljs-string">&#x27;root&#x27;</span>,<br>        password=<span class="hljs-string">&#x27;root&#x27;</span>,<br>        database=<span class="hljs-string">&#x27;study&#x27;</span>,<br>        charset=<span class="hljs-string">&#x27;utf8&#x27;</span><br>    )<br>    <span class="hljs-comment"># 获取cursor</span><br>    cursor = conn.sursor()<br>    <br>    <span class="hljs-comment"># 执行sql语句 返回生效行数</span><br>    cursor.execute(<span class="hljs-string">&quot;&quot;&quot;insert into people(name, age) values(&quot;Ash&quot;, 31);&quot;&quot;&quot;</span>)  <span class="hljs-comment"># 增</span><br>    cursor.execute(<span class="hljs-string">&quot;&quot;&quot;delete from people where id=6 ;&quot;&quot;&quot;</span>)  <span class="hljs-comment"># 删</span><br>    cursor.execute(<span class="hljs-string">&quot;&quot;&quot;update people set age=18 where name=&quot;Tom&quot;;&quot;&quot;&quot;</span>)  <span class="hljs-comment"># 改</span><br>    <br>    <span class="hljs-comment"># 取消所有请求 但是自动增长（例如id）会持续生效</span><br>    <span class="hljs-comment"># conn.rollback()</span><br>    <span class="hljs-comment"># 提交请求</span><br>    conn.commit()<br>    <span class="hljs-comment"># 关闭游标</span><br>    cursor.close()<br>    <span class="hljs-comment"># 关闭连接</span><br>    conn.close()<br></code></pre></td></tr></table></figure><h3 id="防止SQL注入"><a href="#防止SQL注入" class="headerlink" title="防止SQL注入"></a>防止SQL注入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 前略</span><br><br>name = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;请输入你要查询的人的名字：&quot;</span>)<br>cursor.execute(<span class="hljs-string">&quot;&quot;&quot;select * from people where name = &quot;&#123;&#125;&quot; &quot;&quot;&quot;</span>.<span class="hljs-built_in">format</span>(name))<br><span class="hljs-comment"># 输入 Tom</span><br><span class="hljs-comment"># 结果 (1,18,1.80,&quot;男&quot;,&quot;Tom&quot;)</span><br><span class="hljs-comment"># 输入 &quot;or 1=1 or &quot;1</span><br><span class="hljs-comment"># execute内容： select * from people where name = &quot;&quot;or 1=1 or &quot;1&quot;</span><br><span class="hljs-comment"># 结果输出所有人的名字</span><br><span class="hljs-comment"># SQL注入！！！！！</span><br><br><span class="hljs-comment"># 防止方法</span><br><span class="hljs-comment"># 构建参数列表</span><br>params = [name]<br>sql = <span class="hljs-string">&quot;select * from people where name=%s, id=%d, age=%d &quot;</span><br>cursor.execute(sql,params)  <span class="hljs-comment"># 自动填充</span><br><br><span class="hljs-comment">## 后略</span><br></code></pre></td></tr></table></figure><div class="note note-info">            <p>参考文献：</p><ol><li><a href="https://www.jianshu.com/p/fd7b422d5f93">https://www.jianshu.com/p/fd7b422d5f93</a></li><li><a href="https://www.runoob.com/sql/sql-intro.html">https://www.runoob.com/sql/sql-intro.html</a></li><li><a href="https://www.bilibili.com/video/av37278656">https://www.bilibili.com/video/av37278656</a></li></ol>          </div>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络爬虫进化史，原来你是这样的爬虫：第3期</title>
    <link href="/2021/04/05/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC3%E6%9C%9F/"/>
    <url>/2021/04/05/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC3%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="网络爬虫进化史，原来你是这样的爬虫：第3期"><a href="#网络爬虫进化史，原来你是这样的爬虫：第3期" class="headerlink" title="网络爬虫进化史，原来你是这样的爬虫：第3期"></a>网络爬虫进化史，原来你是这样的爬虫：第3期</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一期，万维网经历了发展最迅速的时期，也经历了泡沫破裂的时期，而爬虫却在背地里偷偷壮大起来，仅仅1994这一年，爬虫的爬取能力就扩大了好几倍，而随着Google的天才工程师们的加入，爬虫也学会团结在一起集体行动。</p><p>不知道读者们还记不记得第一期的“常胜将军”</p><blockquote><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153701.png" alt="传统爬虫结构"></p><p>我们可以把爬虫想象为一位攻城掠地的常胜将军，他带着初始的补给去攻打一个个城池，每攻下一个城池就能获得新的补给，然后他就带着新的补给去攻打新的城池……直到他征服了全世界。</p></blockquote><p>在经过几年的磨砺之后，常胜将军手下的军队越来越强大，他的脑袋也越来越灵活，他已经能够率领军队同时进攻几个城池，在新的世纪到来之时，世界的变化越来越大，城池越来越坚固，将军是否还能经受住考验呢？</p><h2 id="Mercator"><a href="#Mercator" class="headerlink" title="Mercator"></a>Mercator</h2><p>Google爬虫是20世纪的王者，而它并不是完美的，假如说Google爬虫是为了Google搜索而生的专业搜索引擎爬虫，那么诞生于1999年的Mercator就是能为各类人员所用的万金油。</p><p>在上世纪90年代的程序设计界，Java和C++是最热门的两门计算机编程语言，而他们的共同特点就是OOP(Object Oriented Programming)，也就是面向对象，而面向对象又常伴随着模块化编程，模块化编程，是强调将计算机程序的功能分离成独立的、可相互改变的“模块”的软件设计技术，它使得每个模块都包含着执行预期功能的一个唯一方面所必需的所有东西。</p><p>我们要介绍的<strong>Mercator</strong>爬虫就是采用模块化设计思维，由Java语言实现的<strong>可拓展性</strong>爬虫。Mercator为爬虫领域带来了模块化设计，现在热门的Scrapy就是一个高度模块化的爬虫框架，当我们使用这种模块化设计的爬虫来进行某个爬取任务时，我们只要改动某一个模块的几十行代码就可以实现，并不需要动爬虫的核心(core)代码。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153706.png" alt="Mercator爬虫的各个模块"></p><p>Mercator爬虫的可拓展分为<strong>规模可拓展性</strong>(scalable)和<strong>功能可拓展性</strong>(extensible)两个方面，规模可拓展指的是无论你想用Mercator爬取一个小网站还是想爬取整个万维网，这个爬虫都会以正常的效率工作，而功能可拓展性指的是Mercator支持第三方来添加新模块来拓展功能，类似现在很多游戏都会加入的创意工坊(steam workshop)或者是Chrome浏览器的插件(Chrome plugins)。</p><p>除了上面提到的可拓展性以外，Mercator还有其他优点</p><ol><li>Mercator和Google一样可以在多台计算机上同时运行来提高效率，在四台Compaq DS20E 666 MHz Alpha服务器和160M的宽带下，Mercator每天就能够下载五千万个页面。</li><li>Mercator遵守爬虫礼仪，它的URL Frontier模块专门设计了前端(front-end)和后端(back-end)两个队列，前端队列负责给URL优先级排序，而后端队列负责保证爬虫礼仪。</li><li>Mercator具有可移植性，由于它是用Java实现的，所以它可以轻松地运行在任何装有Java虚拟机的系统上。</li></ol><p>这些优点让Mercator变得非常热门，再加上Mercator是当时公开信息和技术最多的爬虫，有非常多的人使用Mercator来进行研究，AltaVista搜索引擎就将它整合进去用来为美国和欧洲提供服务，还有人用它爬取了全网超过12TB的数据，甚至还有人用它来监控调查2000年美国总统选举时的与选举有关的网站。</p><h2 id="Polybot"><a href="#Polybot" class="headerlink" title="Polybot"></a>Polybot</h2><p>虽然Mercator靠着它的可拓展性红极一时，但是它有着一个很大的缺点——对硬件的需求高。Mercator虽然是个模块化的爬虫，但是要扩大规模就必须要多台相同的高性能机器一起运行多个Mercator程序，并且在Java尚未得到充足优化的时代，用Java写的程序普遍比C/C++更慢且占用内存更多，这使得使用Mercator的门槛很高。</p><p>2002年，另一个爬虫Polybot横空出世，它专门为低端机器进行了优化。</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153713.png" alt="image-20210121134837559" style="zoom:50%;" /><p>Polybot也是精心使用模块化设计的爬虫，比起Mercator，它的模块化程度显然更高，Mercator虽然能在多台机器上同时进行爬虫任务来提高效率，但是每台机器都运行的是同样复杂的任务，包括下载、提取、DNS解析等等，而Polybot则将它的每个模块完全分开，下载模块和DNS解析模块可以运行在不同的机器上，通过网络来交流和分配任务，这种方式让每台实体机器所负担的任务量大大减少，所以Polybot的使用者可以用更多台低成本机器来提升效率。</p><p>既然机器增多了，可能的故障也增多了，Polybot采用断点(checkpoint)技术来避免机器出问题导致爬取要从头开始。在开发者进行爬取试验的时候，由于各种因素程序崩溃了很多次，但是之后Polybot读取断点又继续进行任务了，实验结束后，Polybot总共在18天内爬取到了超过1.2亿个页面。</p><h2 id="P2P"><a href="#P2P" class="headerlink" title="P2P"></a>P2P</h2><p>在1999年5月的美国东北大学(NEU)，一个叫做Napster的软件免费软件在学生中流行起来，音乐爱好者们不用再担心没有钱去商店里买他们最喜欢的歌手的专辑了，Napster可以让他们互相分享MP3歌曲，在最火的时候，Napster拥有高达8000万的注册用户，无论是歌曲的数量还是下载速度，Napster都远远超过了他的竞争者们。</p><p>Napster的主要技术就是P2P(peer-to-peer)，也就是点对点网络或者对等网络。这种网络的特点就是没有中心服务器，仅依靠用户群来交换数据的互联网。这种网络的优点就是用户越多，效率越高，而且其中任何一个节点（用户）掉线了也不会影响整个网络。QQ、Skype（即时通话app）、SETI@home（利用全球各地计算机提供算力来寻找地外文明的项目）、BT下载（包括迅雷等）和比特币都使用了P2P技术。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153715.jpg" alt="Screengrab of the Napster program"></p><p>P2P的成功也引起了爬虫开发人员的注意，在2002年UbiCrawler爬虫率先使用了P2P网络来进行爬取任务。UbiCrawler和Mercator一样都是100%使用Java来实现的爬虫，然而UbiCrawler出色的设计让Java运行速度慢的劣势消失了，它在使用五台普通个人电脑的情况下，就实现了1000万每日的页面爬取量。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153717.png" alt="传统爬虫结构"></p><p>UbiCrawler使用到P2P技术的地方是URL-Seen模块，也就是爬虫从页面中提取到了超链接之后，需要判断这个链接是否已经被访问过，而随着不断爬取，已经访问过的链接数量可能是几百万几千万，高性能爬虫都会在这里遇到瓶颈。UbiCrawler通过一致性哈希算法(consistent hashing)，在爬虫的某个节点遇到一个URL之后，这个节点会将算出URL的hash值，然后判断这个URL应该由哪个节点负责处理，最后传递给那个节点，这样每个节点都只用处理总URL-Seen的一部分。</p><p>在之后有很多研究团队在UbiCrawler的基础上进行了改进，pSearch项目采用分布式哈希表(Distributed Hash Tables)来进一步提升P2P爬虫的性能，随着P2P的节点遍布全球，还有人通过考虑节点的地理位置来分配任务从而提升效率。</p><p>除了分布式爬虫，也有一些特立独行的爬虫只在一台机器上运行并发挥最大效率，比如2008年的IRLbot，在一台装有四核AMD皓龙处理器的服务器上，用41.27天爬取到了超过63亿个页面！</p><blockquote><h2 id="Wayback-Machine"><a href="#Wayback-Machine" class="headerlink" title="Wayback Machine"></a>Wayback Machine</h2><p>爬虫能做什么？从第一期到现在，开发爬虫的目的好像无非就是构建搜索引擎和对万维网进行规模研究，然而有一个组织使用爬虫制造了一个网站时光机，允许用户“回到过去”，这就是<a href="https://web.archive.org/">Wayback Machine</a>。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153719.png" alt="File:Wayback Machine logo 2010.svg"></p><p>这个时光机通过爬虫将从万维网上爬取到的页面存档下来，创始人Kahle和Gilliat希望以此能为整个互联网“普及所有知识”。时光机于1996年开始存档网页，在2001年正式公开时，它已经存档了超过100亿个页面，截止2018年9月，时光机已经存有了超过25PB的数据。</p><p>这是一个很有趣的网站，我们可以在上面找到很多网页之前的样子，比如B站在2011年的样子</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153724.png" alt="QQ图片20210122102337"></p><p>还有Youtube在2005年的样子</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153726.png" alt="image-20210122102625821"></p><p>还有2009年的steam</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153728.png" alt="image-20210122102958463"></p></blockquote><h2 id="接下来？"><a href="#接下来？" class="headerlink" title="接下来？"></a>接下来？</h2><p>这一期，我们的爬虫不仅开始成群结队了起来，而且他们的阵型变得更加灵活，我们的常胜将军带领的爬虫大军既能分散作战，用庞大的数量攻略城池，也能派出名将用高效的数据结构和算法来攻略城池，就算有几位将军倒下了，也会有其他将军顶替……纵使万维网的页面从最开始的一个页面发展到几百万几亿个页面，成千上万个站点，也避免不了爬虫爬取到每个角落。</p><p>然而，万维网并不是只在数字上有增长，当这些爬虫兴奋地在网上爬来爬去时，殊不知万维网已经成了一座冰山，掩盖在海底的不可见数据越来越多，这让传统的爬虫束手无策，他们需要进一步的升级才能看清水底的数据……</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210405153730.png" alt="What is Dark Web and Why You Should Access it Carefully! - GeeksforGeeks"></p><div class="note note-info">            <p>这篇文章也发布在下面这个公众号数媒极客，公众号里面有其他很有趣的文章，可以扫码看一看~</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/671DEC2D0C09137F94251F74940B395C.jpg" style="zoom:50%;" />          </div>]]></content>
    
    
    <categories>
      
      <category>爬虫历史系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>用ngrok搭建属于自己的内网穿透教程（附错误处理）</title>
    <link href="/2021/03/04/ngrok-tutorial/"/>
    <url>/2021/03/04/ngrok-tutorial/</url>
    
    <content type="html"><![CDATA[<h1 id="用ngrok搭建属于自己的内网穿透教程（附错误处理）"><a href="#用ngrok搭建属于自己的内网穿透教程（附错误处理）" class="headerlink" title="用ngrok搭建属于自己的内网穿透教程（附错误处理）"></a>用ngrok搭建属于自己的内网穿透教程（附错误处理）</h1><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210304145345.png" alt="ngrok示意图"></p><p>ngrok是一个开源的反向代理，它可以创建一个隧道（tunnel），让互联网上的用户访问你的本地资源。</p><p>可以用来<strong>Minecraft等游戏的局域网联机</strong>、<strong>本地网站通过外网访问</strong>等。若用在另外一台服务器，还可以作为<strong>防火墙</strong>。（假如你要用来给游戏局域网联机，你可以把ngrok看作它打通了你和别人的局域网）</p><p>ngrok用go语言编写，需要<strong>go1.1+<strong>和</strong>Mercurial SCM</strong></p><p>ngrok分为两部分，<strong>ngrok</strong>和<strong>ngrokd</strong>，ngrokd是服务端，也就是代理服务器，用来接收外网的信息，然后通过隧道传到客户端的网络中；ngrok是客户端，哪台主机的局域网要暴露，就在哪台主机上运行。</p><p>GitHub：<a href="https://github.com/inconshreveable/ngrok">inconshreveable/ngrok: Introspected tunnels to localhost (github.com)</a></p><blockquote><p><strong>正向代理与反向代理的区别：</strong></p><p>正向代理：让服务器不知道他服务的对象是谁（用户请了代理），常见的应用就是VPN，假如大家想在大学校外访问校园内网，通常要使用学校提供的VPN，让校内的服务器给代理服务，然后代理再把收到的信息转给你。</p><p>反向代理：让用户不知道谁在为他服务（服务器请了代理）。以前给10086打电话，它的客服有很多，你打进来的电话会随机转接到某个客服上，这个转接过程就是反向代理，用户知道的就是10086这个“代理”，而实际给你服务的客服是不知道的。</p></blockquote><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>一台云主机（Linux系统为例 测试用ubuntu 18系统）</li><li>一个域名（可以不用备案）（可选）</li></ul><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="域名解析（可选）"><a href="#域名解析（可选）" class="headerlink" title="域名解析（可选）"></a>域名解析（可选）</h3><p>打开域名管理页面，添加*.ngrok.example.com和ngrok.example.com两条记录</p><p>到时候你将通过 xxx.ngrok.example.com:端口 来访问代理服务器</p><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs console">apt-get update  # 更新软件列表<br>apt-get upgrade  # 更新软件<br>apt install git  # 获取git<br><br>git --version  # 检查已安装git版本<br></code></pre></td></tr></table></figure><h3 id="安装、配置go语言环境"><a href="#安装、配置go语言环境" class="headerlink" title="安装、配置go语言环境"></a>安装、配置go语言环境</h3><p>打开<a href="https://studygolang.com/dl">go语言中文网</a>找到最新的go版本（这里以1.14为例），然后用wget下载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://studygolang.com/dl/golang/go1.14.linux-amd64.tar.gz<br><span class="hljs-meta">#</span><span class="bash"> 默认下载到当前目录，使用 -P path 参数可以指定下载路径</span><br>tar -zxvf go1.14.linux-amd64.tar.gz<br><span class="hljs-meta">#</span><span class="bash"> 默认解压到当前目录</span><br>mv go /usr/local<br><span class="hljs-meta">#</span><span class="bash"> 将go挪到另一个目录，方便管理</span><br><br>cd ~<br><span class="hljs-meta">#</span><span class="bash"> 到主目录</span><br>vi .bashrc<br><span class="hljs-meta">#</span><span class="bash"> 打开配置文件,在末尾添加如下</span><br>export GOROOT=/usr/local/go<br><span class="hljs-meta">#</span><span class="bash"> 这个目录是go的解压目录</span><br>export GOPATH=/home/gosrc/ngrok<br><span class="hljs-meta">#</span><span class="bash"> 这个目录是go的工作目录，即等下要编译ngrok的目录</span><br>export PATH=$GOROOT/bin:$PATH:$GOPATH/bin<br><span class="hljs-meta">#</span><span class="bash"> 设置bin目录</span><br>:wq<br><span class="hljs-meta">#</span><span class="bash"> 保存并退出</span><br>source .bashrc<br><span class="hljs-meta">#</span><span class="bash"> 生效</span><br><br>go version<br><span class="hljs-meta">#</span><span class="bash"> 查看go是否成功安装</span><br></code></pre></td></tr></table></figure><h2 id="安装ngrok"><a href="#安装ngrok" class="headerlink" title="安装ngrok"></a>安装ngrok</h2><h3 id="下载ngrok"><a href="#下载ngrok" class="headerlink" title="下载ngrok"></a>下载ngrok</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /home/gosrc/ngrok<br><span class="hljs-meta">#</span><span class="bash"> 进入你自己准备用来编译的ngrok工作区</span><br>git clone https://github.com/inconshreveable/ngrok.git<br><span class="hljs-meta">#</span><span class="bash"> 把库<span class="hljs-built_in">clone</span>下来</span><br></code></pre></td></tr></table></figure><h3 id="生成签名证书"><a href="#生成签名证书" class="headerlink" title="生成签名证书"></a>生成签名证书</h3><p>这一步很重要，也很容易错，我们要生成自己的SSL证书。</p><p>由于我计划最终提供服务的地址是xxx.ngrok.example.com所以我把NGROK_DOMAIN设置如下</p><p><strong>注意把域名设置成你自己的域名</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">NGROK_DOMAIN=&quot;ngrok.example.com&quot;<br> <br>openssl genrsa -out rootCA.key 2048<br>openssl req -x509 -new -nodes -key rootCA.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -days 5000 -out rootCA.pem<br>openssl genrsa -out server.key 2048<br>openssl req -new -key server.key -subj &quot;/CN=$NGROK_DOMAIN&quot; -out server.csr<br>openssl x509 -req -in server.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out server.crt -days 5000<br> <br>cp rootCA.pem assets/client/tls/ngrokroot.crt<br>cp device.crt assets/server/tls/snakeoil.crt<br>cp device.key assets/server/tls/snakeoil.key<br></code></pre></td></tr></table></figure><p>最后三个cp命令是将生成的证书覆盖原来ngrok的证书</p><h3 id="编译ngrok"><a href="#编译ngrok" class="headerlink" title="编译ngrok"></a>编译ngrok</h3><p>最容易出问题的一步</p><p><strong>编译Linux服务端（本机）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">GOOS=linux GOARCH=386 make release-server<br><span class="hljs-meta">#</span><span class="bash"> 32位</span><br>GOOS=linux GOARCH=amd64 make release-server<br><span class="hljs-meta">#</span><span class="bash"> 64位</span><br></code></pre></td></tr></table></figure><p><strong>编译windows客户端</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">GOOS=windows GOARCH=amd64 make release-client<br><span class="hljs-meta">#</span><span class="bash"> 64位，没人用32了吧。。。</span><br></code></pre></td></tr></table></figure><p><strong>编译Linux客户端</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">GOOS=linux GOARCH=386 make release-client<br><span class="hljs-meta">#</span><span class="bash"> 32位</span><br>GOOS=linux GOARCH=amd64 make release-client<br><span class="hljs-meta">#</span><span class="bash"> 64位</span><br></code></pre></td></tr></table></figure><blockquote><p><strong>go-bindata的错误解决</strong></p><p>go get github.com/go-bindata/go-bindata/…</p><p>按道理会出现在GOPATH，然后把go-bindata复制到ngrok/bin下面</p></blockquote><blockquote><p><strong>其他错误解决</strong></p><p>检查你的云主机是否能正常访问网络</p><p>检查GOPATH的设置，看看是否正确</p><p><code>echo $GOPATH</code></p></blockquote><p>假如一切正常，那么在bin目录下会出现ngrokd（Linux客户端），还可能有存有exe文件的目录</p><h2 id="启动服务端"><a href="#启动服务端" class="headerlink" title="启动服务端"></a>启动服务端</h2><p>在ngrok目录运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">./bin/ngrokd -tlsKey=server.key -tlsCrt=server.crt -domain=&quot;ngrok.example.com&quot; -httpAddr=&quot;:8090&quot;<br></code></pre></td></tr></table></figure><p>前两个参数是指定证书；第三个参数是域名；第四个参数是用来转发http的端口，可以随便写；还可以写httpsAddr用来指定转发https的端口</p><h2 id="启动客户端"><a href="#启动客户端" class="headerlink" title="启动客户端"></a>启动客户端</h2><p>用ftp或者其他方法，将客户端的ngrok或ngrok.exe放到要被访问的机器上</p><ul><li><strong>新建一个ngrok.cfg，打开写入如下内容</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">server_addr:</span> <span class="hljs-string">&quot;ngrok.example.com:4443&quot;</span><br><span class="hljs-attr">trust_host_root_certs:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">tunnels:</span><br> <span class="hljs-attr">a:</span><br>  <span class="hljs-attr">remote_port:</span> <span class="hljs-number">12345</span><br>  <span class="hljs-attr">proto:</span><br>   <span class="hljs-attr">tcp:</span> <span class="hljs-string">&quot;127.0.0.1:25565&quot;</span><br>   <span class="hljs-attr">tcp:</span> <span class="hljs-string">&quot;127.0.0.1:25566&quot;</span><br> <span class="hljs-attr">b:</span><br>  <span class="hljs-attr">proto:</span><br>   <span class="hljs-attr">http:</span> <span class="hljs-string">&quot;127.0.0.1:80&quot;</span><br></code></pre></td></tr></table></figure><p>此文件位YAML格式，<strong>缩进用空格</strong>。</p><p><code>server_addr</code>后填写你的域名，要和之前写的一模一样。</p><p>4443是固定端口，一般不改，但也可以在服务端更改。</p><p>tunnels允许配置文件配置多个隧道，<strong>可以同时启动多个隧道</strong>。</p><p>a和b是隧道名字。</p><p>a中<code>remote_port</code>是远程端口，即访问 <code>xxx.ngrok.example.com:端口</code> 时要输入的端口，假如是http协议则此项无效</p><p>proto是隧道协议，在之下可以<strong>同时用不同协议暴露不同局域网ip地址和端口</strong></p><ul><li><strong>新建一个 启动.bat ，打开写入如下内容</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ngrok -subdomain test -config=ngrok.cfg start a<br></code></pre></td></tr></table></figure><p><code>-subdomain</code>是确定你要用什么三级域名来访问，就是上面xxx的内容。</p><p><code>-config</code>确定配置文件。</p><p><code>start</code>启动隧道，可以<code>start a b c d</code>。</p><p><code>ngrok help</code>可以查看帮助</p><ul><li><strong>双击bat文件运行</strong></li></ul><p>假如出现绿色的online就开启成功。</p><blockquote><p>闪退错误解决</p><ul><li>bat和cfg是否写错</li><li>云主机响应端口是否开放（阿里云服务器要在安全组中设置端口）</li><li>观察服务端的ngrokd输出，假如出现bad certificate，那么就是证书错误，检查你的客户端版本以及服务端用的证书是否统一</li></ul></blockquote><h2 id="Linux后台运行服务端"><a href="#Linux后台运行服务端" class="headerlink" title="Linux后台运行服务端"></a>Linux后台运行服务端</h2><p>由于断开ssh连接后就导致穿透关闭，所以要用<code>screen</code>来后台运行</p><p><strong>安装screen</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt install screen<br></code></pre></td></tr></table></figure><p><strong>screen命令</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">screen -S name<br><span class="hljs-meta">#</span><span class="bash"> 新建一个名字叫name的screen</span><br>screen<br><span class="hljs-meta">#</span><span class="bash"> 新建一个没有名字的screen</span><br>screen -ls<br><span class="hljs-meta">#</span><span class="bash"> 查看当前有多少个screen以及信息</span><br><span class="hljs-meta">#</span><span class="bash"> 结果有Dead：死了 Detached：独立的screen Attched：</span><br>screen -r name|id<br><span class="hljs-meta">#</span><span class="bash"> 通过name或者id来恢复screen</span><br>ctrl+a d<br><span class="hljs-meta">#</span><span class="bash"> 先按ctrl+a 再按d 分离screen，退出到主窗口</span><br>ctrl+a k<br><span class="hljs-meta">#</span><span class="bash"> 杀死当前screen</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>ngrok</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python Logging模块</title>
    <link href="/2021/03/03/Python-Logging-module/"/>
    <url>/2021/03/03/Python-Logging-module/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Logging类"><a href="#Python-Logging类" class="headerlink" title="Python Logging类"></a>Python Logging类</h1><p>Python的Logging类是专门成立程序日志的类，能够方便的输出日志到屏幕、文件等多个地方，能够方便控制如何输出，还能够设置消息级别。</p><ul><li>Logging.Logger：Logger是Logging模块的主体，为程序提供记录日志接口、判断级别、分配给handler。这个对象<strong>不能实例</strong>，应该通过getLogger()来获取。</li><li>Logging.Handler：Handler基于日志级别对日志进行分发，如设置为WARNING级别的Handler只会处理WARNING及以上级别的日志。</li><li>Logging.Filter：Filter是过滤器，可以提供更高级的自定义过滤方式。</li><li>Logging.Formatter: 这个类处理输出格式</li></ul><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/486223_1_En_27_Figa_HTML.png" alt="Logging的结构图"></p><h2 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h2><p><strong>级别排序:  CRITICAL &gt; ERROR &gt; WARNING &gt; INFO &gt; DEBUG</strong></p><p>使用方法如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br>logging.debug(<span class="hljs-string">&quot;张三&quot;</span>)<br>logging.info(<span class="hljs-string">&quot;李四&quot;</span>)<br>logging.warning(<span class="hljs-string">&quot;王五&quot;</span>)<br>logging.error(<span class="hljs-string">&quot;小明&quot;</span>)<br>logging.critical(<span class="hljs-string">&quot;小红&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/QQ%E6%88%AA%E5%9B%BE20200427181133.png" alt="log在控制台的输出"></p><p>默认只显示WARING级别以上。下面代码实现自定义输出级别：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">logging.basicConfig(level=logging.NOTSET)  <span class="hljs-comment"># NOTSET是最低等级</span><br></code></pre></td></tr></table></figure><p>注意！：This function does nothing if the root logger already has handlers configured, unless the keyword argument <em>force</em> is set to <code>True</code>.</p><p>若不使用force参数，则设置输出级别只有第一次有效。<code>force=true</code>能在执行其他参数指定的配置之前，将移除并关闭附加到根记录器的所有现有处理器。</p><p>有一个特殊的日志输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">logger.exception(<span class="hljs-string">&quot;Failed to open sklearn.txt from logger.exception&quot;</span>)<br><span class="hljs-comment"># 这个的输出是traceback的信息</span><br><span class="hljs-comment">#Failed to open sklearn.txt from logger.exception</span><br><span class="hljs-comment">#Traceback (most recent call last):</span><br><span class="hljs-comment">#  File &quot;G:\zhb7627\Code\Eclipse WorkSpace\PythonTest\test.py&quot;, line 23, in &lt;module&gt;</span><br><span class="hljs-comment">#    open(&quot;sklearn.txt&quot;,&quot;rb&quot;)</span><br><span class="hljs-comment">#IOError: [Errno 2] No such file or directory: &#x27;sklearn.txt&#x27;</span><br><br><span class="hljs-comment"># 也可以通过指定参数实现</span><br><span class="hljs-comment"># 下面这条语句和上面等价</span><br>logger.error(<span class="hljs-string">&quot;Faild to open sklearn.txt from logger.error&quot;</span>,exc_info = <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="设置输出格式"><a href="#设置输出格式" class="headerlink" title="设置输出格式"></a>设置输出格式</h2><p>格式有以下几种</p><ul><li>%(levelno)s: 打印日志级别的数值</li><li>%(levelname)s: 打印日志级别名称</li><li>%(pathname)s: 打印当前执行程序的路径，其实就是sys.argv[0]</li><li>%(filename)s: 打印当前执行程序名，如：login.py</li><li>%(funcName)s: 打印日志的当前函数</li><li>%(lineno)d: 打印日志的当前行号,在第几行打印的日志</li><li>%(asctime)s: 打印日志的时间</li><li>%(thread)d: 打印线程ID</li><li>%(threadName)s: 打印线程名称</li><li>%(process)d: 打印进程ID</li><li>%(message)s: 打印日志信息</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过basicConfig来设置格式</span><br><span class="hljs-comment"># basicConfig是默认配置</span><br><span class="hljs-comment"># format是上面的格式字符串</span><br><span class="hljs-comment"># datefmt是和time.strftime()一样的格式字符串</span><br>logging.basicConfig(<br>    <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;</span>，<br>datefmt=<span class="hljs-string">&#x27;%a, %d %b %Y %H:%M:%S&#x27;</span>，<br>)<br></code></pre></td></tr></table></figure><p>注意输出格式在Windows下和Linux下都要符合命名规则。</p><h2 id="日志输出到文件和控制台"><a href="#日志输出到文件和控制台" class="headerlink" title="日志输出到文件和控制台"></a>日志输出到文件和控制台</h2><p>接下来是高级用法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging  <span class="hljs-comment"># 引入logging模块</span><br><span class="hljs-comment"># 第一步，创建一个logger</span><br>logger = logging.getLogger()<br>logger.setLevel(logging.INFO)   <span class="hljs-comment"># Log等级总开关</span><br><span class="hljs-comment"># 第二步，创建一个FileHandler，用于写入日志文件</span><br>handler = logging.FileHandler(<span class="hljs-string">&quot;log.txt&quot;</span>)  <span class="hljs-comment"># 文件名字</span><br>handler.setLevel(logging.INFO)  <span class="hljs-comment"># 单独handler的log等级设置 </span><br><span class="hljs-comment"># 第三步，设置filehandler的格式</span><br>formatter = logging.Formatter(<span class="hljs-string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)<br>handler.setFormatter(formatter)<br><span class="hljs-comment"># 第四步，创建StreamHandler，用于输出到控制台</span><br>console = logging.StreamHandler()<br>console.setLevel(logging.INFO)  <span class="hljs-comment"># 单独handler的log等级设置</span><br><span class="hljs-comment"># 第六步，设置StreamHandler的格式</span><br>console.setFormatter(formatter)<br><span class="hljs-comment"># 第五步，添加handler到logger</span><br>logger.addHandler(handler)<br>logger.addHandler(console)<br><br><span class="hljs-comment"># 日志</span><br>logger.debug(<span class="hljs-string">&#x27;this is a logger debug message&#x27;</span>)<br>logger.info(<span class="hljs-string">&#x27;this is a logger info message&#x27;</span>)<br>logger.warning(<span class="hljs-string">&#x27;this is a logger warning message&#x27;</span>)<br>logger.error(<span class="hljs-string">&#x27;this is a logger error message&#x27;</span>)<br>logger.critical(<span class="hljs-string">&#x27;this is a logger critical message&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="logging-getLogger"><a href="#logging-getLogger" class="headerlink" title="logging.getLogger()"></a>logging.getLogger()</h2><p>这个方法返回一个Logger对象，参数是Logger的名字，get相同名字会返回相同的logger，在不同模块要调用logger的时候永远都不需要传递logger参数，只需要使用这个方法即可。</p><p>示例：<code>logging,getLogger(&quot;hahahaha&quot;)</code></p><p>Logger的名字可以体现继承关系，用<code>.</code>来分隔，子logger继承父logger的配置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">logging.getLogger(<span class="hljs-string">&quot;PythonApp&quot;</span>)<br><br>logging.getLogger(<span class="hljs-string">&quot;PythonApp.Core&quot;</span>)  <span class="hljs-comment"># 继承PythonApp的配置</span><br>logging.getLogger(<span class="hljs-string">&quot;PythonApp.Web&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="logging-Filter"><a href="#logging-Filter" class="headerlink" title="logging.Filter"></a>logging.Filter</h2><p>需要定义一个新的类来自定义过滤规则</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NoParsingFilter</span>(<span class="hljs-params">logging.Filter</span>):</span>  <span class="hljs-comment"># 继承logging.Filter</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter</span>(<span class="hljs-params">self, record</span>):</span>  <span class="hljs-comment"># 重写filter</span><br>    <span class="hljs-keyword">if</span> record.name == <span class="hljs-string">&#x27;PythonApp&#x27;</span> <span class="hljs-keyword">and</span> record.levelno == logging.INFO:<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>  <span class="hljs-comment"># 返回True False来控制是否过滤</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br><br>logger = logging.getLogger(<span class="hljs-string">&#x27;PythonApp&#x27;</span>)<br>logger.addFilter(NoParsingFilter())<br>logger.info(<span class="hljs-string">&quot;info&quot;</span>)<br>logger.error(<span class="hljs-string">&quot;error&quot;</span>)<br></code></pre></td></tr></table></figure><p>record是logging.LogRecord类，有以下属性：</p><ul><li><p>name logger的名字</p></li><li><p>levelno是级别</p></li><li><p>levelname是级别的字符串</p></li><li><p>pathname 是哪个文件输出的这行日志</p></li><li><p>lineno 是行号</p></li><li><p>msg 是日志本身</p></li><li><p>除此以外还有formatter格式化字符串的所有属性</p></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.cnblogs.com/xianyulouie/p/11041777.html">python中logging日志模块详解 - 咸鱼也是有梦想的 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.jb51.net/article/165534.htm">使用Filter过滤python中的日志输出的实现方法</a></p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Logging</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python多线程详解（真的很详细）</title>
    <link href="/2021/03/01/Python-Multithreading-in-detail/"/>
    <url>/2021/03/01/Python-Multithreading-in-detail/</url>
    
    <content type="html"><![CDATA[<h1 id="Python多线程详解"><a href="#Python多线程详解" class="headerlink" title="Python多线程详解"></a>Python多线程详解</h1><p>使用多线程，可以同时进行多项任务，可以使用户界面更友好，还可以后台执行某些用时长的任务，同时具有易于通信的优点。（对于GIL以及Python多线程对于效率的影响讨论可看知乎<a href="https://www.zhihu.com/question/23474039">为什么有人说 Python 的多线程是鸡肋呢？ - 知乎 (zhihu.com)</a>）</p><p>Python3中使用的是threading模块。</p><h2 id="创建和执行一个线程"><a href="#创建和执行一个线程" class="headerlink" title="创建和执行一个线程"></a>创建和执行一个线程</h2><p>一般我们有两种方法来创建线程，一种是以某个函数来作为起点，另一种是继承Thread类。</p><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>获取一个Thread对象，构造参数中target是起点函数，注意不要加括号。假如起点函数有参数，则可以通过args输入元组参数或者kwargs输入字典参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始做一个任务啦&quot;</span>)<br>    time.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 用time.sleep模拟任务耗时</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这个任务结束啦&quot;</span>)<br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = Thread(target=task)<br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    time.sleep(<span class="hljs-number">0.3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程依然可以干别的事&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301190927.png" alt="1.png"></p><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NewThread</span>(<span class="hljs-params">Thread</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        Thread.__init__(self)  <span class="hljs-comment"># 必须步骤</span><br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>(<span class="hljs-params">self</span>):</span>  <span class="hljs-comment"># 入口是名字为run的方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始做一个任务啦&quot;</span>)<br>        time.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 用time.sleep模拟任务耗时</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这个任务结束啦&quot;</span>)<br>        <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = NewThread()<br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    time.sleep(<span class="hljs-number">0.3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程依然可以干别的事&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="正式介绍threading模块"><a href="#正式介绍threading模块" class="headerlink" title="正式介绍threading模块"></a>正式介绍threading模块</h2><p>关于线程信息的函数：</p><ul><li><code>threading.active_count()</code>：返回当前存活的Thread对象数量。</li><li><code>threading.current_thread()</code>：返回当前线程的Thread对象。</li><li><code>threading.enumerate()</code>：列表形式返回所有存活的Thread对象。</li><li><code>threading.main_thread()</code>：返回主Thread对象。</li></ul><p>Thread对象的方法及属性：</p><ul><li><code>Thread.name</code>：线程的名字，没有语义，可以相同名称。</li><li><code>Thread.ident</code>：线程标识符，非零整数。</li><li><code>Thread.Daemon</code>：是否为守护线程。</li><li><code>Thread.is_alive()</code>：是否存活。</li><li><code>Thread.start()</code>：开始线程活动。若多次调用抛出RuntimeError。</li><li><code>Thread.run()</code>：用来重载的，</li><li><code>Thread.join(timeout=None)</code>：等待直到线程正常或异常结束。尚未开始抛出RuntimeError</li><li><code>Thread(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, deamon=None)</code>：构造函数。</li></ul><h3 id="守护线程-Daemon"><a href="#守护线程-Daemon" class="headerlink" title="守护线程 Daemon"></a>守护线程 Daemon</h3><p>如果某个线程是守护线程，那么这个线程会在主线程运行完毕后结束。<em>主线程运行完毕指的是主线程的进程内所有非守护线程全部运行完毕，所以可以理解为守护进程是不那么重要的进程。</em></p><p>设置守护线程用Thread.setDaemon(bool)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task1</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始做任务1啦&quot;</span>)<br>    time.sleep(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 用time.sleep模拟任务耗时</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;任务1结束啦&quot;</span>)<br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task2</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始做任务2啦&quot;</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;任务2-&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i))<br>    time.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;任务2结束啦&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = Thread(target=task1)<br>    t2 = Thread(target=task2)<br>    t2.setDaemon(<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 设置为守护进程，必须在start之前</span><br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    t2.start()<br>    time.sleep(<span class="hljs-number">0.3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程结束了&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191003.png" alt="2"></p><p>运行这段代码用IDLE可能出现守护进程未结束的bug，所以用pycharm或者在命令行里运行可看见真实效果。</p><p><a href="https://www.zhihu.com/question/26826953">关于这个bug的讨论</a></p><h3 id="让主线程等待子线程结束-join"><a href="#让主线程等待子线程结束-join" class="headerlink" title="让主线程等待子线程结束 join"></a>让主线程等待子线程结束 join</h3><p>假如要让主线程等子线程，那么可以使用Thread.join()方法。</p><p>join可以让运行这条语句的主线程在此阻塞（等待），直到子线程结束，再放行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task1</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始做任务1啦&quot;</span>)<br>    time.sleep(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 用time.sleep模拟任务耗时</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;任务1结束啦&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = Thread(target=task1)<br>    <span class="hljs-comment"># t1.setDaemon(True)  # 设置为守护进程，必须在start之前</span><br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    <span class="hljs-comment"># 阻塞</span><br>    t1.join()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程结束了&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191050.png" alt="4"></p><h2 id="由于线程共享资源而引发的bug"><a href="#由于线程共享资源而引发的bug" class="headerlink" title="由于线程共享资源而引发的bug"></a>由于线程共享资源而引发的bug</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><br>n=<span class="hljs-number">0</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task1</span>():</span><br>    <span class="hljs-keyword">global</span> n<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">800000</span>):  <span class="hljs-comment"># 将n循环加800000</span><br>        n += <span class="hljs-number">1</span><br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task2</span>():</span><br>    <span class="hljs-keyword">global</span> n<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;n is &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(n))  <span class="hljs-comment"># 访问n</span><br>    <br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = Thread(target=task1)<br>    t2 = Thread(target=task2)<br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    t2.start()<br>    time.sleep(<span class="hljs-number">0.3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程结束了&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191108.png" alt="3"></p><p>你的结果很可能与我不同，多次执行这个代码的结果也很可能不同。由于这种不确定性，程序有可能出现致命错误，我们称之为<strong>线程不安全</strong>。</p><p>这个问题出现的原因是这样的：t1线程启动后，循环很多次，每次将全局变量n加1，但是加这么多次是要时间的，在t1没有将n加完时，t2线程就对n进行了访问，从而访问到的值可能不是期望值。</p><p><strong>线程安全</strong>的类应该具有以下特征：</p><ul><li>该类的对象可以被多个线程安全地访问</li><li>每个线程在调用该对象的任意方法后，都将得到正确的结果</li><li>每个线程在调用该对象的任意方法后，该对象都依然保持合理的状态</li></ul><p>接下来我们将采取一定的方法来使线程安全。</p><h3 id="锁-Lock-重入锁-RLock"><a href="#锁-Lock-重入锁-RLock" class="headerlink" title="锁 Lock  重入锁 RLock"></a>锁 Lock  重入锁 RLock</h3><p>锁是保证线程安全的一种途径，你可以想象全局变量都存放在一个房间里，只有进入这个房间的人（线程）才能操作全局变量，在许多人进房间的时候，就可能出现混乱。因此他们约定，在门口挂一个牌子，一面写着有人，另一面写着没人，每当有人进出的时候就把牌子翻一面，别人看见这牌子是有人就在门口等着。（这就是锁的获取与释放）。然而既然是约定，就能被打破，有的人可能不知道这个约定，牌子上写着有人他也会进去。（这就是执行没有写锁部分的的方法的线程）</p><p>Python的threading模块中有<strong>Lock</strong>和<strong>RLock</strong>两个类。他们都有这两个方法</p><p><code>Lock.acquire(blocking=True, timeout=-1)</code> 获取锁。</p><ul><li>获取成功返回True，超时或其他返回False</li></ul><ul><li><p>timeout参数指定获取不到锁时等待的时间，单位为秒。</p></li><li><p>blocking参数指定是否阻塞调用，默认获取不到锁就阻塞。</p></li></ul><p><code>Lock.release()</code> 释放锁。</p><ul><li><p>对于Lock，可以从任何线程调用，不一定是上锁的那个线程才能解锁。</p></li><li><p>对于RLock，只能从上锁的线程调用。</p></li></ul><ul><li>对未锁定的锁调用release会引发RuntimeError</li></ul><p><strong>RLock</strong>的R表示Reentrant，如果用RLock，那么在同一个线程中可以对它多次acquire，同时也要用相同数目的release来释放锁。这个东西的意义在于避免<strong>死锁</strong>。</p><blockquote><p>死锁（Deadlock）是指两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。</p></blockquote><p>举个例子，假如你要使用递归函数，这个递归函数中需要对某个全局变量修改，于是你加上了Lock，然而在递归的过程中，第二层递归的acquire就获取不到锁了，于是第一层递归在等待第二层结束，而第二层在等待第一层的release，这就造成了死锁。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191118.jpeg" alt="死锁"></p><p><strong>使用锁可能导致执行速度慢，但是保证了线程安全</strong></p><p>无论是Lock还是RLock，acquire和release都要成对出现，所以一般用这种形式写语句</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">lock.acquire()<br><span class="hljs-keyword">try</span>:<br><span class="hljs-comment"># do something</span><br><span class="hljs-keyword">finally</span>:<br>lock.release()<br></code></pre></td></tr></table></figure><p>使用Lock改进上一次代码的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread, Lock<br><br>lock = Lock()  <span class="hljs-comment"># 创建锁对象</span><br>n=<span class="hljs-number">0</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task1</span>():</span><br>    <span class="hljs-keyword">global</span> n<br>    <span class="hljs-keyword">global</span> lock<br>    lock.acquire()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">800000</span>):<br>        n += <span class="hljs-number">1</span><br>    lock.release()<br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">task2</span>():</span><br>    <span class="hljs-keyword">global</span> n<br>    lock.acquire()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;task2: n is &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(n))<br>    lock.release()<br>    <br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;这里是主线程&quot;</span>)<br>    <span class="hljs-comment"># 创建线程对象</span><br>    t1 = Thread(target=task1)<br>    t2 = Thread(target=task2)<br>    <span class="hljs-comment"># 启动</span><br>    t1.start()<br>    t2.start()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;main: n is &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(n))  <span class="hljs-comment"># 未使用lock的线程仍然访问到错误数据</span><br>    time.sleep(<span class="hljs-number">0.3</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;主线程结束了&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191135.png" alt="7"></p><h3 id="队列-Queue"><a href="#队列-Queue" class="headerlink" title="队列 Queue"></a>队列 Queue</h3><p>Python的queue模块为单独的一个模块，并不在threading里。Queue模拟各种不同的队列，使不同线程之间实现<strong>松耦合</strong>，并且提高效率，经常使用它。</p><p>Python中的queue有三种队列，分别是<code>queue.Queue()</code> <code>queue.LifoQueue()</code> <code>queue.PriorityQueue()</code></p><p><strong>Queue</strong>就是FIFO(First In First Out)先入先出队列。</p><p><strong>LifoQueue</strong>是LIFO(Last In First Out)后入先出队列，对应栈数据结构。</p><p><strong>PriorityQueue</strong>需要你指定添加进队列的数据的重要性，然后队列根据重要性排序，更小的先出。</p><blockquote><p>官方文档：</p><p>最小值先被取出( 最小值条目是由 <code>sorted(list(entries))[0]</code> 返回的条目)。条目的典型模式是一个以下形式的元组： <code>(priority_number, data)</code> 。</p></blockquote><p>也就是说你向PriorityQueue中添加数据时，推荐采用 <code>(priority_number, data)</code> 格式，元组的第一个数据代表优先级，数字越小越先（可以是负数），假如优先级相同，会比较第二个数据，假如不可比较会报错。假如前两个数据都相等，则顺序随机。</p><p>Queue是父类，下面介绍Queue的方法：</p><p><code>Queue(maxsize)</code> 实例化Queue类可提供队列最大值的参数。到达最大值之后的put操作会阻塞。</p><p><code>Queue.put(block=True, timeout=None)</code> 向队列中添加一个数据，同样可以设置阻塞等待时长。超时直接抛出<code>queue.Full</code>错误。</p><p><code>Queue.get(block=True, timeout=None)</code> 从队列中获取一个数据，并从中删除这个数据，超时抛出<code>queue.Empty</code>错误。不设置超时会一直堵塞。</p><p><code>Queue.qsize()</code> 返回队列中数据的量，不怎么可靠，因为获取的同时，其他线程可能进行操作。</p><p><code>Queue.join() </code>队列还存在未完成任务时阻塞，等待知道队列无未完成任务。<strong>注意是任务完成而不是队列为空，需要与task_done联合使用</strong></p><p><code>Queue.task_done()</code> 每put一个数据就会让未完成任务+1，<strong>但是get不会-1</strong>，只有task_done才会-1</p><p>队列为空时报错<code>ValueError</code></p><h4 id="用Queue完成生产者-消费者模型（吃货版）"><a href="#用Queue完成生产者-消费者模型（吃货版）" class="headerlink" title="用Queue完成生产者-消费者模型（吃货版）"></a>用Queue完成生产者-消费者模型（吃货版）</h4><p>生产者消费者模型是一种松耦合模型，生产者互相之间不需要沟通，消费者之间也不需要沟通，生产者和消费者只关系仓库，也就是这里的queue。生产者将数据放入容器，数据流向消费者，消费者从容器中取出数据。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191148.jpeg" alt="模型图"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread, current_thread<br><span class="hljs-keyword">from</span> queue <span class="hljs-keyword">import</span> Queue,Empty<br><br>foods = (<span class="hljs-string">&quot;蒸羊羔&quot;</span>,<span class="hljs-string">&quot;蒸熊掌&quot;</span>,<span class="hljs-string">&quot;蒸鹿尾儿&quot;</span>,<span class="hljs-string">&quot;烧花鸭&quot;</span>,<span class="hljs-string">&quot;烧雏鸡&quot;</span>,<span class="hljs-string">&quot;烧子鹅&quot;</span>,<br>        <span class="hljs-string">&quot;卤猪&quot;</span>,<span class="hljs-string">&quot;卤鸭&quot;</span>,<span class="hljs-string">&quot;酱鸡&quot;</span>,<span class="hljs-string">&quot;腊肉&quot;</span>,<span class="hljs-string">&quot;松花&quot;</span>,<span class="hljs-string">&quot;小肚儿&quot;</span>,<span class="hljs-string">&quot;晾肉&quot;</span>,<span class="hljs-string">&quot;香肠&quot;</span>,<br>        <span class="hljs-string">&quot;什锦苏盘&quot;</span>,)  <span class="hljs-comment"># 食物列表</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">producer</span>(<span class="hljs-params">queue</span>):</span>  <span class="hljs-comment"># 生产者</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[&#123;&#125;]厨师来了&#x27;</span>.<span class="hljs-built_in">format</span>(current_thread().name))  <br>    <span class="hljs-comment"># current_thread()返回一个Thread对象，其有一个name属性，表示线程的名字</span><br>    <span class="hljs-keyword">global</span> foods<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment"># 上十道菜，每道菜加工0.8s</span><br>        food = random.choice(foods)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[&#123;&#125;]正在加工&#123;&#125;中.....&#x27;</span>.<span class="hljs-built_in">format</span>(current_thread().name,food))<br>        time.sleep(<span class="hljs-number">0.8</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[&#123;&#125;]上菜了...&#x27;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br>        queue.put(food)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">consumer</span>(<span class="hljs-params">queue</span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[&#123;&#125;]客人来了&#x27;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:  <span class="hljs-comment"># 每道菜吃0.5s，等上菜的耐心是0.5s</span><br>        <span class="hljs-keyword">try</span>:<br>            food = queue.get(timeout=<span class="hljs-number">0.5</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[&#123;&#125;]正在享用美食:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(current_thread().name,food))<br>            time.sleep(<span class="hljs-number">0.5</span>)<br>        <span class="hljs-keyword">except</span> Empty:  <span class="hljs-comment"># get不到会抛出Empty</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;没菜吃了，[&#123;&#125;]走了&quot;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br>            <span class="hljs-keyword">break</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    queue = Queue()<br>    pds = []  <span class="hljs-comment"># 生产者列表</span><br>    csm = []  <span class="hljs-comment"># 消费者列表</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>        t = Thread(target=producer, args=(queue,))  <span class="hljs-comment"># 由于参数是元组，所以末尾加逗号</span><br>        t.start()<br>        pds.append(t)<br>    time.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>        t = Thread(target=consumer, args=(queue,))<br>        t.start()<br>        csm.append(t)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191156.png" alt="8"></p><h2 id="线程池-thread-pool"><a href="#线程池-thread-pool" class="headerlink" title="线程池  thread pool"></a>线程池  thread pool</h2><p>虽然线程比进程简单许多，但是系统启动一个新线程的成本依旧很高。线程池创建时会<strong>自动创建</strong>一定空闲的线程，我们将一个函数（任务）提交给线程池，线程池就会调用一个空闲的进程来执行它，当函数结束时，线程不死亡，而是返回到线程池中等待执行下一个函数（任务）。</p><p><strong>当程序中需要创建大量生存期短暂的线程时，可考虑线程池</strong></p><p><strong>当程序中需要控制并发线程时，可考虑线程池</strong></p><p>python中有<strong>concurrent.futures</strong>模块，线程池的基类是Executor，其有两个子类，即 <strong>ThreadPoolExecutor</strong> 和 <strong>ProcessPoolExecutor</strong>，其中 <strong>ThreadPoolExecutor</strong> 用于创建线程池，而 <strong>ProcessPoolExecutor</strong> 用于创建进程池。</p><p><strong>Exectuor</strong> 提供了如下常用方法：</p><ul><li><code>submit(fn, *args, **kwargs)</code>：将 fn 函数提交给线程池。<em>args 代表传给 fn 函数的参数，</em>kwargs 代表以关键字参数的形式为 fn 函数传入参数。</li><li><code>map(func, *iterables, timeout=None, chunksize=1)</code>：该函数类似于全局函数 <code>map(func, *iterables)</code>，只是该函数将会启动多个线程，以异步方式立即对 iterables 执行 map 处理。超时抛出TimeoutError错误。返回每个函数的结果，<strong>注意不是返回future</strong>。</li><li><code>shutdown(wait=True)</code>：关闭线程池。关闭之后线程池不再接受新任务，但会将之前提交的任务完成。</li></ul><p>程序将task函数submit给线程池后，会返回一个Future对象，Future主要用来获取task的返回值。</p><blockquote><p>由于结果不确定，对于当时是的未来的对象，所以取名future。</p></blockquote><p><strong>Future</strong> 提供了如下方法：</p><ul><li><code>cancel()</code>：取消该 Future 代表的线程任务。如果该任务正在执行，不可取消，则该方法返回 False；否则，程序会取消该任务，并返回 True。</li><li><code>cancelled()</code>：返回 Future 代表的线程任务是否被成功取消。</li><li><code>running()</code>：如果该 Future 代表的线程任务正在执行、不可被取消，该方法返回 True。</li><li><code>done()</code>：如果该 Funture 代表的线程任务被成功取消或执行完成，则该方法返回 True。</li><li><code>result(timeout=None)</code>：获取该 Future 代表的线程任务最后返回的结果。如果 Future 代表的线程任务还未完成，该方法将会阻塞当前线程，其中 timeout 参数指定最多阻塞多少秒。超时抛出TimeoutError，取消抛出CancelledError。</li><li><code>exception(timeout=None)</code>：获取该 Future 代表的线程任务所引发的异常。如果该任务成功完成，没有异常，则该方法返回 None。</li><li><code>add_done_callback(fn)</code>：为该 Future 代表的线程任务注册一个“回调函数”，当该任务成功完成时，程序会自动触发该 fn 函数，参数是future。</li></ul><p>使用线程池来执行线程任务的步骤如下：</p><ol><li>调用 ThreadPoolExecutor 类的构造器创建一个线程池。</li><li>定义一个普通函数作为线程任务。</li><li>调用 ThreadPoolExecutor 对象的 submit() 方法来提交线程任务。</li><li>当不想提交任何任务时，调用 ThreadPoolExecutor 对象的 shutdown() 方法来关闭线程池。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># 定义一个准备作为线程任务的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">action</span>(<span class="hljs-params"><span class="hljs-built_in">max</span></span>):</span><br>    my_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>):<br>        <span class="hljs-built_in">print</span>(threading.current_thread().name + <span class="hljs-string">&#x27;  &#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        my_sum += i<br>    <span class="hljs-keyword">return</span> my_sum<br><span class="hljs-comment"># 创建一个包含2条线程的线程池</span><br>pool = ThreadPoolExecutor(max_workers=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 向线程池提交一个task, 50会作为action()函数的参数</span><br>future1 = pool.submit(action, <span class="hljs-number">50</span>)<br><span class="hljs-comment"># 向线程池再提交一个task, 100会作为action()函数的参数</span><br>future2 = pool.submit(action, <span class="hljs-number">100</span>)<br><span class="hljs-comment"># 判断future1代表的任务是否结束</span><br><span class="hljs-built_in">print</span>(future1.done())<br>time.sleep(<span class="hljs-number">3</span>)<br><span class="hljs-comment"># 判断future2代表的任务是否结束</span><br><span class="hljs-built_in">print</span>(future2.done())<br><span class="hljs-comment"># 查看future1代表的任务返回的结果</span><br><span class="hljs-built_in">print</span>(future1.result())<br><span class="hljs-comment"># 查看future2代表的任务返回的结果</span><br><span class="hljs-built_in">print</span>(future2.result())<br><span class="hljs-comment"># 关闭线程池</span><br>pool.shutdown()<br></code></pre></td></tr></table></figure><p>下列程序使用 Executor 的 map() 方法来启动线程，并收集线程任务的返回值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># 定义一个准备作为线程任务的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">action</span>(<span class="hljs-params"><span class="hljs-built_in">max</span></span>):</span><br>    my_sum = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>):<br>        <span class="hljs-built_in">print</span>(threading.current_thread().name + <span class="hljs-string">&#x27;  &#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        my_sum += i<br>    <span class="hljs-keyword">return</span> my_sum<br><span class="hljs-comment"># 创建一个包含2条线程的线程池</span><br><span class="hljs-comment"># 线程池支持上下文管理协议，用with可以避免忘记写shutdown</span><br><span class="hljs-keyword">with</span> ThreadPoolExecutor(max_workers=<span class="hljs-number">2</span>) <span class="hljs-keyword">as</span> pool:<br>    <span class="hljs-comment"># 使用线程执行map计算</span><br>    <span class="hljs-comment"># 后面元组有3个元素，因此程序启动3次线程来执行action函数</span><br>    results = pool.<span class="hljs-built_in">map</span>(action, (<span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">150</span>))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;--------------&#x27;</span>)<br>    <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> results:<br>        <span class="hljs-built_in">print</span>(r)<br></code></pre></td></tr></table></figure><p>上面程序使用 map() 方法来启动 3 个线程，但是线程池最多两个线程，所以在输出中你可以看到，刚开始是两个线程都在输出，到后面线程1先被执行完毕，接了<code>action(150)</code>的活，于是后面输出的都是线程1了。</p><p>通过上面程序可以看出，使用 map() 方法来启动线程，并收集线程的执行结果，不仅具有代码简单的优点，而且虽然程序会以并发方式来执行 action() 函数，但最后收集的 action() 函数的执行结果，依然与传入参数的结果保持一致。也就是说，上面 results 的第一个元素是 action(50) 的结果，第二个元素是 action(100) 的结果，第三个元素是 action(150) 的结果。</p><h2 id="信号量-semaphore"><a href="#信号量-semaphore" class="headerlink" title="信号量 semaphore"></a>信号量 semaphore</h2><p>信号量和线程池非常相似。信号量也可以用来控制并发的线程数，它初始化时设定一个计数器，每次<code>acquire()</code>让计数器-1，<code>release()</code>让计数器+1，这个计数器不会小于零，当它为零时，下一个<code>acquire()</code>要等待另一个线程的<code>release()</code>，从而控制实际工作的线程数量。</p><p>可以把它理解为多把相同的锁Locks。</p><p>信号量与线程池的区别：</p><ul><li>信号量需要手动创建线程，线程池自动创建线程。</li><li>信号量需要手动通过<code>acquire()</code>和<code>release()</code>来限流，线程池只用指定任务，其他自动。</li><li>信号量你创建了多少个线程就有多少个线程，没有获得(acquire)信号(semaphore)的线程等待，可能造成内存开销增大。</li></ul><p>信号量类的函数介绍</p><ul><li><code>acquire(blocking=True, timeout=None)</code>：返回是否成功调用，超时返回false</li><li><code>release()</code>：释放一个信号量</li><li><code>Semaphore(value=1)</code>：构造函数，只有一个参数。</li></ul><p>下列代码介绍了信号量的使用以及与线程池的使用方法不同</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> concurrent.futures <span class="hljs-keyword">import</span> ThreadPoolExecutor<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment">## 线程池使用</span><br><span class="hljs-comment"># 定义一个准备作为线程任务的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">action1</span>(<span class="hljs-params"><span class="hljs-built_in">max</span></span>):</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>):<br>        <span class="hljs-built_in">print</span>(threading.current_thread().name + <span class="hljs-string">&#x27;  &#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        time.sleep(<span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 创建一个包含3条线程的线程池</span><br>beg = time.perf_counter()<br>futures = []<br><span class="hljs-keyword">with</span> ThreadPoolExecutor(max_workers=<span class="hljs-number">3</span>) <span class="hljs-keyword">as</span> pool:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>        futures.append(pool.submit(action1,<span class="hljs-number">5</span>))        <br><span class="hljs-keyword">for</span> future <span class="hljs-keyword">in</span> futures:<br>    future.result()<br>end = time.perf_counter()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;time use: &quot;</span>,end-beg)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;----------&quot;</span>)<br><br><span class="hljs-comment">## 信号量使用</span><br>sem = threading.Semaphore(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 定义一个有三个信号的信号量</span><br><span class="hljs-comment"># 定义一个准备作为线程任务的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">action2</span>(<span class="hljs-params"><span class="hljs-built_in">max</span></span>):</span><br>    sem.acquire()  <span class="hljs-comment"># 需要手动获得信号</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>):<br>        <span class="hljs-built_in">print</span>(threading.current_thread().name + <span class="hljs-string">&#x27;  &#x27;</span> + <span class="hljs-built_in">str</span>(i))<br>        time.sleep(<span class="hljs-number">0.1</span>)<br>    sem.release()  <span class="hljs-comment"># 需要手动释放信号</span><br><br>beg = time.perf_counter()<br><span class="hljs-comment"># 创建6个线程，都开始</span><br>threads = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>    t = threading.Thread(target=action2,args=(<span class="hljs-number">5</span>,))<br>    threads.append(t)<br>    t.start()<br><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> threads:<br>    t.join()<br>end = time.perf_counter()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;time use: &quot;</span>,end-beg)<br></code></pre></td></tr></table></figure><p>结果统计了时间，发现在线程池中线程数量和信号量相同时，耗时也几乎相同。</p><h2 id="事件-event"><a href="#事件-event" class="headerlink" title="事件 event"></a>事件 event</h2><p>假如其他线程知道另一个线程的某种状态才能进行下一步操作，就可以使用事件event来处理。这几乎是最简单的一个机制。</p><p>函数介绍：</p><ul><li><code>is_set()</code>：当事件发生时（内部标志为True时）返回True</li><li><code>set()</code>：通告事件发生（将内部标志设为True）</li><li><code>clear()</code>：重置为未发生（将内部标志设为False）</li><li><code>wait(timeout=None)</code>：阻塞线程直到事件发生，超时返回False。</li></ul><p>下列代码通过考试的例子说明事件的使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> threading<br><br>ExamBegEvent = threading.Event()<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">student</span>(<span class="hljs-params"><span class="hljs-built_in">id</span></span>):</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;学生[&#123;&#125;]等待考试开始&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">id</span>))<br>    ExamBegEvent.wait()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;学生[&#123;&#125;]开始考试&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">id</span>))<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">teacher</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;老师：开始考试！！&quot;</span>)<br>    ExamBegEvent.<span class="hljs-built_in">set</span>()<br>    <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">6</span>):<br>    threading.Thread(target=student, args=(i,)).start()<br>time.sleep(<span class="hljs-number">3</span>)<br>threading.Thread(target=teacher).start()<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191213.png" alt="9"></p><h2 id="条件变量-Condition"><a href="#条件变量-Condition" class="headerlink" title="条件变量 Condition"></a>条件变量 Condition</h2><p>这玩意我看了各种博主的各种教程，发现都看不懂，于是钻研了下官方文档，也是一知半解。</p><p>下面介绍我理解的某种条件下使用条件变量的方法。</p><p>Condition和某种锁相关联，但是他可以自动创建锁，服从上下文管理协议，用with方便，</p><blockquote><p><code>acquire()</code>和<code>release()</code>用来请求底层锁，像我这种不懂的就不要用了</p></blockquote><ul><li><code>wait(timeout=None)</code>：等待直到被通知(notify)，超时返回False。</li><li><code>wait_for(predicate, timeout=None)</code>：等待直到条件为真。predicate是一个可调用对象且返回值是布尔类型。这个方法会重复调用<code>wait()</code>直到满足判断。超时返回False</li><li><code>notify(n=1)</code>：唤醒处于wait状态（等待这个条件）的n个线程</li><li><code>notify_all()</code>：唤醒处于wait状态（等待这个条件）的所有线程</li></ul><p>使用条件变量的典型情况是将锁用于同步某些共享状态的权限，那些对某些状态的特定改变感兴趣的线程，它们应该重复调用<code>wait()</code>，直到看到所期望的改变发生；而对于修改某个状态的线程，修改完后调用<code>notify()</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 消费一个东西</span><br><span class="hljs-keyword">with</span> cv:<br><span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> an_item_is_availabe():<br>        cv.wait()<br>    get_an_available_item()<br>    <br><span class="hljs-comment"># 消费一个东西的另一种写法</span><br><span class="hljs-keyword">with</span> cv:<br>    cv.wait_for(an_item_available)<br>    get_an_available_item()<br>    <br><span class="hljs-comment"># 生产一个东西</span><br><span class="hljs-keyword">with</span> cv:<br>    make_an_item_available()<br>    cv.notify()<br></code></pre></td></tr></table></figure><h2 id="定时器-Timer"><a href="#定时器-Timer" class="headerlink" title="定时器 Timer"></a>定时器 Timer</h2><p>是Thread的子类，像一个自定义线程一样。</p><p>定时器的函数介绍：</p><ul><li><p><code>Timer(interval, function, args, kwargs)</code>：指定延时的事件和要执行的函数和参数。</p></li><li><p><code> Timer.start()</code>：开启定时器，经过一定事件后执行。</p></li><li><p><code>Timer.cancel()</code>：取消定时器。</p></li></ul><h2 id="栅栏-Barrier"><a href="#栅栏-Barrier" class="headerlink" title="栅栏 Barrier"></a>栅栏 Barrier</h2><p>与其叫栅栏，不如叫开车对象。这个类的功能是等人齐就发车。并且一趟车走之后自动开启下一趟车，</p><p>翻车条件：超时、强行abort。</p><p>抛出错误条件：wait的时候翻车，wait的时候发新车。</p><p>下面介绍Barrier的函数和属性： </p><ul><li><code>Barrier(parties, action=None, timeout=None)</code>：parties是数量，当阻塞的线程到达这个数量是就放行（当乘客到达这个数字时就发车）。action是随机抽取一个幸运线程，发车时让这个线程先执行action函数再干自己的事。超时后翻车。</li><li><code>wait(timeout=None)</code>：线程上车，等开车，这里的timeout会<strong>覆盖</strong>Barrier的timeout，超时会强行发车。返回一个范围在0到parties-1的整数，每个线程都不同，可用于从所有线程中选择唯一的一个线程执行一些特别的工作。如果车翻了抛出BrokenBarrierError错误。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">i = barrier.wait()<br><span class="hljs-keyword">if</span> i==<span class="hljs-number">0</span>:  <br><span class="hljs-comment"># do something</span><br></code></pre></td></tr></table></figure><ul><li><code>reset()</code>：重置Barrier的状态，即再发一辆新车。假如有人上了旧车，那些人会抛出BrokenBarrierError错误</li><li><code>abort()</code>：一般用来防止死锁，强行翻车。通常给Barrier设置超时时间而不用这个。</li><li><code>parties</code>：发车需要的人数量。</li><li><code>n_waiting</code>：正在车上的人的数量。</li><li><code>broken</code>：布尔值，栅栏有没有烂，即车有没有翻。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread, current_thread, Barrier, BrokenBarrierError<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lucky</span>():</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[&#123;&#125;]成为了司机！！&quot;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br><br>car = Barrier(<span class="hljs-number">3</span>, action=lucky)  <span class="hljs-comment"># 三轮车</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">people</span>():</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[&#123;&#125;]要上车！！&quot;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br>        car.wait()<br>    <span class="hljs-keyword">except</span> BrokenBarrierError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[&#123;&#125;]要上的车翻啦~QWQ&quot;</span>.<span class="hljs-built_in">format</span>(current_thread().name))<br><br><span class="hljs-comment"># 四人准备上车</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>    t = Thread(target=people)<br>    t.start()<br>    <br>time.sleep(<span class="hljs-number">0.5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;现在有&#123;&#125;人在等车&quot;</span>.<span class="hljs-built_in">format</span>(car.n_waiting))<br><br>car.reset() <span class="hljs-comment"># 再开一辆</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;现在这辆车不要啦~&quot;</span>)<br><br>t1 = Thread(target=people)<br>t2 = Thread(target=people)<br>t1.start()<br>t2.start()<br>time.sleep(<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;现在有&#123;&#125;人在等车&quot;</span>.<span class="hljs-built_in">format</span>(car.n_waiting))<br>car.abort()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;翻车啦！&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301191223.png" alt="10"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p><a href="http://c.biancheng.net/view/2617.html">http://c.biancheng.net/view/2617.html</a></p><p><a href="https://blog.csdn.net/luohuacanyue/article/details/14648185">https://blog.csdn.net/luohuacanyue/article/details/14648185</a></p><p><a href="http://c.biancheng.net/view/2627.html">http://c.biancheng.net/view/2627.html</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>多线程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Video Captioning相关论文调查</title>
    <link href="/2021/03/01/Video-Caption-Related-Papers/"/>
    <url>/2021/03/01/Video-Caption-Related-Papers/</url>
    
    <content type="html"><![CDATA[<h1 id="Video-Captioning相关论文调查"><a href="#Video-Captioning相关论文调查" class="headerlink" title="Video Captioning相关论文调查"></a>Video Captioning相关论文调查</h1><p>不是一个综述，不会全面解析论文，只是一个调查笔记，而且本人水平不高，部分地方可能有错误。</p><p>对目前基于深度学习的Video Captioning(视频描述)的论文进行调查，统计现在得到的最好结果。</p><h2 id="S2VT"><a href="#S2VT" class="headerlink" title="S2VT"></a>S2VT</h2><p><em>S. Venugopalan, M. Rohrbach, J. Donahue, R. J. Mooney, T. Darrell, and K. Saenko. Sequence to sequence - video to text. In ICCV, 2015</em></p><p><strong>代码实现</strong>：</p><ul><li>官方caffe：<a href="https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt">https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt</a></li><li>复现pytorch：<a href="https://github.com/xiadingZ/video-caption.pytorch">xiadingZ/video-caption.pytorch: pytorch implementation of video captioning (github.com)</a></li><li>我的复现（pytorch）（暂未完成，最新可看readme）：<a href="https://github.com/Kamino666/S2VT-video-caption">Kamino666/S2VT-video-caption: the recurrence of paper “Sequence to Sequence – Video to Text” (github.com)</a></li></ul><p><strong>论文简介</strong>：</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301112335.png" alt="image-20210301112335348" style="zoom:50%;" /><p>大概结构如图，对于视频图像，使用预训练的CNN网络，对视频的每一帧进行特征的提取，每个视频会得到一个[len, feat_dim]的特征，其中每个视频的len不相同。视频的图像输入，可以是RGB图像也可以是光流图。论文中RGB用VGG16，光流图用AlexNet提取feature。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301112655.png" alt="红色为图像层，绿色为文字层"></p><p>训练时，之前由CNN提取的不定长的feature，在编码阶段逐步送进图像层，在图像输入结束后，给文字层提供<code>&lt;BOS&gt;</code>标志开始预测文字，预测到文字层输出<code>&lt;EOS&gt;</code>结束。这样实现了输入和输出都能不定长度。文字层的输入由图像层的输出结合文字输入得到（这里的结合是在hid之前那个维度上的拼接）。</p><p>由于要保持格式不变，在图像输入结束之前，给文字层提供的文字数据是<code>&lt;pad&gt;</code>，在图像输入之后，给图像层提供的图像数据是<code>&lt;pad&gt;</code>。<code>&lt;pad&gt;</code>在实现中简单填充为0.</p><p>注意实现的时候这两层的输入大小不同，得分成两个CNN。</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 29.8%，M-VAD数据集 METEOR 6.7%，MPII-MD数据集 METEOR 7.1%。</p><h2 id="Multimodal-Memory-Modelling"><a href="#Multimodal-Memory-Modelling" class="headerlink" title="Multimodal Memory Modelling"></a>Multimodal Memory Modelling</h2><p><em>Wang J, Wang W, Huang Y, et al. M3: Multimodal memory modelling for video captioning. CVPR, IEEE 2018</em></p><p><strong>论文简介</strong>：</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301113305.png" alt="image-20210301090931120" style="zoom: 67%;" /><p>对记忆建模（Memory Modeling），主要处理长视频，比较复杂，没深入研究。</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 33.3%，MSR-VTT数据集 METEOR 26.58%。</p><h2 id="MRS（Multi-Representation-Switching）"><a href="#MRS（Multi-Representation-Switching）" class="headerlink" title="MRS（Multi-Representation Switching）"></a>MRS（Multi-Representation Switching）</h2><p><em>Heechan Kim, Soowon Lee. A Video Captioning Method Based on Multi-Representation Switching for Sustainable Computing. Sustainability 2021</em></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301115135.png" alt="image-20210301115135156"></p><p>比较新的一篇论文，在Sustainability上发的，所以注重可持续计算，网络不大。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301120022.png" alt="image-20210301120022647"></p><p>作者的思想就是认为在Video Caption生成的句子中，有的单词是要依靠画面来生成的，而有的单词只是语法需要，比如图中“a baby is dancing on a chair”，只有标了颜色的那几个单词是要从画面中提取的，其余都是语法上的要求。</p><p>所以作者分别弄了行为特征模块和文字特征模块，通过一个switcher来学习使用哪个模块。</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 34.0%。</p><h2 id="RecNet"><a href="#RecNet" class="headerlink" title="RecNet"></a>RecNet</h2><p><em>Bairui Wang, Lin Ma, Wei Zhang, Wei Liu. Reconstruction Network for Video Captioning. arxiv 1803.11438</em></p><p><a href="https://zhuanlan.zhihu.com/p/79810631">Reconstruction Network for Video Captioning - 知乎 (zhihu.com)</a></p><p><strong>论文简介</strong></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301120712.png" alt="image-20210301120712622"></p><p>腾讯AI实验室的一篇论文，在解码器后面新增了一个Reconstructor。Encoder和Decoder不是重点，可以用注意力机制的模型，也可以用S2VT。</p><p>重点是Reconstructor，Reconstructor是搭建在解码器之上的，旨在根据解码器的隐状态h，恢复原视频信息。但是考虑到原视频帧的多样性以及较高的维度，这种方案较为棘手。因此重建为由编码器得到的视觉特征也是个很好的选择。Reconstructor可以加强视觉序列和caption之间的关系，有望于改善video caption的质量。在具体实现上，Reconstructor是一个LSTM，文中提供两种结构的Reconstructor，分别是侧重于原始视频的全局结构和局部结构。</p><p>（这一部分还待更仔细看一看论文，预计会专门写一篇感想。）</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 34.1%。</p><h2 id="OA-BTG"><a href="#OA-BTG" class="headerlink" title="OA-BTG"></a>OA-BTG</h2><p><em>Junchao Zhang and Yuxin Peng, Object-aware Aggregation with Bidirectional Temporal Graph for Video Captioning, 2019 CVPR.</em> </p><p><a href="https://zhuanlan.zhihu.com/p/73935242">使用双向时空图做视频描述(video captioning) - 知乎 (zhihu.com)</a></p><p><strong>论文简介</strong>：</p><p>太复杂了，不适用于我目前的研究。但是这篇论文是目前找到的效果最好的。(但是有点作弊的是它输入数据还手动分隔了对象的区域)</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 36.2%， MSR-VTT数据集 METEOR 28.2%。</p><h2 id="multirate-GRU"><a href="#multirate-GRU" class="headerlink" title="multirate GRU"></a>multirate GRU</h2><p><em>Linchao Zhu, Zhongwen Xu, Yi Yang. Bidirectional Multirate Reconstruction for Temporal Modeling in Videos. 2016, arxiv 1611.09053v1.</em></p><p><strong>论文简介</strong>：</p><p>不是专门弄video caption的，论文中提到的很少。论文主要是用到了多速率GRU的技术，即让GRU有的一个一个读，有的隔一个读，有的隔两个，这样形成不同的速率。没有仔细读这篇论文，仅记录下效果。</p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 33.4%</p><h2 id="GRU-EVE"><a href="#GRU-EVE" class="headerlink" title="GRU-EVE"></a>GRU-EVE</h2><p><em>Nayyer Aafaq, Naveed Akhtar et. Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning. 2019, arxiv 1902.10322v2.</em></p><p><a href="https://blog.csdn.net/chr1991/article/details/103806439">论文介绍–Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning_信道者-CSDN博客 </a></p><p><strong>论文简介</strong>：</p><p>挺复杂的，结合了2D-CNN 3D-CNN和对象识别三个数据来源，还用了一个什么傅里叶变换.第一就是用层级的短时傅里叶变换对卷积网络提取出来的特征进行浓缩，把时间信息融入其中；第二就是用物体检测模型从视频中提取高层的语义信息，丰富编码器提炼的视频表示。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301130437.png" alt="image-20210301090845060"></p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 35.0%， MSR-VTT数据集 METEOR 28.4%</p><h2 id="SibNet"><a href="#SibNet" class="headerlink" title="SibNet"></a>SibNet</h2><p><em>Sheng Liu, Zhou Ren, Junsong Yuan. SibNet: Sibling Convolutional Encoder for Video Captioning. <a href="https://doi.org/10.1145/3240508.3240667">https://doi.org/10.1145/3240508.3240667</a></em></p><p><strong>论文简介</strong>：</p><p>重点在于encode videos。编码分成两部分，一部分用自编码器，另一部分用一种视觉语义互相组合embed的编码（目前理解也是非监督学习）。然后这两个编码再解码生成caption，这三部分都有train_loss。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210301131059.png" alt="image-20210301090803104"></p><p><strong>实验结果</strong>：</p><p>MSVD数据集 METEOR 34.8%， MSR-VTT数据集 METEOR 27.5%</p><h1 id="MSVD数据集汇总"><a href="#MSVD数据集汇总" class="headerlink" title="MSVD数据集汇总"></a>MSVD数据集汇总</h1><table><thead><tr><th>模型名字</th><th>METEOR</th></tr></thead><tbody><tr><td>S2VT</td><td>29.8</td></tr><tr><td>M^3^-C3D+InceptionV3</td><td>33.3</td></tr><tr><td>MRS-ew+</td><td>34.0</td></tr><tr><td>RecNet<del>local</del>(SA-LSTM)</td><td>34.1</td></tr><tr><td>OA-BTG</td><td>36.2</td></tr><tr><td>mGRU</td><td>34.5</td></tr><tr><td>GRU-EVE</td><td>35.0</td></tr><tr><td>SibNet</td><td>34.8</td></tr></tbody></table><h1 id="MSR-VTT数据集汇总"><a href="#MSR-VTT数据集汇总" class="headerlink" title="MSR-VTT数据集汇总"></a>MSR-VTT数据集汇总</h1><table><thead><tr><th>模型名字</th><th>METEOR</th></tr></thead><tbody><tr><td>M^3^</td><td>26.6</td></tr><tr><td>OA-BTG</td><td>28.2</td></tr><tr><td>RecNet</td><td>26.6</td></tr><tr><td>GRU-EVE</td><td>28.4</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux常用打包、压缩、解压指令</title>
    <link href="/2021/02/23/Linux%E5%B8%B8%E7%94%A8%E6%89%93%E5%8C%85%E3%80%81%E5%8E%8B%E7%BC%A9%E3%80%81%E8%A7%A3%E5%8E%8B%E6%8C%87%E4%BB%A4/"/>
    <url>/2021/02/23/Linux%E5%B8%B8%E7%94%A8%E6%89%93%E5%8C%85%E3%80%81%E5%8E%8B%E7%BC%A9%E3%80%81%E8%A7%A3%E5%8E%8B%E6%8C%87%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux常用打包、压缩、解压指令"><a href="#Linux常用打包、压缩、解压指令" class="headerlink" title="Linux常用打包、压缩、解压指令"></a>Linux常用打包、压缩、解压指令</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p><strong>打包</strong>是指将一大堆文件或目录打包为一个文件。</p><p><strong>压缩</strong>是将一个大文件通过某些压缩算法压缩为一个更小的文件。</p><p>Linux很多压缩程序只能针对一个文件进行压缩，要压缩很多文件时，要<strong>先打包再压缩。</strong></p><h2 id="tar命令"><a href="#tar命令" class="headerlink" title="tar命令"></a>tar命令</h2><p>tar命令可以为Linux的文件和目录创建档案。tar可以进行打包、压缩、解压三种操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># tar命令基本格式</span></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 必须包含-f 以及解包或者打包或者查看的指令</span></span><br>tar [指令] [参数（若需要）] <br><span class="hljs-meta">   #</span><span class="bash"><span class="hljs-comment"># 下面这两行命令是等价的</span></span><br>tar -c -v -f new.tar /home/tmp/file/<br>tar -cvf new.tar /home/tmp/file/<br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 常用参数</span></span> <br>-c  # create 建立新文件（打包或者压缩）<br>-x  # extract 解压，解包<br>-t  # list 列出备份文件内容<br>-r  # renew 添加文件到已经压缩的文件<br>-f  # file 作为最后一个参数 ，表示新建的文件名，可以随意指定后缀名，但最好用指定的名字。Linux不根据后缀名识别文件类型。<br><br>-v  # verbose 打包或者解压时显示详细信息<br>-C  # 大写的C 解压、解包到某特定目录<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## 压缩参数</span></span><br>-z  # 用gzip命令处理  .tar.gz<br>-j  # 用bzip2命令处理  .tar.bz2<br><br>tar -cvf new.tar ./file/  # 将./file/目录下所有文件打包为new.tar，并保存在当前目录，过程显示详细信息<br>tar -cvf new.tar ./file1/ ./file2/  # 可以一次包含多个目录<br>tar -tvf new.tar  # 不解包的情况下查看包内文件信息<br>tar -xvf new.tar -C ./file3/ # 解压new,tar到另一个目录<br>tar -rvf new.tar ./file4/  # 向new.tar中加入新的目录<br></code></pre></td></tr></table></figure><h2 id="其他压缩命令"><a href="#其他压缩命令" class="headerlink" title="其他压缩命令"></a>其他压缩命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">## zip .zip</span></span><br>zip new.zip ./file  # 压缩<br>-m  # 压缩后删除源文件<br>-q  # 安静模式<br>-o  # 将文件最新变动时间更新<br>-r  # 压缩目录<br>-S  # 大写S 包含系统和隐藏文件<br>-[1-9]  # 压缩效率 1表示最快<br>unzip new.zip  # 解压<br>-n  # 解压时不覆盖原有文件<br>-o  # 解压后覆盖原有文件<br>-q  # 安静模式<br>-P [密码]  # 解压密码<br>-d [目录]  # 选择解压目录<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LaTex Math语法</title>
    <link href="/2021/02/23/LaTex%20Math%E8%AF%AD%E6%B3%95/"/>
    <url>/2021/02/23/LaTex%20Math%E8%AF%AD%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="LaTeX-Math语法"><a href="#LaTeX-Math语法" class="headerlink" title="LaTeX Math语法"></a>LaTeX Math语法</h1><p>一个充满干货的速查语法文章。</p><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><p>使用<code>$字母语法$</code>来使用，首字母大小写决定了希腊字母的大小写</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex">$\Gamma$ $\gamma$<br></code></pre></td></tr></table></figure><p>$\Gamma$ $\gamma$</p><table><thead><tr><th>字母</th><th>实现</th><th>字母</th><th>实现</th></tr></thead><tbody><tr><td>A</td><td><code>A</code></td><td>α</td><td><code>\alhpa</code></td></tr><tr><td>B</td><td><code>B</code></td><td>β</td><td><code>\beta</code></td></tr><tr><td>Γ</td><td><code>\Gamma</code></td><td>γ</td><td><code>\gamma</code></td></tr><tr><td>Δ</td><td><code>\Delta</code></td><td>δ</td><td><code>\delta</code></td></tr><tr><td>E</td><td><code>E</code></td><td>ϵ</td><td><code>\epsilon</code></td></tr><tr><td>Z</td><td><code>Z</code></td><td>ζ</td><td><code>\zeta</code></td></tr><tr><td>H</td><td><code>H</code></td><td>η</td><td><code>\eta</code></td></tr><tr><td>Θ</td><td><code>\Theta</code></td><td>θ</td><td><code>\theta</code></td></tr><tr><td>I</td><td><code>I</code></td><td>ι</td><td><code>\iota</code></td></tr><tr><td>K</td><td><code>K</code></td><td>κ</td><td><code>\kappa</code></td></tr><tr><td>Λ</td><td><code>\Lambda</code></td><td>λ</td><td><code>\lambda</code></td></tr><tr><td>M</td><td><code>M</code></td><td>μ</td><td><code>\mu</code></td></tr><tr><td>N</td><td><code>N</code></td><td>ν</td><td><code>\nu</code></td></tr><tr><td>Ξ</td><td><code>\Xi</code></td><td>ξ</td><td><code>\xi</code></td></tr><tr><td>O</td><td><code>O</code></td><td>ο</td><td><code>\omicron</code></td></tr><tr><td>Π</td><td><code>\Pi</code></td><td>π</td><td><code>\pi</code></td></tr><tr><td>P</td><td><code>P</code></td><td>ρ</td><td><code>\rho</code></td></tr><tr><td>Σ</td><td><code>\Sigma</code></td><td>σ</td><td><code>\sigma</code></td></tr><tr><td>T</td><td><code>T</code></td><td>τ</td><td><code>\tau</code></td></tr><tr><td>Υ</td><td><code>\Upsilon</code></td><td>υ</td><td><code>\upsilon</code></td></tr><tr><td>Φ</td><td><code>\Phi</code></td><td>ϕ</td><td><code>\phi</code></td></tr><tr><td>X</td><td><code>X</code></td><td>χ</td><td><code>\chi</code></td></tr><tr><td>Ψ</td><td><code>\Psi</code></td><td>ψ</td><td><code>\psi</code></td></tr><tr><td>Ω</td><td><code>\v</code></td><td>ω</td><td><code>\omega</code></td></tr></tbody></table><h2 id="三角函数、对数、指数"><a href="#三角函数、对数、指数" class="headerlink" title="三角函数、对数、指数"></a>三角函数、对数、指数</h2><p>使用<code>$符号语法$</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs latex">$\tan$、$\sin$、$\cos$、$\lg$、$\arcsin$、$\arctan$、$\min$、$\max$、$\exp$、$\log$<br>$\log_n(2)$ $\circ$<br></code></pre></td></tr></table></figure><p>$\tan$、$\sin$、$\cos$、$\lg$、$\arcsin$、$\arctan$、$\min$、$\max$、$\exp$、$\log$</p><p>$\log_2(2)$ $30^\circ$</p><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs latex">$+$、$-$、$=$、$&gt;$、$&lt;$、$\times$、$\div$、$\equiv$、$\leq$、$\geq$、$\neq$ $!$<br>$\pm$ $\mp$ $\cdot$ $\ast$ || $\frac&#123;分子&#125;&#123;分母&#125;$  $&#123;分子&#125; \voer &#123;分母&#125;$<br>$\sqrt&#123;&#125;$ $\sqrt[n]&#123;&#125;$<br></code></pre></td></tr></table></figure><p>$+$、$-$、$=$、$&gt;$、$&lt;$、$\times$、$\div$、$\equiv$、$\leq$、$\geq$、$\neq$  $!$</p><p>$\pm$ $\mp$ $\cdot$ $\ast$ $|x+y|$  $\frac{分子}{分母}$  ${x+y} \over {y+z}$ </p><p>$\sqrt[]{x+y}$ $\sqrt[n]{x+y}$</p><h2 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex">$\cup$、$\cap$、$\in$、$\notin$、$\ni$、$\subset$、$\subseteq$、$\supset$、$\supseteq$、$\infty$<br></code></pre></td></tr></table></figure><p>$\cup$、$\cap$、$\in$、$\notin$、$\ni$、$\subset$、$\subseteq$、$\supset$、$\supseteq$、$\infty$</p><h2 id="定界符"><a href="#定界符" class="headerlink" title="定界符"></a>定界符</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs latex">$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$<br>$ [] $ $ \&#123;\&#125; $ $\left(x\right)$<br>$&#123;上位公式 \choose 下位公式&#125;$<br>$&#123;上位公式 \atop 下位公式&#125;$<br></code></pre></td></tr></table></figure><p>$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$</p><p>$ [] $ $ {} $ $\left(x\right)$ 这个是自动适应符号</p><p>${上位公式 \choose 下位公式}$</p><p>${上位公式 \atop 下位公式}$</p><h2 id="上标下标"><a href="#上标下标" class="headerlink" title="上标下标"></a>上标下标</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs latex">^ _ &#123;&#125;用这个来组合<br></code></pre></td></tr></table></figure><p>$x^4$ $x_1$ ${16}<em>{8}O{2+}</em>{2}$</p><h2 id="内联输出与块状输出"><a href="#内联输出与块状输出" class="headerlink" title="内联输出与块状输出"></a>内联输出与块状输出</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs latex">$ $<br>$$ $$<br></code></pre></td></tr></table></figure><p>这是一个公式$x^y$</p><p>这是一个公式$$x^y$$</p><h2 id="高级运算"><a href="#高级运算" class="headerlink" title="高级运算"></a>高级运算</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs latex">$\overline&#123;算式&#125;$ <br>$\lim$ $\lim\limits_&#123;x \to y&#125;$<br>$\sum$ $\sum_&#123;n=1&#125;^\infty k$<br></code></pre></td></tr></table></figure><p>$\overline{xyz}$ $$\lim\limits_{x \to \infty} \exp(-x) = 0$$ </p><p>$\sum_{n=1}^\infty k$</p><h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs latex">$$<br>  \begin&#123;matrix&#125;<br>   1 &amp; 2 &amp; 3 \\<br>   4 &amp; 5 &amp; 6 \\<br>   7 &amp; 8 &amp; 9<br>  \end&#123;matrix&#125; <br>$$<br></code></pre></td></tr></table></figure><p>$$<br>\begin{matrix}<br>   1 &amp; 2 &amp; 3 \<br>   4 &amp; 5 &amp; 6 \<br>   7 &amp; 8 &amp; 9<br>  \end{matrix}<br>$$</p><h2 id="分段函数"><a href="#分段函数" class="headerlink" title="分段函数"></a>分段函数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs latex">$$<br>X(m,n)=<br>\begin&#123;cases&#125;<br>x(n),\\<br>x(n-1)\\<br>x(n-1)<br>\end&#123;cases&#125;<br>$$<br></code></pre></td></tr></table></figure><p>$$<br>X(m,n)=<br>\begin{cases}<br>x(n),\<br>x(n-1)\<br>x(n-1)<br>\end{cases}<br>$$</p>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LaTeX</tag>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python-Pathlib库基础使用教程</title>
    <link href="/2021/02/23/Python-Pathlib%E5%BA%93%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <url>/2021/02/23/Python-Pathlib%E5%BA%93%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-Pathlib库基础使用教程"><a href="#Python-Pathlib库基础使用教程" class="headerlink" title="Python-Pathlib库基础使用教程"></a>Python-Pathlib库基础使用教程</h1><p>深度学习处理数据的时候经常使用这个Python库，Pathlib能够很方便地遍历各种样子的文件目录，性能也很好。</p><h2 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">p = Path(<span class="hljs-string">r&#x27;d:\test\tt.txt.bk&#x27;</span>)<br>p.name                          <span class="hljs-comment"># 获取文件名</span><br><span class="hljs-comment"># tt.txt.bk</span><br>p.stem                          <span class="hljs-comment"># 获取文件名除后缀的部分</span><br><span class="hljs-comment"># tt.txt</span><br>p.suffix                        <span class="hljs-comment"># 文件后缀</span><br><span class="hljs-comment"># .bk</span><br>p.suffixs                       <span class="hljs-comment"># 文件的后缀们...</span><br><span class="hljs-comment"># [&#x27;.txt&#x27;, &#x27;.bk&#x27;]</span><br>p.parent                        <span class="hljs-comment"># 相当于dirnanme</span><br><span class="hljs-comment"># WindowsPath(&#x27;d:/test&#x27;)</span><br>p.parents                       <span class="hljs-comment"># 返回一个iterable, 包含所有父目录</span><br><span class="hljs-comment"># &lt;WindowsPath.parents&gt;</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> p.parents:<br>    <span class="hljs-built_in">print</span>(i)<br><span class="hljs-comment"># d:\test</span><br><span class="hljs-comment"># d:\</span><br>a.parts                         <span class="hljs-comment"># 将路径通过分隔符分割成一个元祖</span><br><span class="hljs-comment"># (&#x27;d:\\&#x27;, &#x27;test&#x27;, &#x27;tt.txt.bk&#x27;)</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">p = Path(<span class="hljs-string">r&#x27;d:\test&#x27;</span>)<br>p = Path(p, <span class="hljs-string">&#x27;tt.txt&#x27;</span>)           <span class="hljs-comment"># 字符串拼接</span><br>p.exists()                      <span class="hljs-comment"># 判断文件是否存在</span><br>p.is_file()                     <span class="hljs-comment"># 判断是否是文件</span><br>p.is_dir()                      <span class="hljs-comment"># 判断是否是目录</span><br></code></pre></td></tr></table></figure><h2 id="遍历❤"><a href="#遍历❤" class="headerlink" title="遍历❤"></a>遍历❤</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">p = Path(<span class="hljs-string">r&#x27;d:\test&#x27;</span>)<br><span class="hljs-comment"># WindowsPath(&#x27;d:/test&#x27;)</span><br>p.iterdir()                     <span class="hljs-comment"># 相当于os.listdir 列出子目录/文件</span><br>p.glob(<span class="hljs-string">&#x27;*&#x27;</span>)                     <span class="hljs-comment"># 相当于os.listdir, 列出符合条件的子目录/文件但是可以添加匹配条件</span><br>p.rglob(<span class="hljs-string">&#x27;*&#x27;</span>)                    <span class="hljs-comment"># 相当于os.walk, 递归列出符合条件的子目录/文件也可以添加匹配条件</span><br></code></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">* # 所有<br>? # 单个字符<br>. # 当前目录<br>.. # 上一级目录<br>[0-9] [a-z] [A-Z] # 字面意思<br>[A-Za-z] # 大小写字母 windows路径不分大小写<br>[0-9A-Za-Z] # 数字和字母<br><br>**  # 表示 “此目录以及所有子目录，递归”<br></code></pre></td></tr></table></figure><h2 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">p = Path(<span class="hljs-string">r&#x27;d:\test\tt\dd&#x27;</span>)<br>p.mkdir(exist_ok=<span class="hljs-literal">True</span>)          <span class="hljs-comment"># 创建文件目录(前提是tt目录存在, 否则会报错)</span><br><span class="hljs-comment"># 一般我会使用下面这种创建方法</span><br>p.mkdir((exist_ok=<span class="hljs-literal">True</span>, parents=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 递归创建文件目录</span><br></code></pre></td></tr></table></figure><h2 id="文件详细信息-size-createtime…"><a href="#文件详细信息-size-createtime…" class="headerlink" title="文件详细信息(size, createtime…)"></a>文件详细信息(size, createtime…)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">p = Path(<span class="hljs-string">r&#x27;d:\test\tt.txt&#x27;</span>)<br>p.stat()                        <span class="hljs-comment"># 获取详细信息</span><br><span class="hljs-comment"># os.stat_result(st_mode=33206, st_ino=562949953579011, st_dev=3870140380, st_nlink=1, st_uid=0, st_gid=0, st_size=0, st_atime=1525254557, st_mtime=1525254557, st_ctime=1525254557)</span><br>p.stat().st_size                <span class="hljs-comment"># 文件大小</span><br><span class="hljs-comment"># 0</span><br>p.stat().st_ctime               <span class="hljs-comment"># 创建时间</span><br><span class="hljs-comment"># 1525254557.2090347</span><br><span class="hljs-comment"># 其他的信息也可以通过相同方式获取</span><br>p.stat().st_mtime               <span class="hljs-comment"># 修改时间</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>机器学习</tag>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux基础学习笔记(随缘会更新)</title>
    <link href="/2021/02/23/Linux%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E9%9A%8F%E7%BC%98%E4%BC%9A%E6%9B%B4%E6%96%B0)/"/>
    <url>/2021/02/23/Linux%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E9%9A%8F%E7%BC%98%E4%BC%9A%E6%9B%B4%E6%96%B0)/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux基础学习笔记-随缘会更新"><a href="#Linux基础学习笔记-随缘会更新" class="headerlink" title="Linux基础学习笔记(随缘会更新)"></a>Linux基础学习笔记(随缘会更新)</h1><p>记录一些基本的能用上的命令。之后假如遇到了什么新的命令会在这更新。</p><p>第一次更新：用学校科研平台的时候发现查看资源的几个命令能用上</p><p>第二次更新：更新了一些超常用的命令速查</p><h2 id="超常用命令速查！！"><a href="#超常用命令速查！！" class="headerlink" title="超常用命令速查！！"></a>超常用命令速查！！</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">ls -alh  <span class="hljs-comment"># 人性化显示所有文件</span><br>tar -cvf xxx.tar ./data1/ ./data2/  <span class="hljs-comment"># 打包文件，不压缩！</span><br>tar -czvf xxx.tar.gz ./data1/ ./data2/  <span class="hljs-comment"># 压缩文件</span><br>tar -xvf xxx.tar -C ./data/ <span class="hljs-comment"># 解压xxx.tar</span><br>du -h /data/  <span class="hljs-comment"># 人性化显示文件占用磁盘大小</span><br>df -h  <span class="hljs-comment"># 显示磁盘分区可用空间</span><br>find /var/<span class="hljs-built_in">log</span>/ -<span class="hljs-built_in">type</span> f -<span class="hljs-built_in">print</span> | wc -l  <span class="hljs-comment"># 查看目录下有多少文件</span><br></code></pre></td></tr></table></figure><h2 id="文件与目录管理"><a href="#文件与目录管理" class="headerlink" title="文件与目录管理"></a>文件与目录管理</h2><h3 id="ls-：-list，列出目录"><a href="#ls-：-list，列出目录" class="headerlink" title="ls ： list，列出目录"></a>ls ： list，列出目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">ls<br>-a  # all 全部的文件，包括隐藏文件<br>-l  # long 详细信息<br>-h  # 配合-l以人性化的方式显示文件大小<br>-i  # 显示inode信息<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 可以组合使用</span></span><br>ls -lha  # 结合三个标签的效果，可以乱序<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># ls及其他命令可能使用的通配符</span></span><br>*  # 任意个数字符<br>?  # 任意一个字符，不能多也不能少<br>[]  # 匹配字符组中任意一个,比如下列<br>[abc]  # 匹配abc中任意一个<br>[a-f]  # 匹配a到f内任意一个<br>[1-9]  # 匹配1到9内任意一个<br></code></pre></td></tr></table></figure><h3 id="cd：-change-dir，改变工作目录"><a href="#cd：-change-dir，改变工作目录" class="headerlink" title="cd： change dir，改变工作目录"></a>cd： change dir，改变工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># Linux所有目录和文件名大小写敏感</span></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># cd后可能用的特殊路径</span></span><br>cd ~  # 当前用户主目录<br>cd .  # 当前目录<br>cd ..  # 上级目录<br>cd -  # 最近两次工作目录间切换<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 相对路径与绝对路径</span></span><br>cd /home/tmp  # 绝对路径，最前面是~或者/<br>cd file/src  # 相对路径，表示当前目录下的文件<br></code></pre></td></tr></table></figure><h3 id="mkdir-make-dir-创建新目录"><a href="#mkdir-make-dir-创建新目录" class="headerlink" title="mkdir: make dir, 创建新目录"></a>mkdir: make dir, 创建新目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir [目录名字]<br>-p  # 可以递归创建目录<br></code></pre></td></tr></table></figure><h3 id="rmdir：-remove-dir，删除空目录"><a href="#rmdir：-remove-dir，删除空目录" class="headerlink" title="rmdir： remove dir，删除空目录"></a>rmdir： remove dir，删除空目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">rmdir [目录名字]<br>-P  # 删除指定空目录，假如上一级也是空那也删除<br></code></pre></td></tr></table></figure><h3 id="rm-remove-删除文件或目录"><a href="#rm-remove-删除文件或目录" class="headerlink" title="rm: remove, 删除文件或目录"></a>rm: remove, 删除文件或目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">rm [文件名]<br>-f  # 强制删除，忽略不存在的文件<br>-r  # 删除目录<br>-i  # 会询问一次<br></code></pre></td></tr></table></figure><h3 id="pwd-print-working-dir，显示目前所在目录"><a href="#pwd-print-working-dir，显示目前所在目录" class="headerlink" title="pwd: print working dir，显示目前所在目录"></a>pwd: print working dir，显示目前所在目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">pwd<br>-P  # 显示出真实路径而非link路径<br></code></pre></td></tr></table></figure><h3 id="cp-copy，复制文件"><a href="#cp-copy，复制文件" class="headerlink" title="cp: copy，复制文件"></a>cp: copy，复制文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">cp [参数] [来源] [目标]<br>-d  # 若复制的文件是link，则复制link而非文件本身<br>-p  # 复制文件的属性，备份常用<br>-r  # 递归复制，能复制目录<br>-a  # -pdr<br><br>-f  # force，若目标已存在且无法开启，则删除后再试一次<br>-i  # 若目标已存在，会先询问再覆盖<br></code></pre></td></tr></table></figure><h3 id="mv-move，移动文件或修改名称"><a href="#mv-move，移动文件或修改名称" class="headerlink" title="mv: move，移动文件或修改名称"></a>mv: move，移动文件或修改名称</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">mv [参数] [来源] [目标]<br>-f  # force，若目标已存在且无法开启，则删除后再试一次<br>-i  # 若目标已存在，会先询问再覆盖<br>-u  # 若目标文件已存在，且来源更新，才会覆盖<br>mv file file2  # 重命名操作<br></code></pre></td></tr></table></figure><h3 id="ln-链接"><a href="#ln-链接" class="headerlink" title="ln: 链接"></a>ln: 链接</h3><blockquote><h2 id="硬连接"><a href="#硬连接" class="headerlink" title="硬连接"></a><strong>硬连接</strong></h2><p>硬连接指通过索引节点来进行连接。<strong>在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号</strong>，称为<strong>索引节点号(Inode Index)<strong>。在 Linux 中，多个文件名指向同一索引节点是存在的。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，</strong>A 和 B 对文件系统来说是完全平等的。删除其中任何一个都不会影响另外一个的访问。</strong></p><p>硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。<strong>只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。</strong>也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。</p><p><em><strong>不允许给目录创建硬链接</strong></em></p><h2 id="软连接"><a href="#软连接" class="headerlink" title="软连接"></a><strong>软连接</strong></h2><p>另外一种连接称之为<strong>符号连接（Symbolic Link），也叫软连接</strong>。软链接文件有类似于 Windows 的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。比如：A 是 B 的软链接（A 和 B 都是文件名），A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，<strong>A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）</strong>。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223234253.png" alt="1 (1)"></p><p>如图，最左边一栏就是inode，a-hard是硬链接，a-light是软连接。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">ln [参数] [来源] [目标]<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 必要参数</span></span><br>-b  # 覆盖以前建立的连接<br>-f  # 强制执行<br>-i  # 存在会询问一次<br>-s  # 软连接<br>-v  # 显示过程<br></code></pre></td></tr></table></figure><h3 id="cat-category，由第一行开始显示文件内容"><a href="#cat-category，由第一行开始显示文件内容" class="headerlink" title="cat: category，由第一行开始显示文件内容"></a>cat: category，由第一行开始显示文件内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat [参数] [目标]<br>-E  # 将结尾的断行字节用$表示<br>-v  # 列出看不出来的特殊字符<br>-T  # 列出tab键为^|<br>-A  # -vET<br><br>-b  # 列出行号，空白行不计<br>-n  # 列出行号，空白行计<br></code></pre></td></tr></table></figure><h3 id="tac-倒过来的cat，从最后一行开始显示文件内容"><a href="#tac-倒过来的cat，从最后一行开始显示文件内容" class="headerlink" title="tac: 倒过来的cat，从最后一行开始显示文件内容"></a>tac: 倒过来的cat，从最后一行开始显示文件内容</h3><h3 id="nl-显示行号"><a href="#nl-显示行号" class="headerlink" title="nl: 显示行号"></a>nl: 显示行号</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">nl [参数] [文件]<br>-b a  # 计空行<br>-b t  # 不计空行 默认<br>-w [数字]  # 行号栏所占位数<br></code></pre></td></tr></table></figure><h3 id="more-一页一页翻动"><a href="#more-一页一页翻动" class="headerlink" title="more: 一页一页翻动"></a>more: 一页一页翻动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">space  # 向下翻一页<br>enter  # 向下一行<br>/[字符]  # 向下搜索字符<br>q  # 离开<br>b  # 回翻页 <br></code></pre></td></tr></table></figure><h3 id="head-tail：-前-后几行"><a href="#head-tail：-前-后几行" class="headerlink" title="head/tail： 前/后几行"></a>head/tail： 前/后几行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">head -n [数字] [目标]<br>tail -n [数字] [目标]<br></code></pre></td></tr></table></figure><h2 id="查看系统相关信息"><a href="#查看系统相关信息" class="headerlink" title="查看系统相关信息"></a>查看系统相关信息</h2><h3 id="CPU使用信息"><a href="#CPU使用信息" class="headerlink" title="CPU使用信息"></a>CPU使用信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">top  # 查看使用率等<br></code></pre></td></tr></table></figure><h3 id="GPU使用信息"><a href="#GPU使用信息" class="headerlink" title="GPU使用信息"></a>GPU使用信息</h3><p>跑深度学习模型的时候常用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvidia-smi  # 查看显存、GPU使用率等<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>常用易忘</category>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git与GitHub使用教程</title>
    <link href="/2021/02/23/Git%E4%B8%8EGithub%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <url>/2021/02/23/Git%E4%B8%8EGithub%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Git与GitHub使用教程"><a href="#Git与GitHub使用教程" class="headerlink" title="Git与GitHub使用教程"></a>Git与GitHub使用教程</h1><p>这篇文章是我的学习笔记，借鉴了各种博主的资料和自己的理解整理而成。</p><p>本文从0开始完整介绍Git和GitHub，所以比较长，请灵活运用大纲和搜索功能。</p><h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h2 id="Git是什么？"><a href="#Git是什么？" class="headerlink" title="Git是什么？"></a>Git是什么？</h2><p><a href="https://www.runoob.com/manual/git-guide/">参考</a></p><p>Git是目前世界上最先进的<strong>分布式版本控制系统</strong>。</p><p>版本控制的目录叫做一个<strong>仓库(repository)</strong></p><p>你的本地仓库由 Git 维护的三棵“树”组成。第一个是你的 <strong>工作目录</strong>，它持有实际文件；第二个是 <strong>暂存区（Index）</strong>，它像个缓存区域，临时保存你的改动；最后是 <strong>HEAD</strong>，它指向你最后一次提交的结果。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150705.png"></p><p>使用Git的工作流程如下：</p><p>在本地修改、保存之后，通过 <strong>推送(Push)</strong> 操作来提交到远程仓库。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150713.png"></p><p>与其他版本控制系统一样，Git还提供 <strong>分支(branch)</strong> 功能，该功能允许你从开发仓库的主线上分离出一个版本，然后在不影响主线的情况下继续工作。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150717.png"></p><blockquote><p>版本控制系统：</p><p>小明正在写一篇文章，他想删除一个段落，过了一会后，他突然发现他想要回这个段落，于是他苦逼地再打了一遍。</p><p>小红正在写一篇文章，她想删除一个段落，但是她不确定之后是否想恢复这个段落，所以她拷贝了一份，过了一会儿，她又想更改一个段落，也不确定之后是否会想恢复，于是她又拷贝了一份，他的文件夹里出现了很多类似xxxxx-副本（2）的文件，她苦逼地寻找他想要恢复的那个版本。</p><p>张三正在写一篇文章，他使用了Git来管理版本，Git详细记录了每次更改的日期和更改处以及张三自己为改动写的备注。他很开心地写了一篇神作。后面李四想与张三合作这篇文章，李四也使用Git，Git还记录了每次更改的用户。他们很开心地合作了一篇神作。</p></blockquote><blockquote><p>分布式：</p><p><a href="https://www.liaoxuefeng.com/wiki/896043488029600/896202780297248">参考资料</a></p><p>下图是集中式系统，中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。集中式版本控制系统最大的毛病就是必须联网才能工作，如果在局域网内还好，带宽够大，速度够快，可如果在互联网上，遇到网速慢的话，可能提交一个10M的文件就需要5分钟，这还不得把人给憋死啊。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150726.jpeg"></p><p>下图是分布式系统，首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。</p><p>分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150727.jpeg"></p></blockquote><h2 id="使用Git"><a href="#使用Git" class="headerlink" title="使用Git"></a>使用Git</h2><h3 id="使用之前"><a href="#使用之前" class="headerlink" title="使用之前"></a>使用之前</h3><p>Git是一个跨平台的开源软件。<a href="https://git-scm.com/">官网</a>没有被墙而且速度很快，直接下载安装即可。</p><p>Linux系统可以使用<code>sudo apt-get install git</code>安装</p><p>下载安装后，打开终端或Git Bash，我们接下来要配置Git。</p><p>配置要设置你的身份，身份由用户名和邮箱组成，通过一下命令设置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git config --global user.name <span class="hljs-string">&quot;你的名字&quot;</span></span><br><span class="hljs-meta">$</span><span class="bash"> git config --global user.email <span class="hljs-string">&quot;你的邮箱&quot;</span></span><br></code></pre></td></tr></table></figure><h3 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h3><p>最常用的命令是<code>push</code> <code>commit</code> <code>pull</code> <code>clone</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs shell">git init  # 初始化一个仓库，在此命令之前要从终端进入你想记录更改的那个工作目标里<br><br>git clone &lt;repo&gt;  # 克隆一个仓库 repo是仓库地址<br>git clone &lt;repo&gt; &lt;path&gt; # 克隆一个仓库 path是本地保存路径<br>git clone https://github.com/sample/hello.git  # 克隆github上一个仓库的写法<br><br>git add &lt;文件名&gt;  # 添加某个文件到仓库缓存区<br>git add *  # 添加所有文件<br><br>git commit -m &quot;代码提交备注信息&quot;  # 提交你的代码附带一段备注，你的改动只提交到了HEAD而不是远程仓库。<br><br>git push origin &lt;分支名字&gt;  # 将本地HEAD提交到远程仓库，这个操作叫做push<br>git push origin master  # 每个仓库有一条主线分支叫做master<br><br>git remote add origin &lt;server&gt;  # 假如你不是通过clone来创建仓库的，那么你需要用这个命令来连接到某个远程服务器<br><br>git log  # 查看修改的日志<br><br>git checkout -b &lt;分支名字&gt;  # 创建一个分支并切换过去，分支也要push才能在远程仓库中被看见<br>git checkout &lt;分支名字&gt;   # 切换分支<br>git branch -d &lt;分支名字&gt;  # 删除分支<br><br>git pull  # 更新你的本地仓库，这个操作叫做pull<br>git merge &lt;分支名字&gt;  # 将其他分支合并到你的分支<br><br>git checkout -- &lt;文件名&gt;  # 将尚未commit的内容放弃退回到上一个版本<br>git reset --hard HEAD^  # 退回到上一个版本 HEAD^^为上上个版本 HEAD~n 为上n个版本<br>git reset --hard &lt;commit id&gt;  # 每一次commit有一个单独的ID，通过此命令到相应版本<br><span class="hljs-meta">#</span><span class="bash"> 这两个命令让你放弃所有尚未push的内容，并获取远程仓库上最新的版本</span><br>git fetch origin<br>git reset --hard origin/master<br></code></pre></td></tr></table></figure><p><a href="https://www.runoob.com/git/git-basic-operations.html">更多操作</a></p><h1 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h1><p>GitHub是一个面向开源及私有软件项目的托管平台。也就是远程仓库存放的地方。18年被微软收购，目前微软、谷歌以及很多开源项目的代码都托管在改平台。GitHub是最好的代码托管平台。</p><p>界面大概长这样23333</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150732.webp" alt="个人界面"></p><h2 id="使用之前-1"><a href="#使用之前-1" class="headerlink" title="使用之前"></a>使用之前</h2><p>你得先注册一个GitHub账号。<a href="https://github.com/">官网</a></p><p>然后你要创建一个<strong>SSH Key</strong>，这个秘钥用来保证没有别人来瞎改你的仓库，是你的凭证。</p><p>打开终端（git bash）输入下面代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -C <span class="hljs-string">&quot;你的邮箱&quot;</span><br></code></pre></td></tr></table></figure><p>然后在你的用户主目录(Windows下是C:\users\你的用户名)下找到.ssh目录。</p><p>里面有<code>id_rsa</code>和<code>id_rsa.pub</code>两个文件，公钥是<code>.pub</code>，打开它，复制里面的内容。</p><p>打开Github的Account settings，在SSH keys里面粘贴。然后添加Key。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150738.webp"></p><h2 id="创建远程仓库-repo"><a href="#创建远程仓库-repo" class="headerlink" title="创建远程仓库(repo)"></a>创建远程仓库(repo)</h2><p>在你的用户界面下的Repositories点new。</p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223152527.webp"></p><p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/20210223150742.png"></p><p>Repository name是你仓库的名字。之后是对仓库的描述以及可见性，现在Github上私有库已经免费了，所以这两个随便选。其他暂时默认，点击创建。</p><p>然后你就有了一个远程仓库！</p><p>此时网页会写的很清楚这个仓库的地址，之后你就可以用命令行来git了！</p><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>GitHub有客户端，搜索下载就行了，然后登陆，这样你就不用手动输入命令了。</p><h2 id="README-md"><a href="#README-md" class="headerlink" title="README.md"></a>README.md</h2><p>别人从网页打开你的仓库会有一个初始化文档，让别人知道你这个仓库是用来干什么的，要如何使用你的代码。这些通常用markdown格式书写，并且命名为README.md放在根目录。这个文件会在网站上自动显示。<a href="https://guides.github.com/features/mastering-markdown/">github官方教程</a></p><p>GitHub支持拓展语法：</p><p><strong>emoji</strong>：<code>:blush:</code>:blush:</p><p><a href="https://www.webfx.com/tools/emoji-cheat-sheet/">所有emoji代码</a></p><p><strong>@用户</strong>：<code>@username</code>可以@别的用户</p><p><strong>badge</strong>：项目徽章。<a href="http://www.cocoachina.com/articles/19256">教程</a>   <a href="https://shields.io/">Shield.io</a> </p><p><strong>标准写法</strong>：<a href="https://github.com/RichardLitt/standard-readme">Standard Readme</a></p><h2 id="issues"><a href="#issues" class="headerlink" title="issues"></a>issues</h2><p><a href="https://blog.csdn.net/Wuzihui___/article/details/79952068">教程</a></p><p>GitHub为开发者提供了许多便于开发的功能，其中，issues功能被用来追踪各种想法，增强功能，任务，bug等。</p><p>项目维护者可以通过Issues来组织需要完成的任务，例如增加新特性或者审计一个已经上线的功能。同时，还可以将Issues关联某些pull request，一旦合并了某个pull request，这个issue会被自动关闭。同时，你可以将issues添加到看板，也可以将看板的任务转化为issue。</p><h2 id="commit-log"><a href="#commit-log" class="headerlink" title="commit log"></a>commit log</h2><p>feat: 新功能</p><p>change：需求变更</p><p>fix：缺陷修复</p><p>test：修改测试代码</p><p>docs：文档变更</p><p>style：代码格式调整</p><p>refactor：代码重构</p>]]></content>
    
    
    <categories>
      
      <category>未分类</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
      <tag>GitHub</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络爬虫进化史，原来你是这样的爬虫：第2期</title>
    <link href="/2021/02/21/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC2%E6%9C%9F/"/>
    <url>/2021/02/21/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC2%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="网络爬虫进化史，原来你是这样的爬虫：第2期"><a href="#网络爬虫进化史，原来你是这样的爬虫：第2期" class="headerlink" title="网络爬虫进化史，原来你是这样的爬虫：第2期"></a>网络爬虫进化史，原来你是这样的爬虫：第2期</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一期我们说到万维网被发明之后，马修·格雷（Matthew Gray）找到了从万维网上获取数据的好方法，并写出了历史上第一个爬虫——<em>World Wide Web Wanderer</em>，接下来我们将会进入到万维网的黄金发展时期——1993-1994年，同时也是搜索引擎和爬虫发展最迅速的时期~</p><h2 id="What’s-New？"><a href="#What’s-New？" class="headerlink" title="What’s New？"></a>What’s New？</h2><p>假如让你上网，你最先想到的是什么？恐怕大多数人都会打开桌面上的Chrome浏览器。</p><p>然而在万维网刚开始的时候，人们使用的是蒂姆发明万维网时同时发明的万维网浏览器，名字也就叫做<em>WorldWideWeb</em>（后改名Nexus以防止混淆），这个简陋的浏览器的用户体验不是很好，既没有丰富的颜色，也不能显示图片。当时这个浏览器运行在<strong>NeXTSTEP</strong>操作系统上，而这个操作系统早已支持彩色图形化的操作界面，WorldWideWeb的界面是在引不起用户的兴趣。</p><blockquote><p>你可以在CERN的这个网站重温当年的浏览器<a href="https://worldwideweb.cern.ch/browser/">https://worldwideweb.cern.ch/browser/</a></p></blockquote><p><img src="/img/2/post12.png" alt="最早的浏览器"></p><p><img src="/img/2/post7.png" alt="用历史上第一个浏览器打开现在的百度"></p><p>于是，<strong>Mosaic浏览器横空出世，这是第一个早期普及的网页浏览器</strong>，它不仅具有更好看的界面，而且它还可以在文字中嵌入图片。并且在1993年，<strong>Mosaic推出了一个叫做What’s New的页面</strong>，这个页面几乎每天都会给公众提供一个全新网站的链接。在当时，这个页面吸引了很多人的眼球，要知道，1992年11月的时候世界上才只有26个网站，所以每一个新网站的出现都是引人注目的。</p><p>在What’s New功能出现初期，这个页面是无法自动更新的，需要靠开发者手动添加页面，来自斯特灵大学计算机系的一名毕业生乔纳森·弗莱彻（ Jonathon Fletcher）发现了这个问题，所以他发明了<em>JumpStation</em>爬虫，在1993年底，JumpStation爬遍了全世界，记录了2万5千个网页，在乔纳森为其加上搜索工具后，Mosaic的What‘s New就形成了世界上第一个网页搜索引擎。Mosaic和它的What‘s New非常辉煌，据说在当时What’s New可能是万维网上访问量最高的单个页面，在1994年，获得了最重要服务概念奖（Most Important Service Concept）。</p><p><img src="/img/2/post9.png" alt="What&#39;s New的最佳服务概念奖"></p><p><img src="/img/2/post3.jpg" alt="1993年的What&#39;s New"></p><h2 id="更多爬虫的出现"><a href="#更多爬虫的出现" class="headerlink" title="更多爬虫的出现"></a>更多爬虫的出现</h2><p><strong>93年在学术界也有崭新的爬虫出现，那就是<em>World Wide Web Worm</em>，简称<em>WWWW</em>。</strong>与之前的爬虫不一样，这个爬虫还支持正则表达式搜索。正则表达式是一种“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。</p><p>比如<code>[1-9]\d&#123;5&#125;(?!\d)</code>这一句正则表达式表示中国的邮政编码格式，能匹配100001这样的字符串</p><p>再比如<code>((2(5[0-5]|[0-4]\d))|[0-1]?\d&#123;1,2&#125;)(\.((2(5[0-5]|[0-4]\d))|[0-1]?\d&#123;1,2&#125;))&#123;3&#125;</code>这样的字符串，能匹配<code>192.168.0.1</code>这样的IP地址。</p><p>看到这你是不是已经头大了？虽然正则表达式很难被计算机小白们理解，但是在没有google之前，搜索引擎能准确的找到东西都是一个问题，虽然使用正则表达式稍微麻烦一点，但是他还是得到了很多人的喜爱。WWWW在1994年爬取到了11万个网页，并它获得了年度最佳导航网站的奖项。</p><p><img src="/img/2/post4.png" alt="WWWW最佳导航网站奖"></p><p><strong>然而WWWW和JumpStation，都遇到了一个问题，那就是数据的储存。</strong>WWWW的作者并没有能力保存下爬取到的所有数据，于是只保存了爬取到的网页的前几级标题，而JumpStation的开发者没有得到斯特灵大学的投资，即使是只保存标题，也在1994年由于缺乏资金来购买存储介质而停止了开发。（当初数据的存储器是非常非常贵的）</p><p>而*<em>休斯顿大学财大气粗，启动了</em>RBSE(Repository Based Software Engineering Program)*项目**，这个项目也开发了一个爬虫，与WWWW和JumpStation不一样，RBSE的爬虫会存储并索引HTML页面的全文，这与当下的搜索引擎更为接近。我们在搜索引擎中输入的关键词搜索到的网页更可能是与正文内容匹配，而不仅是标题，这大大提高了搜索引擎的准确率。RBSE总共获取到了100MB的数据，他们的搜索功能获得了平均每天300个访问，最高900次请求的成绩，作为一个研究项目，RSBE的成果可以是非常成功的。</p><p><strong>RBSE spider还是第一个提出注重爬虫礼仪的爬虫</strong>，上一期提到，马修写的爬虫出了问题，导致互联网出现了大拥堵，于是开发者约定了robots.txt，而RBSE提出，在访问网站的时候会在User-Agent中添加<code>RBSE-Spider/0.1</code>的字样，并且通过优化代码降低对互联网的影响。</p><p><img src="/img/2/post5.png" alt="RBSE的爬虫礼仪"></p><p><strong>接下来要介绍的爬虫成功存活到了现在，那就是<em>WebCrawler</em>。</strong></p><p><img src="/img/2/post11.png" alt="过去的webcrawler"></p><p><img src="/img/2/post8.png" alt="WebCrawler"></p><p>这个与爬虫的英文同名的爬虫在1994年爬取到了总共4000个网站，在年底，用这个爬虫构建的搜索引擎就迎来了它的第一百万次搜索。（据说第一百万次的搜索内容是“核武器的设计和研究”）比起RBSE，WebCrawler同样也能进行全文搜索，不同的是，WebCrawler比RBSE爬取的范围更大更广，而且WebCrawler能够同时下载15个网页，这意味着搜索引擎数据库更新的速度也更快。</p><h2 id="互联网泡沫"><a href="#互联网泡沫" class="headerlink" title="互联网泡沫"></a>互联网泡沫</h2><p>这个优秀的产品迅速吸引了资本的注入，在1995年，美国在线（AOL）收购了WebCrawler，然后对WebCrawler进行了商业化，即在搜索结果的边上放置广告位，通过广告位收费来盈利。在1996年，WebCrawler达到了它的顶峰，当时这个网站是是互联网上访问量第二高的网站，它的服务器甚至经常因为访问量太高而崩溃。</p><p>然而，好景不长，Inktomi开发了一个叫做Slurp的爬虫，并研发了Inktomi搜索引擎，关于这个爬虫的资料比较少，所以我也无法详细介绍，但是Inktomi与其他搜索引擎不同，他不直接提供搜索功能，而是向合作伙伴卖技术来盈利，雅虎、Infoseek、Lycos、Excite甚至微软MSN都在使用它的技术。于是，<strong>WebCrawler在竞争中处于劣势，然后几经转手，虽然现在还苟活着，但是它已经没有独立的数据库来支持搜索功能了，它成为了一个元搜索引擎</strong>。元搜索引擎和百度、Google这样的独立搜索引擎区别很大，前者的数据来源是多个独立搜索引擎甚至是其他元搜索引擎，拿到手的数据再经过自己的整理、优化然后再呈现给用户。</p><p>之后，互联网泡沫逐渐形成了，我对经济学不是很了解，但是对于上世纪九十年代美国的互联网泡沫的形成原因，大概就是那些投资人把太多的钱给了没有前景没有技术只会讲故事的互联网公司。其中Yahoo就是受到打击很严重的企业之一，Yahoo没有自己的搜索引擎技术，甚至在很长的一段时间内，它是手工对网站进行分类的，这样不牢固的基础，使得它在泡沫破裂的时候市值蒸发了90%。</p><p><img src="/img/2/Nasdaq_Composite_dot-com_bubble.svg" alt="纳斯达克指数，互联网泡沫"></p><p>总结一下这场泡沫，那就是对于搜索引擎和爬虫领域，没有足够强技术的WebCrawler没落了，没有自己技术的Yahoo失败了，反倒是有技术但是不直接和消费者打交道的Inktomi生存下来了，由此可见，科学技术还是非常非常重要的，咱们只有掌握了核心的技术才能在大风大浪来临时稳操胜券。</p><h2 id="Google"><a href="#Google" class="headerlink" title="Google"></a>Google</h2><p>虽然20世纪末的互联网泡沫破裂导致了一大堆.com公司倒闭，但是存活下来的公司大多到如今都成为了互联网界闪耀的明星，比如Amazon、eBay、PayPal、Netflix，最具代表性的当然还有我们接下来要介绍的Google，在这些公司当中，Google的日子算是过的最好的，它在泡沫期间不仅几乎没有受到负面影响，甚至在泡沫爆破后还能进行公开招股。这和他们的经营方法有关系，也和Google爬虫的强大技术有关系。</p><p>Google的最初版本是由斯坦福大学的拉里·佩奇和谢尔盖·布林开发的，Google这个词起源于Googol，也就是$10^{100}$这个数字，他们想让自己的搜索引擎能够大到Googol这么大，于是，他们又带了一位斯坦福的博士同学克雷格·希尔福斯坦出去创业。</p><p><strong>Google搜索的爬虫从开始就被设计成为一个大范围的、通用的网络爬虫</strong>。当时的技术对于查找到万维网上的资源已经不是个很大的问题，但是可能出现搜索某个关键词，出来的结果十条只有两三条是相关的情况。甚至当时冒出的很多搜索引擎为了节约存储资源，不仅不爬取网页全文，连标题也不爬全，对于虚词（to not be）不做索引，结果这些搜索引擎对于莎士比亚的那句话“To be or not to be”的搜索结果就是空。而Google可以做到十条结果能有七八条是相关的，而且能够搜索到“To be or not to be”。</p><p><img src="/img/2/post10.jpg" alt="90年代的Google"></p><p><strong>Google的爬虫在存储、搜索、爬取三方面做出了创新：</strong></p><ul><li><p>之前其他爬虫遇到的问题，Google爬虫也遇见了，那就是数据的存储问题，Google为了保证搜索的准确性，肯定也是进行网页全文爬取的，它对存储过程进行了大量的底层优化，包括将爬取到的网页进行压缩后存储、并创建索引来减少磁盘访问时间。</p></li><li><p>Google爬虫在搜索算法方面发明了一个存活至今的叫做PageRank的算法，其基本假设是：<strong>更重要的页面往往更多地被其他页面引用。</strong>这个算法将互联网的网页看做节点，将超链接看做边，形成一张非常大的有向图，指向某个网页的超链接被看做对这个网页的“投票”，而这种“投票”的权重由超链接所存在的网页权重有关。假如一个非常热门和权威的网页上出现了你的网站的链接，那么你的网页权重就会升高，假如有非常多的网站都出现了你网站的链接，那么你的网页权重也会升高。虽然目前该算法早已不再是Google用来给网页排名的唯一算法，但它是最早的，也是最著名的算法。</p><p><img src="/img/2/post2.png" alt="PageRank算法"></p><p>我们有的时候能在一些网站底部看见一些超链接，这些被称作友情链接，网站的站长们为了让自己的网站在搜索引擎中能排的更前，会与其他网站的站长商量，在网页不起眼的地方互相加上网站的链接，这就是根据PageRank算法所耍的小聪明。</p><p><img src="/img/2/post6.png" alt="阿里云网站的页面底端"></p></li><li><p>在爬取速度方面，Google使用了主从式爬虫架构（Master-Slave），这种架构的核心思想就是“分而治之”，<strong>自此，爬虫从单一作战成功进化成群体进攻</strong>。主从式架构的主服务器（master）将一个原始的大任务分解成一系列小任务，然后分配给子服务器（Slave）执行，然后再主服务器收集产生的结果。这种架构虽然不是最佳的解决方案，但是<strong>在当时Google做到了每秒100个页面的下载速度。</strong></p><p><img src="/img/2/post1.png" alt="主从式架构"></p></li></ul><h2 id="接下来？"><a href="#接下来？" class="headerlink" title="接下来？"></a>接下来？</h2><p>爬虫已经完成了第一阶段的进化，它们在搜索引擎中发挥巨大作用，它们帮助Google度过互联网泡沫，它们开始成群结队有纪律地向万维网发起进攻，然而，随着爬虫的威力越来越强，万维网的规模也在逐渐加大，那座传说中的互联网冰山正在形成，爬虫能将他的魔掌伸向冰川之下吗……</p><div class="note note-info">            <p>这篇文章也发布在下面这个公众号数媒极客，公众号里面有其他很有趣的文章，可以扫码看一看~</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/671DEC2D0C09137F94251F74940B395C.jpg" style="zoom:50%;" />          </div>]]></content>
    
    
    <categories>
      
      <category>爬虫历史系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络爬虫进化史，原来你是这样的爬虫：第1期</title>
    <link href="/2021/02/21/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC1%E6%9C%9F/"/>
    <url>/2021/02/21/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%BF%9B%E5%8C%96%E5%8F%B2%EF%BC%8C%E5%8E%9F%E6%9D%A5%E4%BD%A0%E6%98%AF%E8%BF%99%E6%A0%B7%E7%9A%84%E7%88%AC%E8%99%AB%EF%BC%9A%E7%AC%AC1%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="网络爬虫进化史，原来你是这样的爬虫：第1期"><a href="#网络爬虫进化史，原来你是这样的爬虫：第1期" class="headerlink" title="网络爬虫进化史，原来你是这样的爬虫：第1期"></a>网络爬虫进化史，原来你是这样的爬虫：第1期</h1><h2 id="导语"><a href="#导语" class="headerlink" title="导语"></a>导语</h2><p><img src="/img/1/post6.png" alt="image-20200930210703651"></p><p>2020年的一个平淡的一天，累了一天的你打开手机，发现满朋友圈的“手把手教你写Python爬虫爬取小姐姐照片”广告，有没有疑惑过爬虫究竟是个啥？怎么突然就这么火了？</p><p>接下来这个系列的文章将会告诉你，爬虫是如何从一只小虫，变成布满整个互联网、在所有人面前张牙舞爪的可怕巨虫的。</p><h2 id="出生之前"><a href="#出生之前" class="headerlink" title="出生之前"></a>出生之前</h2><p>我们的故事要从1989年的瑞士开始。在瑞士日内瓦西部与德国的边境处有一片荒野，在这片荒野里，一群智商高达250的精英们躲在这偷偷研究世界上最小的物质——这里建立着世界上最大的粒子物理学实验室：欧洲核子研究委员会（CERN）。八十年代，切尔诺贝利事故的阴影笼罩在整个欧洲上空，然而年轻的<strong>蒂姆·伯纳斯·李（Timothy John Berners-Lee）</strong>和其他CERN的科学家们却没有停下脚步，仍然在继续研究。</p><p>话说这蒂姆并不是很有名气的资深教授，CERN的研究也轮不上他，但是Boss也不能让他闲着，看蒂姆的爸妈都参与了第一台商业电脑<strong>曼切斯特1型（Manchester Mark I）</strong>的发明，就让他开发个计算机软件，目的能让CERN与其他国家的研究室更加便捷地交流。</p><p>蒂姆虽然拿到了牛津的荣誉物理学士学位，本该研究物理，但是他还是接了这项工作。令人出乎意料的是，不久之后，在1989年的夏夜，世界上第一个Web服务器和客户端出现在了CERN的一台NeXT计算机上。<strong>他将这项技术命名为World Wide Web，也就是www，或者叫做万维网，从此，互联网的青春开始了。</strong></p><p><img src="/img/1/post2.jpg" alt="万维网的诞生机器"></p><p>等等，你不是要讲爬虫吗，怎么讲起万维网来了？</p><p>别急，蒂姆发明万维网的同时，还带来了三项关键的技术，这三项技术为爬虫的诞生构建了温床，那就是<strong>URI、HTML和HTTP</strong>。</p><p>先说最基础的http吧，这个大家应该不陌生，你打开浏览器访问任何网页的时候，看网址开头都是<code>http://</code>。爬虫说到底还是一堆0和1，它们靠着http在万维网中伸展拳脚。</p><p>之后就是URI，用来精确定位互联网上的资源，简单说就是咱们说的网址，网址各部分的意思如图所示，通过一堆字符确定了服务器、端口、路径、内容和传送的方式，爬虫靠着他提供的“地址”敲响每个服务器的门。</p><p><img src="/img/1/post10.jpg" alt="URL"></p><p>最后就是HTML，这是与爬虫联系最精密的一项技术。HTML是超文本标记语言，作家写文章的时候可能会给编辑留下一些非正文的消息，比如</p><blockquote><p>作家：</p><p>……我家门口有两棵树，其中一棵是枣树，另一棵也是枣树。（注：这两棵树品种不同）……</p><p>编辑：</p><p>把括号里的文字放在书的最下方，并用小号字体标注是注释，正文中删去括号中的话。</p></blockquote><p>HTML就是作家写的原文，网页编写者通过<code>&lt;h&gt;&lt;/h&gt;</code>这样的标签对来标记文章的内容，然后咱们优秀的编辑——浏览器把这些标签解释出来，然后形成你现在正在看的这个网页。有了这些标签，你就能看见这些有<strong>粗体</strong> <em>斜体</em> <font size="5">大</font><font size="2">小<font color="#dd0000">颜色</font></font>不同的字了。这让人们能把他们宝贵的知识放到网上共享，也能让你天天在微信发各种各样的朋友圈，而这些有用的数据就是爬虫的<strong>最终目标。</strong></p><p>值得一提的是，HTML有一种特殊的标签<code>&lt;a&gt;</code>，被这个标签标记的文本会被认为是一个<strong>超链接</strong>，超链接的发明，让阅览网页与阅读书籍产生的本质上的区别，这是一种<strong>“所见即所得”</strong>的体验，比如这篇推送的“阅读原文”，你只要动动手指点一下阅读原文就能跳转页面过去，而不是从书架上翻一本新的书。超链接就像虫洞一样，爬虫靠着这个完美的交通工具，在万维网上爬来爬去。</p><h2 id="万维网需要爬虫"><a href="#万维网需要爬虫" class="headerlink" title="万维网需要爬虫"></a>万维网需要爬虫</h2><p>之前我们说到那蒂姆发明了万维网，在1991年这项技术被公之于众之后，它可是成了当时的“网红”，1993年只有130个网站，1996年就有十万个了，1993年Web服务器占比1.5%，1996年就已经有50%的服务器是Web服务器了。如此快的增长速度，也伴随着巨量的数据，而数据一多，要找到特定的数据就尤为困难。假如你想知道爬虫是啥，你可能打开电脑首先就百度去，可是当时的人没有搜索引擎，他们使用一种类似黄页的东西，要查询到爬虫是啥，他们可能会选择从厚厚的书中找到某生物研究机构的主页，然后在控制台敲上网址，然后访问（虽然结果还是无功而返）。</p><p><img src="/img/1/post7.png" alt="碟中谍1"></p><p>其实在万维网发布之前就出现了第一个搜索引擎——<strong>Archie</strong>，不过它与百度谷歌相差甚远，它只是一个搜索匿名ftp下载服务器的脚本。ftp是文件传输协议，在万维网出现之前就已经流行起来，即使是当下也有很多文件是通过ftp协议下载的。Archie虽然叫做搜索引擎，但是搜索功能很蛋疼，用户搜索的每个字都必须要精确符合标题才可以搜索到结果，但即使功能如此简陋，但是在其巅峰时期，使用这个引擎的流量占据蒙特利尔总带宽的50%。</p><p><img src="/img/1/post1.jpg" alt="Archie"></p><p>Archie体现了搜索引擎的需求，而开发者们选择了两种方式来开发搜索引擎：</p><p><strong>马丁·科斯特（Martijn Koster）的尝试是ALIWEB</strong>，这是最早的万维网搜索引擎之一，于1993年12月发布，ALIWEB的数据来源是用户的主动提交，它允许网站站长上传他们网站的URL，并手动添加描述，之后用户就可以通过ALIWEB查询到对应的网站。然而，来提交网站的站长并没有马丁想象的那么多，有的可能不知道如何提交，有的可能懒得提交，有的可能根本就不知道这个网站，所以ALIWEB就这样慢慢的消失在了互联网的发展长河中。</p><p><img src="/img/1/post5.png" alt="ALIWEB在1997年的页面"></p><p><strong>而另一波开发者选择了一个更聪明的数据获取方式，他们准备发明一个能够自动环游万维网的探索者，主动去探索万维网，获取网站的信息，再通过算法索引它们来建立搜索引擎，这样就不需要被动的等待站长们来提交网页了。</strong></p><p>然而他们都没有想到，这是一个潘多拉宝盒，这个探索者转眼间就变成了依附于万维网上的爬虫。在三十年后的今天，这些爬虫密密麻麻地分布在网络上，互联网的每个角落都有爬虫的身影，即使是冰山底下的暗网也被特殊的爬虫涉足，据传言，<strong>互联网上50%的流量都是爬虫创造的</strong>，也许人们称这项技术为“爬虫”时就已经潜意识认为这项技术像爬虫一样，虽然无害甚至有益，但总是让人恐惧。</p><p><img src="/img/1/post3.png" alt="传统爬虫结构"></p><p>工程师们最初设计的传统爬虫的结构由图中这几部分组成，这是一个很简单的架构，简单来说就是获取网页-&gt;提取网页的数据和连接-&gt;从新获取的连接中获取新网页。</p><p>我们可以把爬虫想象为一位攻城掠地的常胜将军，他带着初始的补给去攻打一个个城池，每攻下一个城池就能获得新的补给，然后他就带着新的补给去攻打新的城池……直到他征服了全世界。</p><p>然而，有的将军脑子不是那么灵光，他走到一个城池地下，在脑子里想半天才能回忆起来这个城池是否已经攻略，还有的将军的战略不太好，攻下一个城池的时间过于久，以至于他一辈子也征服不了世界。这些都是常胜将军的训练员——爬虫工程师们将要解决的问题。</p><h2 id="初露锋芒"><a href="#初露锋芒" class="headerlink" title="初露锋芒"></a>初露锋芒</h2><p>虽然爬虫的需求是依附于搜索引擎的，但是世界上第一个爬虫程序并不是用于搜索引擎的。</p><p>在万维网成为“网红”并展示其惊人的发展速度后，<strong>MIT的一位学生，马修·格雷（Matthew Gray），决定研究一下万维网的拓张速度，于是他在1993年写下了历史上第一个爬虫——<em>World Wide Web Wanderer</em>。</strong></p><p>马修使用了当时热门的Perl语言来编写这个爬虫，爬虫会生成一个叫做Wandex的Web数据库，这个数据库里存储着爬取到的所有URL和服务器，只要稍加改进，这个数据库就能成为搜索引擎，比雅虎和谷歌早了好多年。然而马修只想着他的课题——研究万维网的拓张速度，并没有兴趣开发搜索引擎。</p><p><img src="/img/1/post9.jpg" alt="然而这位马修·格雷在2017年还是去了谷歌工作"></p><p>马修的爬虫引起了许多人的关注，早期的代码也在互联网上广泛流传，然而还是学生的马修写出的代码出现了严重的bug，再加上许多人同时运行这个爬虫，导致相同的一个页面一天被访问上百次，在带宽不高的当时，这样的访问直接让几个服务器宕机了。隔壁ALIWEB的马丁立刻在万维网开发者的讨论区——www-talk中喷了一波爬虫，并且提议设立<strong>机器人排除标准（Robots Exclusion Standard）</strong>，又叫做robots.txt。这是历史最悠久并存在至今的反爬虫技术。</p><p><img src="/img/1/post8.jpg" alt="Robots.txt介绍"></p><p><img src="/img/1/post4.png" alt="百度的部分robots.txt，图中禁止了百度自家爬虫爬取自己"></p><blockquote><p>可怜的爬虫技术，自其一出生就遇见了死对头，爬虫与反爬虫从此开始了道高一尺魔高一丈的斗争。爬虫的合法性常常被人质疑，俗话说“爬虫写得好，牢饭吃得早”，由于反爬虫技术越来越强，反反爬虫技术也一直革新，而反反爬虫有被认为是非法盗取信息以及侵犯隐私的嫌疑，于是许多爬虫开发者都游走在灰色区域。在国外非常著名的案件有eBay VS. Bidder’s Edge案，在国内有百度起诉360搜索案，然而这都是后话……</p></blockquote><p>robots.txt是什么呢，其实并不是什么高级的技术，只是在网站的根目录下的一个普通txt文档而已。与其说它是网站的高大城墙，不如说它是酒店房间门口挂的“请勿打扰”，站长可以通过编辑robots.txt来指定爬虫能爬取哪些页面，或者指定哪些不道德的爬虫不允许来爬取这个网站，但是这些规则都不是强制性的，爬虫技术上完全可以无视这些规则。</p><h2 id="接下来？"><a href="#接下来？" class="headerlink" title="接下来？"></a>接下来？</h2><p>1993年和1994年是爬虫发展最为迅速的两年，许多爬虫的开发都是同时进行的，几乎每个月都能有新的爬虫出现，一张大网已经为织好，接下来，就有请它们闪亮登场吧……</p><div class="note note-info">            <p>这篇文章也发布在下面这个公众号数媒极客，公众号里面有其他很有趣的文章，可以扫码看一看~</p><img src="https://kamino-img.oss-cn-beijing.aliyuncs.com/671DEC2D0C09137F94251F74940B395C.jpg" style="zoom:50%;" />          </div>]]></content>
    
    
    <categories>
      
      <category>爬虫历史系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
